Author,Title,Year,Link,Affiliation,Abstract,Author Keywords,Index Keywords
Karina Valdívia Delgado,Extreme Risk Averse Policy for Goal-Directed Risk-Sensitive Markov Decision Process,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015155700&doi=10.1109%2fBRACIS.2016.025&partnerID=40&md5=1a29482f7f3e352ec1dfd3b11a8062d0,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"The Goal-Directed Risk-Sensitive Markov Decision Process allows arbitrary risk attitudes for the probabilistic planning problem to reach a goal state. In this problem, the risk attitude is modeled by an expected exponential utility and a risk factor λ. However, the problem is not well defined for every λ, posing the problem of defining the maximum (extreme) value for this factor. In this paper, we propose an algorithm to find this e-extreme risk factor and the corresponding optimal policy. © 2016 IEEE.",Exponential Utility; Markov Decision Process; Risk averse,Intelligent systems; Risk analysis; Exponential utility; Extreme risk factors; Goal directed; Markov Decision Processes; Optimal policies; Probabilistic planning; Risk attitude; Risk averse; Markov processes
Karina Valdívia Delgado,Robust probabilistic planning with ilao,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963778693&doi=10.1007%2fs10489-016-0780-4&partnerID=40&md5=90eb0dd63f8ba4635302ae1ec9e5272e,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"In probabilistic planning problems which are usually modeled as Markov Decision Processes (MDPs), it is often difficult, or impossible, to obtain an accurate estimate of the state transition probabilities. This limitation can be overcome by modeling these problems as Markov Decision Processes with imprecise probabilities (MDP-IPs). Robust LAO* and Robust LRTDP are efficient algorithms for solving a special class of MDP-IPs where the probabilities lie in a given interval, known as Bounded-Parameter Stochastic-Shortest Path MDP (BSSP-MDP). However, they do not make clear what assumptions must be made to find a robust solution (the best policy under the worst model). In this paper, we propose a new efficient algorithm for BSSP-MDPs, called Robust ILAO* which has a better performance than Robust LAO* and Robust LRTDP, considered the-state-of-the art of robust probabilistic planning. We also define the assumptions required to ensure a robust solution and prove that Robust ILAO* algorithm converges to optimal values if the initial value of all states is admissible. © 2016, Springer Science+Business Media New York.",Bounded-parameter Markov decision process; Heuristic search; Probabilistic planning,Algorithms; Heuristic algorithms; Learning algorithms; Markov processes; Probability; Stochastic systems; Bounded parameters; Heuristic search; Imprecise probabilities; Markov Decision Processes; Probabilistic planning; State of the art; State transition probabilities; Stochastic shortest paths; Behavioral research
Karina Valdívia Delgado,Real-time dynamic programming for Markov decision processes with imprecise probabilities,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946143616&doi=10.1016%2fj.artint.2015.09.005&partnerID=40&md5=f47261404e3828492de899ab35ae81eb,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"Markov Decision Processes have become the standard model for probabilistic planning. However, when applied to many practical problems, the estimates of transition probabilities are inaccurate. This may be due to conflicting elicitations from experts or insufficient state transition information. The Markov Decision Process with Imprecise Transition Probabilities (MDP-IPs) was introduced to obtain a robust policy where there is uncertainty in the transition. Although it has been proposed a symbolic dynamic programming algorithm for MDP-IPs (called SPUDD-IP) that can solve problems up to 22 state variables, in practice, solving MDP-IP problems is time-consuming. In this paper we propose efficient algorithms for a more general class of MDP-IPs, called Stochastic Shortest Path MDP-IPs (SSP MDP-IPs) that use initial state information to solve complex problems by focusing on reachable states. The (L)RTDP-IP algorithm, a (Labeled) Real Time Dynamic Programming algorithm for SSP MDP-IPs, is proposed together with three different methods for sampling the next state. It is shown here that the convergence of (L)RTDP-IP can be obtained by using any of these three methods, although the Bellman backups for this class of problems prescribe a minimax optimization. As far as we are aware, this is the first asynchronous algorithm for SSP MDP-IPs given in terms of a general set of probability constraints that requires non-linear optimization over imprecise probabilities in the Bellman backup. Our results show up to three orders of magnitude speedup for (L)RTDP-IP when compared with the SPUDD-IP algorithm. © 2015 Elsevier B.V. All rights reserved.",Markov decision process; Probabilistic planning; Robust planning,Algorithms; Behavioral research; Learning algorithms; Markov processes; Nonlinear programming; Optimization; Probability; Problem solving; Stochastic systems; Markov Decision Processes; Probabilistic planning; Probability constraints; Real-time dynamic programming; Robust planning; Stochastic shortest paths; Three orders of magnitude; Transition probabilities; Dynamic programming
Karina Valdívia Delgado,Learning to program using hierarchical model-based debugging,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941876149&doi=10.1007%2fs10489-015-0659-9&partnerID=40&md5=427f6e947ec825cfb436ff53292d28aa,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"Model-based Diagnosis is a well known AI technique that has been applied to software debugging for senior programmers, called Model-Based Software Debugging (MBSD). In this paper we describe the basis of MBSD and show how it can be used for educational purposes. By extending the classical diagnosis technique to a hierarchical approach, we built a programming learning system to allow a student to debug his program in different abstraction levels. © 2015, Springer Science+Business Media New York.",Intelligent tutoring system; Model-based diagnosis; Pedagogical patterns; Program debugging,Computer aided instruction; Education computing; Hierarchical systems; Program diagnostics; Teaching; Diagnosis techniques; Hierarchical approach; Hierarchical model; Intelligent tutoring system; Model based diagnosis; Pedagogical patterns; Programming learning; Software debugging; Program debugging
Karina Valdívia Delgado,Analysis of an advisor-advisee relationship: An exploratory study of the area of Exact and Earth Sciences in Brazil,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930221861&doi=10.1371%2fjournal.pone.0129065&partnerID=40&md5=9116c57ee5551923d117809fdac4dd98,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"Scientific collaboration has been studied by researchers for decades. Several approaches have been adopted to address the question of how collaboration has evolved in terms of publication output, numbers of coauthors, and multidisciplinary trends. One particular type of collaboration that has received very little attention concerns advisor and advisee relationships. In this paper, we examine this relationship for the researchers who are involved in the area of Exact and Earth Sciences in Brazil and its eight subareas. These pairs are registered in the Lattes Platform that manages the individual curricula vitae of Brazilian researchers. The individual features of these academic researchers and their coauthoring relationships were investigated. We have found evidence that there exists positive correlation between time of advisor-advisee relationship with the advisee's productivity. Additionally, there has been a gradual decline in advisor-advisee coauthoring over a number of years as measured by the Kulczynski index, which could be interpreted as decline of the dependence. © 2015 Tuesta et al.",,Article; author; bibliometrics; Brazil; cluster analysis; coauthor; computer; controlled study; data analysis; data mining; exploratory research; faculty student relation; geology; human; Kulczynski index; mathematical computing; mathematical parameters; postgraduate student; productivity; publication; publishing; research student; scientific literature; scientist; writing; geology; human relation; mentor; personnel; Authorship; Bibliometrics; Brazil; Earth Sciences; Humans; Interpersonal Relations; Mentors; Research Personnel
Karina Valdívia Delgado,B2RTDP: An efficient solution for bounded-parameter Markov decision process,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922575911&doi=10.1109%2fBRACIS.2014.33&partnerID=40&md5=56e6bfec0ffadb166b79d66125c2b71f,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"Bounded-parameter Markov decision process (BMDP) can be used to model sequential decision problems, where the transitions probabilities are not completely know and are given by intervals. One of the criteria used to solve that kind of problems is the maxim in, i.e., the best action on the worst scenario. The algorithms to solve BMDPs that use this approach include interval value iteration and an extension of real time dynamic programming (Robust-LRTDP). In this paper, we introduce a new algorithm, named B2RTDP, also based on real time dynamic programming that makes a different choice of the next state to be visited using upper and lower bounds of the optimal value function. The empirical evaluation of the algorithm shows that it converges faster than the state-of-the-art algorithms that solve BMDPs. © 2014 IEEE.",Dynamic Programming; Markov Decision Process; Probabilistic Planning,Algorithms; Decision theory; Intelligent systems; Iterative methods; Markov processes; Empirical evaluations; Markov Decision Processes; Optimal value functions; Probabilistic planning; Real-time dynamic programming; Sequential decisions; State-of-the-art algorithms; Upper and lower bounds; Dynamic programming
Karina Valdívia Delgado,Robust optimization for hybrid MDPs with state-dependent noise,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896063404&partnerID=40&md5=a1e86ed9808664a5f080a17048e62356,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"Recent advances in solutions to Hybrid MDPs with discrete and continuous state and action spaces have significantly extended the class of MDPs for which exact solutions can be derived, albeit at the expense of a restricted transition noise model. In this paper, we work around limitations of previous solutions by adopting a robust optimization approach in which Nature is allowed to adversarially determine transition noise within pre-specified confidence intervals. This allows one to derive an optimal policy with an arbitrary (user-specified) level of success probability and significantly extends the class of transition noise models for which Hybrid MDPs can be solved. This work also significantly extends results for the related ""chance- constrained"" approach in stochastic hybrid control to accommodate state-dependent noise. We demonstrate our approach working on a variety of hybrid MDPs taken from AI planning, operations research, and control theory, noting that this is the first time robust solutions with strong guarantees over all states have been automatically derived for such problems.",,Confidence interval; Continuous state; Hybrid controls; Optimal policies; Robust optimization; Robust solutions; State-dependent noise; Transition noise; Artificial intelligence; Operations research; Optimization
Karina Valdívia Delgado,Using mathematical programming to solve Factored Markov Decision Processes with Imprecise Probabilities,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052406723&doi=10.1016%2fj.ijar.2011.04.002&partnerID=40&md5=6543eeccca51dec6b61fb0690ee27c3c,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"This paper investigates Factored Markov Decision Processes with Imprecise Probabilities (MDPIPs); that is, Factored Markov Decision Processes (MDPs) where transition probabilities are imprecisely specified. We derive efficient approximate solutions for Factored MDPIPs based on mathematical programming. To do this, we extend previous linear programming approaches for linear approximations in Factored MDPs, resulting in a multilinear formulation for robust ""maximin"" linear approximations in Factored MDPIPs. By exploiting the factored structure in MDPIPs we are able to demonstrate orders of magnitude reduction in solution time over standard exact non-factored approaches, in exchange for relatively low approximation errors, on a difficult class of benchmark problems with millions of states. © 2011 Elsevier Inc. All rights reserved.",Imprecise Markov Decision Processes (MDPIPs); Multilinear programming; Probabilistic planning,Approximate solution; Bench-mark problems; Factored Markov decision process; Imprecise probabilities; Linear approximations; Low approximation; Markov Decision Processes; Maximin; Multilinear programming; Orders of magnitude; Probabilistic planning; Solution time; Transition probabilities; Markov processes; Probability; Mathematical programming
Karina Valdívia Delgado,Symbolic dynamic programming for discrete and continuous state MDPs,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053161811&partnerID=40&md5=933aaf09385291a8311657f37ce3e031,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"Many real-world decision-theoretic planning problems can be naturally modeled with discrete and continuous state Markov decision processes (DC-MDPs). While previous work has addressed automated decision-theoretic planning for DCMDPs, optimal solutions have only been defined so far for limited settings, e.g., DC-MDPs having hyper-rectangular piecewise linear value functions. In this work, we extend symbolic dynamic programming (SDP) techniques to provide optimal solutions for a vastly expanded class of DCMDPs. To address the inherent combinatorial aspects of SDP, we introduce the XADD - a continuous variable extension of the algebraic decision diagram (ADD) - that maintains compact representations of the exact value function. Empirically, we demonstrate an implementation of SDP with XADDs on various DC-MDPs, showing the first optimal automated solutions to DCMDPs with linear and nonlinear piecewise partitioned value functions and showing the advantages of constraint-based pruning for XADDs.",,Automated solutions; Combinatorial aspect; Compact representation; Constraint-based; Continuous state; Continuous variables; Decision diagram; Decision-theoretic; Markov Decision Processes; Optimal solutions; Piece-wise; Piecewise linear; Planning problem; Value functions; Artificial intelligence; Markov processes; Optimal systems; Optimization; Piecewise linear techniques; Dynamic programming
Karina Valdívia Delgado,Efficient solutions to factored MDPs with imprecise transition probabilities,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953864311&doi=10.1016%2fj.artint.2011.01.001&partnerID=40&md5=d234c4b34e2d65d5a84fab088f395459,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"When modeling real-world decision-theoretic planning problems in the Markov Decision Process (MDP) framework, it is often impossible to obtain a completely accurate estimate of transition probabilities. For example, natural uncertainty arises in the transition specification due to elicitation of MDP transition models from an expert or estimation from data, or non-stationary transition distributions arising from insufficient state knowledge. In the interest of obtaining the most robust policy under transition uncertainty, the Markov Decision Process with Imprecise Transition Probabilities (MDP-IPs) has been introduced to model such scenarios. Unfortunately, while various solution algorithms exist for MDP-IPs, they often require external calls to optimization routines and thus can be extremely time-consuming in practice. To address this deficiency, we introduce the factored MDP-IP and propose efficient dynamic programming methods to exploit its structure. Noting that the key computational bottleneck in the solution of factored MDP-IPs is the need to repeatedly solve nonlinear constrained optimization problems, we show how to target approximation techniques to drastically reduce the computational overhead of the nonlinear solver while producing bounded, approximately optimal solutions. Our results show up to two orders of magnitude speedup in comparison to traditional ""flat"" dynamic programming approaches and up to an order of magnitude speedup over the extension of factored MDP approximate value iteration techniques to MDP-IPs while producing the lowest error of any approximation algorithm evaluated. © 2011 Elsevier B.V. All rights reserved.",Markov Decision Process; Probabilistic planning; Robust planning,Approximation techniques; Computational bottlenecks; Computational overheads; Decision-theoretic; Dynamic programming methods; Markov Decision Processes; Non-linear solver; Nonlinear constrained optimization problems; Nonstationary; Optimal solutions; Optimization routine; Orders of magnitude; Planning problem; Probabilistic planning; Robust planning; Solution algorithms; Transition model; Transition probabilities; Value iteration; Approximation algorithms; Constrained optimization; Markov processes; Probability; Dynamic programming
Karina Valdívia Delgado,Symbolic bounded real-time dynamic programming,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649954435&doi=10.1007%2f978-3-642-16138-4_20&partnerID=40&md5=3494cd95266f19620c11c5e55a47ca30,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"Real-time dynamic programming (RTDP) solves Markov decision processes (MDPs) when the initial state is restricted. By visiting (and updating) only a fraction of the state space, this approach can be used to solve problems with intractably large state space. In order to improve the performance of RTDP, a variant based on symbolic representation was proposed, named sRTDP. Traditional RTDP approaches work best on problems with sparse transition matrices where they can often efficiently achieve ε-convergence without visiting all states; however, on problems with dense transition matrices where most states are reachable in one step, the sRTDP approach shows an advantage over traditional RTDP by up to three orders of magnitude, as we demonstrate in this paper. We also specify a new variant of sRTDP based on BRTDP, named sBRTDP, which converges quickly when compared to RTDP variants, since it does less updating by making a better choice of the next state to be visited. © 2010 Springer-Verlag.",,Initial state; Markov Decision Processes; One step; State space; Symbolic representation; Three orders of magnitude; Transition matrices; Markov processes; Problem solving; Dynamic programming
Karina Valdívia Delgado,Approximate dynamic programming with affine ADDs,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899418045&partnerID=40&md5=e0529b083dcddf804ed910e247d009c8,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"The Affin ADD (AADD) is an extension of the Algebraic Decision Diagram (ADD) that compactly represents context-specific, additive and multiplicative structure in functions from a discrete domain to a real-valued range. In this paper, we introduce a novel algorithm for efficientl findin AADD approximations that we use to develop the MADCAP algorithm for AADD-based structured approximate dynamic programming (ADP) with factored MDPs. MADCAP requires less time and space to achieve comparable or better approximate solutions than the current state-of-the-art ADD-based ADP algorithm of APRICODD and can provide approximate solutions for problems with context-specific additive and multiplicative structure on which APRICODD runs out of memory. Copyright © 2010, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.",Approximate Dynamic Programming; Markov Decision Processes; Planning,Autonomous agents; Markov processes; Multi agent systems; Planning; Approximate dynamic programming; Approximate solution; Decision diagram; Discrete domains; Markov Decision Processes; Novel algorithm; Out-of-memory; Approximation algorithms
Karina Valdívia Delgado,Efficient solutions to factored MDPs with imprecise transition probabilities,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650627490&partnerID=40&md5=6247291857fd8114206d6ca122ca7181,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"When modeling real-world decision-theoretic planning problems in the Markov decision process (MDP) framework, it is often impossible to obtain a completely accurate estimate of transition probabilities. For example, natural uncertainty arises in the transition specification due to elicitation of MDP transition models from an expert or data, or non-stationary transition distributions arising from insufficient state knowledge. In the interest of obtaining the most robust policy under transition uncertainty, the Markov Decision Process with Imprecise Transition Probabilities (MDP-1Ps) has been introduced to model such scenarios. Unfortunately, while solutions to the MDP-1P are well-known, they require nonlinear optimization and are extremely time-consuming in practice. To address this deficiency, we propose efficient dynamic programming methods to exploit the structure of factored MDP-1Ps. Noting that the key computational bottleneck in the solution of MDP-1Ps is the need to repeatedly solve nonlinear constrained optimization problems, we show how to target approximation techniques to drastically reduce the computational overhead of the nonlinear solver while producing bounded, approximately optimal solutions. Our results show up to two orders of magnitude speedup in comparison to traditional ""flat"" dynamic programming approaches and up to an order of magnitude speedup over the extension of factored MDP approximate value iteration techniques to MDP-1Ps. Copyright © 2009, Association for the Advancement of Artificial Intelligence. All rights reserved.",,Approximation techniques; Computational bottlenecks; Computational overheads; Decision-theoretic; Dynamic programming methods; Markov Decision Processes; Non-linear optimization; Non-linear solver; Nonlinear constrained optimization problems; Nonstationary; Optimal solutions; Order of magnitude; Orders of magnitude; Planning problem; Real-world; Transition model; Transition probabilities; Value iteration; Constrained optimization; Markov processes; Probability; Scheduling; Dynamic programming
Karina Valdívia Delgado,Representing and solving factored markov decision processes with imprecise probabilities,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649981107&partnerID=40&md5=9af390bd08438eb89699f55ca6de0c8c,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"This paper investigates Factored Markov Decision Processes with Imprecise Probabilities; that is, Markov Decision Processes where transition probabilities are imprecisely specified, and where their specification does not deal directly with states, but rather with factored representations of states. We first define a Factored MDPIP, based on a multilinear formulation for MDPIPs; then we propose a novel algorithm for generation of Γ-maximin policies for FactoredMDPIPs. We also developed a representation language for Factored MDPIPs (based on the standard PPDDL language); finally, we describe experiments with a problem of practical significance, the well-known System Administrator Planning problem.",Imprecise markov decision processes (MDPIPs); Knowledge representation languages; Multilinear programming; Probabilistic planning and PPDDL,Factored Markov decision process; Imprecise probabilities; Knowledge representation language; Markov Decision Processes; Multi-linear programming; Probabilistic planning; Representation languages; Transition probabilities; Algorithms; Knowledge representation; Markov processes; Probabilistic logics; Probability
Karina Valdívia Delgado,Diagnostic of programs for programming learning tools,2006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751372759&partnerID=40&md5=cfc413014089c312a4c08f0da97b45c8,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"It is not easy for a student to develop programming skills and learn how to construct their own problem solving algorithms. Well designed materials and tools can guide programming students knowledge and skill construction. Such tools may allow students to acquire better and faster, the necessary programming skills. In this paper we show the results of some experiments realized on a set of faulty student's programs using PROPAT_DEBUG, an automatic program debugger, based on the Model Based Diagnosis technique of Artificial Intelligence. The results show that during the interactive debugging process it is possible for a student to learn by answering the questions posed by the AI diagnosis system to discriminate its fault hypotheses. © Springer-Verlag Berlin Heidelberg 2006.",,Algorithms; Artificial intelligence; Computer aided software engineering; Learning systems; Problem solving; Students; Diagnosis system; Model Based Diagnosis; Program debugger; Programming learning; Computer programming
Karina Valdívia Delgado,A tool for programming learning with pedagogical patterns,2005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-59249089916&doi=10.1145%2f1117696.1117722&partnerID=40&md5=0e0bd2d4eda9cdd20d1ad2743474d27e,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"Programming Patterns help create a shared language for communicating insight and experience about programming problems and their solutions. Inspired by this idea, we developed the ProPAT e-learning tool: an Eclipse IDE that allows students of a first Computer Science course to learn how to program using pedagogical patterns, i.e., a set of programming patterns recommended by Computer Science educators. ProPAT has been implemented as an Eclipse plug- in with two main perspectives: the Teacher Perspective and the Student Perspective. To identify some of the students' mistakes, the ProPAT plug-in also includes a program diagnosis system that uses Model Based Diagnosis techniques from the Artificial Inteligence. Copyright © 2005 IBM.",Computer-based learning; Debugging and testing tools; Teaching introductory undgraduate Programming,Computer Science course; Computer-based learning; Diagnosis systems; E-learning tool; Model based diagnosis; Plug-ins; Programming learning; Programming patterns; Programming problem; Shared language; Computer debugging; Computer science; E-learning; Java programming language; Program debugging; Software testing; Students; Teaching; Program diagnostics
Karina Valdívia Delgado,ProPAT: A Programming ITS Based on Pedagogical Patterns,2004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048862361&partnerID=40&md5=a3c2f9e015a420ee82e4037d657efa7b,Universidade de São Paulo - Escola de Artes Ciências e Humanidades,"Research on cognitive theories about programming learning suggests that experienced programmers solve problems by looking for previous solutions that are related to the new problem and that can be adapted to the current situation. Inspired by these ideas, programming teachers have developed a pattern based programming instruction. In this model, learning can be seen as a process of pattern recognition, which compares experiences from the past with the current situation. In this work, we present a new Eclipse programming environment in which a student can program using a set of pedagogical patterns, i.e., elementary programming patterns recommended by a group of teachers. © Springer-Verlag 2004.",,Computer aided instruction; Computer programming; Education; Intelligent vehicle highway systems; Pattern recognition; Teaching; Cognitive theory; Current situation; Programming environment; Programming instruction; Programming learning; Programming patterns; Highway planning
