Authors,Title,Link,Abstract,Author Keywords
"Gou C., Wu Y., Wang K., Wang K., Wang F.-Y., Ji Q.","A joint cascaded framework for simultaneous eye detection and eye state estimation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016162115&doi=10.1016%2fj.patcog.2017.01.023&partnerID=40&md5=4e520139493216b3785525d52be121fa","Eye detection and eye state (close/open) estimation are important for a wide range of applications, including iris recognition, visual interaction and driver fatigue detection. Current work typically performs eye detection first, followed by eye state estimation by a separate classifier. Such an approach fails to capture the interactions between eye location and its state. In this paper, we propose a method for simultaneous eye detection and eye state estimation. Based on a cascade regression framework, our method iteratively estimates the location of the eye and the probability of the eye being occluded by eyelid. At each iteration of cascaded regression, image features from the eye center as well as contextual image features from eyelid and eye corners are jointly used to estimate the eye position and openness probability. Using the eye openness probability, the most likely eye state can be estimated. Since it requires large number of facial images with labeled eye related landmarks, we propose to combine the real and synthetic images for training. It further improves the performance by utilizing this learning-by-synthesis method. Evaluations of our method on benchmark databases such as BioID and Gi4E database as well as on real world driving videos demonstrate its superior performance comparing to state-of-the-art methods for both eye detection and eye state estimation. © 2017 Elsevier Ltd","Cascade regression framework; Eye detection; Eye state estimation; Learning-by-synthesis"
"Rathod H., Ware Y., Sane S., Raulo S., Pakhare V., Rizvi I.A.","Automated attendance system using machine learning approach","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022053578&doi=10.1109%2fICNTE.2017.7947889&partnerID=40&md5=199acf2399cd6e955b24ea92409add01","The conventional method of taking attendance is done manually by the teacher or the administrator which requires considerable amount of time and efforts also involving errors and proxy attendance. As the number of students are increasing day by day, it is a challenging task for universities or colleges to monitor and maintain the record of the students. Automated systems involving use of biometrics like fingerprint and iris recognition are well developed in the recent years however, it is intrusive and cost required for deployment on large scale gets increased substantially. To overcome these issues, biometric feature like facial recognition can be used which involves the phases such as image acquisition, face detection, feature extraction, face classification, face recognition and eventually marking the attendance. The algorithms like Viola-Jones and HOG features along with SVM classifier are used to acquire the desired results. Various real time scenarios need to be considered such as scaling, illumination, occlusions and pose. The problem of redundancy in manual records and keeping attendance is solved by this system. Quantitative analysis is done on the basis of PSNR values. © 2017 IEEE.","Face Recognition; Histogram of Oriented Gradients (HOG); Peak Signal to Noise Ratio (PSNR); Support Vector Machine (SVM)"
"Sepas-Moghaddam A., Chiesa V., Correia P.L., Pereira F., Dugelay J.-L.","The IST-EURECOM Light Field Face Database","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021833322&doi=10.1109%2fIWBF.2017.7935086&partnerID=40&md5=f061a85d6364ce7d5634ae9995857c3e","Light field cameras are emerging as powerful devices to capture rich scene representations that provide unique advantages for analysis and representation purposes. Some recent works have shown the power and usefulness of the richer information carried out by light field imaging, notably for face recognition. However, it is still difficult to fully assess how face recognition technology can benefit from these novel imaging sensors, notably due to the lack of appropriate test material. To support face recognition research exploiting light field images, the IST-EURECOM Light Field Face Database (IST-EURECOM LFFD) is presented in this paper. The purpose is to report the public availability of a light field face database which should be instrumental for designing, testing and validating light field imaging based recognition systems. The proposed face database includes data from 100 subjects, captured by a Lytro ILLUM camera in two 1-6 months separated sessions, with 20 samples per each person per session. To simulate multiple scenarios, the images are captured with several facial variations, covering a range of emotions, actions, poses, illuminations, and occlusions. The database includes the raw light field images, 2D rendered images and associated depth maps, along with a rich set of metadata. The IST-EURECOM LFFD is expected to become a valuable addition to existing face database repositories. © 2017 IEEE.","Face Database; Face Recognition; Light Field Imaging"
"Cheheb I., Al-Maadeed N., Al-Madeed S., Bouridane A., Jiang R.","Random sampling for patch-based face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021840286&doi=10.1109%2fIWBF.2017.7935104&partnerID=40&md5=05307af561f25a7e8773290068b3a67d","Real face recognition is a challenging problem especially when face images are subject to distortions. This paper presents an approach to tackle partial occlusion distortions present in real face recognition using a single training sample per person. First, original images are partitioned into multiple blocks and Local Binary Patterns are applied as a local descriptor on each block separately. Then, a dimensionality reduction of the resulting descriptors is carried out using Kernel Principle Component Analysis. Once done, a random sampling method is used to select patches at random and hence build several sub-SVM classifiers. Finally, the results from each sub-classifier are combined in order to increase the recognition performance. To demonstrate the usefulness of the approach, experiments were carried on the AR Face Database and obtained results have shown the effectiveness of our technique. © 2017 IEEE.",
"Huwedi A.S., Selem H.M.","Face recognition using Regularized Linear Discriminant Analysis under occlusions and illumination variations","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020693221&doi=10.1109%2fCEIT.2016.7929029&partnerID=40&md5=966c7ddfa50d4e9b092f0f44310923d9","In recent years face recognition has received substantial attention from researchers in biometrics, pattern recognition, and computer vision communities. At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies in recent years of research. Many existing methods in face recognition area perform well under certain conditions, but still facing challenging with illumination changes and occlusions. This paper attempts to deal with the above challenges by combining robust illumination normalization techniques with powerful feature extraction method. © 2016 IEEE.","Cosine distance; Face Recognition; Feature extraction; RLDA; Small Sample Size (sss) problem; Wavelet Analysis; Wavelet-based image De-noising"
"Choudhary A., Vig R.","Face recognition using multiresolution wavelet combining discrete cosine transform and Walsh transform","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021401213&doi=10.1145%2f3077829.3077835&partnerID=40&md5=6eac97a290aa5bfc10b4f06ded90836f","In this paper a face recognition system based on multi resolution hybrid wavelet approach has been presented. The multi resolution hybrid wavelet transform matrix is generated using Kronecker product of Walsh and DCT transform matrices. This wavelet is used to extract features from face images with different expressions of subjects' faces. A feature map is generated using energy compaction technique which is used as a template to extract features of enrolled and test images. The experiments are performed on faces94 database with different variations in facial expression, change in face position and occlusion. The recognition rates achieved are 99.24%. © 2017 Association for Computing Machinery.","Discrete cosine transform(DCT); Face recognition; Multiresolution hybrid wavelet; Walsh transform"
"Gonzalez-Sosa E., Dantcheva A., Vera-Rodriguez R., Dugelay J.-L., Bremond F., Fierrez J.","Image-based gender estimation from body and face across distances","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019066667&doi=10.1109%2fICPR.2016.7900104&partnerID=40&md5=067995f14d14a28210239c60ac153751","Gender estimation has received increased attention due to its use in a number of pertinent security and commercial applications. Automated gender estimation algorithms are mainly based on extracting representative features from face images. In this work we study gender estimation based on information deduced jointly from face and body, extracted from single-shot images. The approach addresses challenging settings such as low-resolution-images, as well as settings when faces are occluded. Specifically the face-based features include local binary patterns (LBP) and scale-invariant feature transform (SIFT) features, projected into a PCA space. The features of the novel body-based algorithm proposed in this work include continuous shape information extracted from body silhouettes and texture information retained by HOG descriptors. Support Vector Machines (SVMs) are used for classification for body and face features. We conduct experiments on images extracted from video-sequences of the Multi-Biometric Tunnel database, emphasizing on three distance-settings: close, medium and far, ranging from full body exposure (far setting) to head and shoulders exposure (close setting). The experiments suggest that while face-based gender estimation performs best in the close-distance-setting, body-based gender estimation performs best when a large part of the body is visible. Finally we present two score-level-fusion schemes of face and body-based features, outperforming the two individual modalities in most cases. © 2016 IEEE.",
"Liu H., Lu J., Feng J., Zhou J.","Learning deep sharable and structural detectors for face alignment","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015768126&doi=10.1109%2fTIP.2017.2657118&partnerID=40&md5=fad35706fae9d06b39d2fb9f8079bb7a","Face alignment aims at localizing multiple facial landmarks for a given facial image, which usually suffers from large variances of diverse facial expressions, aspect ratios and partial occlusions, especially when face images were captured in wild conditions. Conventional face alignment methods extract local features and then directly concatenate these features for global shape regression. Unlike these methods which cannot explicitly model the correlation of neighbouring landmarks and motivated by the fact that individual landmarks are usually correlated, we propose a deep sharable and structural detectors (DSSD) method for face alignment. To achieve this, we firstly develop a structural feature learning method to explicitly exploit the correlation of neighbouring landmarks, which learns to cover semantic information to disambiguate the neighbouring landmarks. Moreover, our model selectively learns a subset of sharable latent tasks across neighbouring landmarks under the paradigm of the multi-task learning framework, so that the redundancy information of the overlapped patches can be efficiently removed. To better improve the performance, we extend our DSSD to a recurrent DSSD (R-DSSD) architecture by integrating with the complementary information from multi-scale perspectives. Experimental results on the widely used benchmark datasets show that our methods achieve very competitive performance compared to the state-of-the-arts. © 1992-2012 IEEE.","biometrics; deep learning; Face alignment"
"Tripathi B.K.","On the complex domain deep machine learning for face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015831764&doi=10.1007%2fs10489-017-0902-7&partnerID=40&md5=42040ab408c86f52eb4ecb7efe27f588","Biometric based verification and recognition has become the center of attention for many significant applications for security conscious societies, as it is believed that biometrics can provide accurate and reliable identification. The face biometrics are one that possesses the merits of both high accuracy and low intrusiveness. An efficient machine recognition of human faces in big dataset is both important and challenging tasks. This paper addresses an intelligent face recognition system that is pose invariant and can recognize multi-expression, occluded and blurred faces through efficient but compact deep learning. Superior functionality of neural network in a complex domain has been observed in recent researches. My work presents a new approach, which is the fusion of higher-order novel neuron models with multivariate statistical techniques in a complex domain with a sole goal of improving performance of biometric systems. This also aims at reducing the computational cost and providing a faster recognition system. This paper presents the formal algorithms for feature extraction with multivariate statistical techniques in complex domain and compare them their real domain counterpart. This paper also presents a classifier structure (OCON : One-Class-in-One-Neuron) which contains an ensemble of novel higher order neurons, which drastically reduces the complexity of proposed learning machine because only single neuron is sufficient to recognize a subject in the database. This novel fusion in the proposed deep learning machine has thoroughly presented its superiority over a wide spectrum of experiments. Advanced deep learning capabilities, and complex domain implementation in particular, are significantly advancing state-of-art in computer vision and pattern recognition. © 2017 Springer Science+Business Media New York","Biometrics; Complex independent component analysis (CICA); Complex principal component analysis (CPCA); One-class-in-one-neuron (OCON)"
"McLaughlin N., Ming J., Crookes D.","Largest Matching Areas for Illumination and Occlusion Robust Face Recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960158384&doi=10.1109%2fTCYB.2016.2529300&partnerID=40&md5=a109fda84d4806feb5994c2a981fa183","In this paper, we introduce a novel approach to face recognition which simultaneously tackles three combined challenges: 1) uneven illumination; 2) partial occlusion; and 3) limited training data. The new approach performs lighting normalization, occlusion de-emphasis and finally face recognition, based on finding the largest matching area (LMA) at each point on the face, as opposed to traditional fixed-size local area-based approaches. Robustness is achieved with novel approaches for feature extraction, LMA-based face image comparison and unseen data modeling. On the extended YaleB and AR face databases for face identification, our method using only a single training image per person, outperforms other methods using a single training image, and matches or exceeds methods which require multiple training images. On the labeled faces in the wild face verification database, our method outperforms comparable unsupervised methods. We also show that the new method performs competitively even when the training images are corrupted. © 2016 IEEE.","Biometrics; face recognition; identification of persons"
"Naveen S., Rugmini K.P., Moni R.S.","3D face reconstruction by pose correction, patch cloning and texture wrapping","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014911379&doi=10.1109%2fCSN.2016.7823997&partnerID=40&md5=d83e42a8548567d921eea89900252c10","Face is being considered as one of the most commonly used biometric modality. The inaccuracy in two dimensional face recognition systems is mainly due to pose variations, occlusions, illumination etc. Among this, changes in illumination condition do not affect 3D face recognition systems. But pose variation drastically changes the appearance of face images. To solve the problems with depth map and texture images corrupted by head pose variations and the occlusions generated due to these pose variations, a reconstruction method is proposed which consist of three stages. In the first stage, the pose correction is done by Iterative Closest Point (ICP) algorithm and in the second stage the occluded region of the face is reconstructed by a resurfacing method called patch cloning. It is followed by the wrapping of reconstructed depth map by its texture to generate a 3D model. The statistical error between the original face and the reconstructed face is also evaluated. In this work, facial symmetry is used as a prior knowledge. Experiments are done with the FRAV3D database. © 2016 IEEE.","Face recognition; Face Resurfacing; ICP algorithm; Patch Cloning; Pose Correction"
"Badejo J.A., Atayero A.A., Ibiyemi T.S.","A robust preprocessing algorithm for iris segmentation from low contrast eye images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013625210&doi=10.1109%2fFTC.2016.7821663&partnerID=40&md5=4a1c087024cea7b14e6830a3fa1b3331","Iris recognition systems offer highly accurate personal identification both on small and very-large scale systems needed in government, forensic and commercial applications. The automatic segmentation of a noise-free iris region is imperative for optimal performance of the system. However, image characteristics such as brightness and contrast, the differing levels of pigmentation, occlusion by eyelashes and/or eyelids, coupled with varying sensor and environmental conditions, makes iris segmentation a huge and difficult task. This paper proposes an image pre-processing algorithm for robust iris segmentation of low contrast images, aimed at reducing mis-localization errors of basic curve-fitting algorithms. Similar to face detection, the algorithm performs iris detection with a k-NN classifier trained with features extracted by a rotation-invariant texture descriptor based on the co-occurrence of local binary patterns. The integration of the proposed algorithm into an existing open-source iris segmentation module offered a 40% improvement in execution time; a segmentation accuracy of 92% was also recorded over 1,898 low contrast eye images acquired from African subjects. The low contrast eye images were acquired to support diversity in iris recognition. © 2016 IEEE.","Iris Dataset; Iris Detection; Iris Segmentation; Local Binary Patterns; Pattern Recognition; Texture Descriptor"
"Ouanan H., Ouanan M., Aksasse B.","Facial landmark localization: Past, present and future","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010192469&doi=10.1109%2fCIST.2016.7805097&partnerID=40&md5=8d06c27f8154628d1620f098c405b5dc","Face landmarking, defined as the detection and localization of certain keypoints points on the face, plays arguably the important role as an intermediary step for many subsequent face processing operations that ranges from biometric recognition to the understanding of mental states. Though its conceptual simplicity, the computer vision problem has proven extremely challenging due to multitude of compound factors such as pose, expression, occlusion and illumination. In this paper, we survey the recent advances of facial landmarks localization techniques and discuss the advantages and disadvantages of the presented algorithms. © 2016 IEEE.","Face Detection; face recognition; face tracking; Facial landmarks; localization"
"Savvides M., Juefei-Xu F., Prabhu U., Bhagavatula C.","Unconstrained biometric identification in real world environments","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986246038&doi=10.1007%2f978-3-319-41956-5_21&partnerID=40&md5=7ebd72f6c8ec7db11aaaa8904e8e3c83","In this work, we introduce four topics that cover the most important problems and challenges for unconstrained face biometrics identification in real world environment. They are (1) off angle and occluded face recognition, (2) low resolution face recognition, (3) full craniofacial 3D modeling, and (4) hallucinating the full face from the periocular region. We will show the state-of-the-art results accordingly. © Springer International Publishing Switzerland 2017.","Occluded face recognition; Off angle face recognition; Unconstrained biometric identification; Unconstrained face recognition"
"Shwetha S., Dixit S., Khondanpur B.I.","Person recognition using surf features and Vola-jones algorithm","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014955023&doi=10.1007%2f978-981-10-3156-4_56&partnerID=40&md5=200c769cb524e589cae3078ad74bc4d8","Face recognition is one of the prominent biometric software applications, which can identify specific person in a digital image by analysing few parameters and comparing them. These type of recognitions are commonly used in security systems but are used increasingly in variety of other applications. Few non static conditions like facial hair can make recognition system a serious problem. The three stages of face recognition system are facing detection, feature extraction and classification. For enhancing the face recognition from video successions against dissimilar occlusion invariant and posture is proposed by using a novel approach. This face identification system made use of Viola and Jones algorithm for face detection and SURF (Speed Up Robust Feature) for feature extraction. Classifications of these face images are done using RBF (Radial Basis Function kernel) SVM (Support Vector Machine) classifier. © Springer Nature Singapore Pte Ltd. 2017.","Face detection; Face recognition; SURF; SVM; Vola-jones algorithm"
"Tan S., Chen D., Guo C., Huang Z.","A Robust Shape Reconstruction Method for Facial Feature Point Detection","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016122177&doi=10.1155%2f2017%2f4579398&partnerID=40&md5=8724a12efd94e25bd3e071a97d6de415","Facial feature point detection has been receiving great research advances in recent years. Numerous methods have been developed and applied in practical face analysis systems. However, it is still a quite challenging task because of the large variability in expression and gestures and the existence of occlusions in real-world photo shoot. In this paper, we present a robust sparse reconstruction method for the face alignment problems. Instead of a direct regression between the feature space and the shape space, the concept of shape increment reconstruction is introduced. Moreover, a set of coupled overcomplete dictionaries termed the shape increment dictionary and the local appearance dictionary are learned in a regressive manner to select robust features and fit shape increments. Additionally, to make the learned model more generalized, we select the best matched parameter set through extensive validation tests. Experimental results on three public datasets demonstrate that the proposed method achieves a better robustness over the state-of-the-art methods.",
"Xia B.","3D nasal shape: A new basis for soft-biometrics recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025157822&doi=10.1007%2f978-3-319-60654-5_7&partnerID=40&md5=f2b8a70acbaf802fe8e92f2104530a2a","In the past 10 years, Soft-Biometrics recognition using 3D face has become prevailing, with many successful research works developed. In contrast, the usage of facial parts for Soft-Biometrics recognition remains less investigated. In particular, the nasal shape contains rich information for demographic perception. They are usually free from hair/glasses occlusions, and stay robust to facial expressions, which are challenging issues 3D face analysis. In this work, we propose the idea of 3D nasal Soft-Biometrics recognition. To this end, the simple 3D coordinates features are derived from the radial curves representation of the 3D nasal shape. With the 466 earliest scans of FRGCv2 dataset (mainly neutral), we achieved 91% gender (Male/Female) and 94% ethnicity (Asian/Non-asian) classification rates in 10-fold cross-validation. It demonstrates the richness of the nasal shape in presenting the two Soft-Biometrics, and the effectiveness of the proposed recognition scheme. The performances are further confirmed by more rigorous cross-dataset experiments, which also demonstrates the generalization ability of propose approach. When experimenting on the whole FRGCv2 dataset (40% are expressive), comparable recognition performances are achieved, which confirms the general knowledge that the nasal shape stays robust during facial expressions. © Springer International Publishing AG 2017.","3D; Gender/Ethnicity recognition; Nasal Soft-Biometrics"
"Sarangi P.P., Panda M., Mishra B.S.P., Dehuri S.","An automated ear localization technique based on modified hausdorff distance","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009477189&doi=10.1007%2f978-981-10-2107-7_21&partnerID=40&md5=f045ee582f6e704b09cdbf2f01daeb5a","Localization of ear in the side face images is a fundamental step in the development of ear recognition based biometric systems. In this paper, a well-known distance measure termed as modified Hausdorff distance (MHD) is proposed for automatic ear localization.We introduced theMHD to decrease the effect of outliers and allowing it more suitable for detection of ear in the side face images. The MHD uses coordinate pairs of edge pixels derived from ear template and skin regions of the side face image to locate the ear portion. To detect ears of various shapes, ear template is created by considering different structure of ears and resized it automatically for the probe image to find exact location of ear. The CVL and UND-E database have side face images with different poses, inconsistent background and poor illumination utilized to analyse the effectiveness of the proposed algorithm. Experimental results reveal the strength of the proposed technique is invariant to various poses, shape, occlusion, and noise. © Springer Science+Business Media Singapore 2017.","Biometrics; Ear localization; Ear verification; Hausdorff distance; Skin-color segmentation"
"Zheng Y., Zhu C., Luu K., Bhagavatula C., Le T.H.N., Savvides M.","Towards a deep learning framework for unconstrained face detection","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011260714&doi=10.1109%2fBTAS.2016.7791203&partnerID=40&md5=b9b1b80e7c227ec82e5606040ed3312d","Robust face detection is one of the most important preprocessing steps to support facial expression analysis, facial landmarking, face recognition, pose estimation, building of 3D facial models, etc. Although this topic has been intensely studied for decades, it is still challenging due to numerous variants of face images in real-world scenarios. In this paper, we present a novel approach named Multiple Scale Faster Region-based Convolutional Neural Network (MS-FRCNN) to robustly detect human facial regions from images collected under various challenging conditions, e.g. large occlusions, extremely low resolutions, facial expressions, strong illumination variations, etc. The proposed approach is benchmarked on two challenging face detection databases, i.e. the Wider Face database and the Face Detection Dataset and Benchmark (FDDB), and compared against recent other face detection methods, e.g. Two-stage CNN, Multi-scale Cascade CNN, Faceness, Aggregate Chanel Features, HeadHunter, Multi-view Face Detection, Cascade CNN, etc. The experimental results show that our proposed approach consistently achieves highly competitive results with the state-of-the-art performance against other recent face detection methods. © 2016 IEEE.",
"Lazarus M.Z., Gupta S.","A low rank model based improved eye detection under spectacles","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010382951&doi=10.1109%2fUEMCON.2016.7777820&partnerID=40&md5=5933dc387baae7e7d75438c8325b6f93","Eye detection is a primary step in many applications such as face recognition, iris recognition, driver fatigue detection, gaze tracking etc. Occlusion by spectacles, glare and secondary image formations deteriorate its performance. In this paper, we formulate the glare/reflection removal as a classification problem and employ Low rank decomposition technique to overcome these challenges. We provide an in-depth analysis by comparing various low rank decomposition formulations and propose a simple preprocessing step to improve the detection accuracy. Experimentation on CASIA NIR-VIS 2.0 facial database validates the proposed preprocessing method. © 2016 IEEE.","Eye detection; Glare removal; Low rank model; Spectacle reflection"
"Karahan Ş., Yildirim M.K., Kirtaç K., Rende F.Ş., Bütün G., Ekenel H.K.","How image degradations affect deep CNN-based Face recognition?","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997427301&doi=10.1109%2fBIOSIG.2016.7736924&partnerID=40&md5=13e6a5faaa4ce0092f1b4815bbd2c0af","Face recognition approaches that are based on deep convolutional neural networks (CNN) have been dominating the field. The performance improvements they have provided in the so called in-the-wild datasets are significant, however, their performance under image quality degradations have not been assessed, yet. This is particularly important, since in realworld face recognition applications, images may contain various kinds of degradations due to motion blur, noise, compression artifacts, color distortions, and occlusion. In this work, we have addressed this problem and analyzed the influence of these image degradations on the performance of deep CNN-based face recognition approaches using the standard LFW closed-set identification protocol. We have evaluated three popular deep CNN models, namely, the AlexNet, VGG-Face, and GoogLeNet. Results have indicated that blur, noise, and occlusion cause a significant decrease in performance, while deep CNN models are found to be robust to distortions, such as color distortions and change in color balance. © 2016 Gesellschaft für Informatik e.V., Bonn, Germany.",
"Alonso-Fernandez F., Bigun J.","A survey on periocular biometrics research","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950261580&doi=10.1016%2fj.patrec.2015.08.026&partnerID=40&md5=28476fbbf7c5d4b6d0e159d028fe0ac7","Periocular refers to the facial region in the vicinity of the eye, including eyelids, lashes and eyebrows. While face and irises have been extensively studied, the periocular region has emerged as a promising trait for unconstrained biometrics, following demands for increased robustness of face or iris systems. With a surprisingly high discrimination ability, this region can be easily obtained with existing setups for face and iris, and the requirement of user cooperation can be relaxed, thus facilitating the interaction with biometric systems. It is also available over a wide range of distances even when the iris texture cannot be reliably obtained (low resolution) or under partial face occlusion (close distances). Here, we review the state of the art in periocular biometrics research. A number of aspects are described, including: (i) existing databases, (ii) algorithms for periocular detection and/or segmentation, (iii) features employed for recognition, (iv) identification of the most discriminative regions of the periocular area, (v) comparison with iris and face modalities, (vi) soft-biometrics (gender/ethnicity classification), and (vii) impact of gender transformation and plastic surgery on the recognition accuracy. This work is expected to provide an insight of the most relevant issues in periocular biometrics, giving a comprehensive coverage of the existing literature and current state of the art. © 2015 Elsevier B.V.","Biometrics; Eye; Face; Iris; Periocular"
"Rikhtegar A., Pooyan M., Manzuri-Shalmani M.T.","Genetic algorithm-optimised structure of convolutional neural network for face recognition applications","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984699027&doi=10.1049%2fiet-cvi.2015.0037&partnerID=40&md5=09653416764872bd4ef9e4654ce273e5","Proposing a proper method for face recognition is still a challenging subject in biometric and computer vision applications. Although some reliable systems were introduced under relatively controlled conditions, their recognition rate is not satisfactory in the general settings. This is especially true when there are variations in pose, illumination, and facial expression. To alleviate these problems, a hybrid face recognition system is proposed which benefits from the superiority of both convolutional neural network (CNN) and support vector machine (SVM). To this end, first a genetic algorithm is employed to find the optimum structure of CNN. Then, the performance of the system is improved by replacing the last layer of CNN with an ensemble of SVMs. Finally, using concepts of error correction, decision is made. The potential of CNN as a trainable feature extractor provides a flexible recognition system that can recognise faces with variations in pose and illumination. Simulation results show that the system achieves good recognition rate and is robust against variations in terms of facial expressions, occlusion, noise, and illuminations. © The Institution of Engineering and Technology.",
"Sanchez del Rio J., Moctezuma D., Conde C., Martin de Diego I., Cabello E.","Automated border control e-gates and facial recognition systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978477264&doi=10.1016%2fj.cose.2016.07.001&partnerID=40&md5=923aef0b2a5c87323cf36a3fd7dbe0df","A fast automated biometric solution has been proposed to satisfy the future border control needs of airports resulting from the rapid growth in the number of passengers worldwide. Automated border control (ABC) systems handle the problems caused by this growth, such as congestion at electronic gates (e-gates) or delays in the planned arrival schedules. Different modalities, such as face, fingerprint, or iris recognition, will be used in most of the ABC systems located at airports in the European/Schengen areas. Because facial recognition is the modality that travelers consider most acceptable, it was decided to include this modality in all second generation passports. Face recognition systems, installed in small kiosks inside the e-gates, require high quality facial images to allow high performance and efficiency. Accurate face recognition algorithms, which should be invariant to non-idealities, such as changes in pose and expression, occlusions, and changes in lighting, are also required for these systems. In this paper, a review of the most important face recognition algorithms described in the literature that are invariant to these non-idealities and that can be used in ABC e-gates is presented. A comparative analysis of the most common ABC e-gates located at the different airports is provided. In addition, the results of an experimental evaluation of a face recognition system when halogen, white LEDs, near infra-red, or fluorescence illumination was used, which was conducted in order to determine which type of illumination is optimal for use in ABC e-gates, are presented. To conclude, improvements that could be implemented in the near future in ABC face recognition systems are described. © 2016 The Authors","Automated; Borders; E-gates; Face; Harmonization; Invariant; Passports; Performance; Quality; Recognition"
"Guermoui M., Melaab D., Mekhalfi M.L.","Sparse coding joint decision rule for ear print recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989154446&doi=10.1117%2f1.OE.55.9.093105&partnerID=40&md5=5bcde4cdb470a5889b3d1875c8a1508f","Human ear recognition has been promoted as a profitable biometric over the past few years. With respect to other modalities, such as the face and iris, that have undergone a significant investigation in the literature, ear pattern is relatively still uncommon. We put forth a sparse coding-induced decision-making for ear recognition. It jointly involves the reconstruction residuals and the respective reconstruction coefficients pertaining to the input features (co-occurrence of adjacent local binary patterns) for a further fusion. We particularly show that combining both components (i.e., the residuals as well as the coefficients) yields better outcomes than the case when either of them is deemed singly. The proposed method has been evaluated on two benchmark datasets, namely IITD1 (125 subject) and IITD2 (221 subjects). The recognition rates of the suggested scheme amount for 99.5% and 98.95% for both datasets, respectively, which suggest that our method decently stands out against reference state-of-the-art methodologies. Furthermore, experiments conclude that the presented scheme manifests a promising robustness under large-scale occlusion scenarios. © 2016 Society of Photo-Optical Instrumentation Engineers (SPIE).","ear imaging; feature fusion; physiological biometrics; signal reconstruction; sparse coding"
"Zhang J., Huang D., Wang Y., Sun J.","Lock3DFace: A large-scale database of low-cost Kinect 3D faces","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988432113&doi=10.1109%2fICB.2016.7550062&partnerID=40&md5=b25394bb9ffda22d92409c2cd0a74cfa","In this paper, we present a large-scale database consisting of low cost Kinect 3D face videos, namely Lock3DFace, for 3D face analysis, particularly for 3D Face Recognition (FR). To the best of our knowledge, Lock3DFace is currently the largest low cost 3D face database for public academic use. The 3D samples are highly noisy and contain a diversity of variations in expression, pose, occlusion, time lapse, and their corresponding texture and near infrared channels have changes in lighting condition and radiation intensity, allowing for evaluating FR methods in complex situations. Furthermore, based on Lock3DFace, we design the standard experimental protocol for low-cost 3D FR, and give the baseline performance of individual subsets belonging to different scenarios for fair comparison in the future. © 2016 IEEE.",
"Majeed R., Beiji Z., Hatem H.","Face detection based on wavelet transform and cuckoo algorithm","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991270714&doi=10.1166%2fjctn.2016.5329&partnerID=40&md5=ea71928842c191986536908d353a0815","Over the last 3 decades face detection have pushed the envelope of face recognition techniques. The actual advantages of face based identification over other biometrics are uniqueness and acceptance. Face recognition is a difficult problem because of the generally similar shape of faces combined with the numerous variations between images of the same face. The task of a face recognition system is to recognize a face in a manner that is as independent as possible of these image variations. In this paper, we have proposed a new combination of Discrete Cosine Transform (DCT), Discrete Wavelet Transform (DWT) and Cuckoo Search Algorithm (CS) for human face detection. We applied automatic wavelet base selection approach to decompose the image and obtain the wavelet coefficients, a filter employed to adjust these coefficients, the inverse DWT reconstruct the image. DCT extract features of a face image, Then CS algorithm use for feature selection. Finally, we proposed head-pose estimation using coordinates of both eyes and a mouth with the origin of a nose. Experimental results indicated that the computational cost of our approach is low and our method has superior detection performance, in particular regarding factors that affect the appearance of faces, such as variation in illumination, poses, facial expressions, occlusion, makeup, beards, mustaches, and glasses. In addition to these factors, the face images may be large or small and the details of face parts may be clearly visible or not. We also give a general presentation of the possible application areas and the problems associated with face detection. © 2016 American Scientific Publishers All rights reserved.","Cuckoo Search Algorithm (CS); Discrete Cosine Transform (DCT); Discrete Wavelet Transform (DWT); Face Recognition (FR); Facial Feature"
"Sajjad M., Ahn C.-W., Jung J.-W.","Iris image enhancement for the recognition of non-ideal iris images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964848287&doi=10.3837%2ftiis.2016.04.025&partnerID=40&md5=314d40ff1d2a34f024afff3176782165","Iris recognition for biometric personnel identification has gained much interest owing to the increasing concern with security today. The image quality plays a major role in the performance of iris recognition systems. When capturing an iris image under uncontrolled conditions and dealing with non-cooperative people, the chance of getting non-ideal images is very high owing to poor focus, off-angle, noise, motion blur, occlusion of eyelashes and eyelids, and wearing glasses. In order to improve the accuracy of iris recognition while dealing with non-ideal iris images, we propose a novel algorithm that improves the quality of degraded iris images. First, the iris image is localized properly to obtain accurate iris boundary detection, and then the iris image is normalized to obtain a fixed size. Second, the valid region (iris region) is extracted from the segmented iris image to obtain only the iris region. Third, to get a well-distributed texture image, bilinear interpolation is used on the segmented valid iris gray image. Using contrast-limited adaptive histogram equalization (CLAHE) enhances the low contrast of the resulting interpolated image. The results of CLAHE are further improved by stretching the maximum and minimum values to 0–255 by using histogram-stretching technique. The gray texture information is extracted by 1D Gabor filters while the Hamming distance technique is chosen as a metric for recognition. The NICE-II training dataset taken from UBRIS.v2 was used for the experiment. Results of the proposed method outperformed other methods in terms of equal error rate (EER). © 2016 KSII.","Bi-linear interpolation; Contrast limited adaptive histogram equalization; Iris image enhancement; Iris recognition; Non-ideal iris images"
"Alonso-Fernandez F., Bigun J.","Periocular biometrics: Databases, algorithms and directions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965104294&doi=10.1109%2fIWBF.2016.7449688&partnerID=40&md5=a6eb23d48469b48850896cba0508f873","Periocular biometrics has been established as an independent modality due to concerns on the performance of iris or face systems in uncontrolled conditions. Periocular refers to the facial region in the eye vicinity, including eyelids, lashes and eyebrows. It is available over a wide range of acquisition distances, representing a trade-off between the whole face (which can be occluded at close distances) and the iris texture (which do not have enough resolution at long distances). Since the periocular region appears in face or iris images, it can be used also in conjunction with these modalities. Features extracted from the periocular region have been also used successfully for gender classification and ethnicity classification, and to study the impact of gender transformation or plastic surgery in the recognition performance. This paper presents a review of the state of the art in periocular biometric research, providing an insight of the most relevant issues and giving a thorough coverage of the existing literature. Future research trends are also briefly discussed. © 2016 IEEE.","Databases; Features; Periocular biometrics; Segmentation; Soft-biometrics"
"Weng R., Lu J., Tan Y.-P.","Robust Point Set Matching for Partial Face Recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962781375&doi=10.1109%2fTIP.2016.2515987&partnerID=40&md5=c0b579fa108ad13ede66b8fbd5ea8714","Over the past three decades, a number of face recognition methods have been proposed in computer vision, and most of them use holistic face images for person identification. In many real-world scenarios especially some unconstrained environments, human faces might be occluded by other objects, and it is difficult to obtain fully holistic face images for recognition. To address this, we propose a new partial face recognition approach to recognize persons of interest from their partial faces. Given a pair of gallery image and probe face patch, we first detect keypoints and extract their local textural features. Then, we propose a robust point set matching method to discriminatively match these two extracted local feature sets, where both the textural information and geometrical information of local features are explicitly used for matching simultaneously. Finally, the similarity of two faces is converted as the distance between these two aligned feature sets. Experimental results on four public face data sets show the effectiveness of the proposed approach. © 1992-2012 IEEE.","biometrics; Face recognition; feature alignment; feature set matching; image matching; partial face recognition"
"Liao S., Jain A.K., Li S.Z.","A Fast and Accurate Unconstrained Face Detector","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962088950&doi=10.1109%2fTPAMI.2015.2448075&partnerID=40&md5=3d8e875f2dc5d19b15ef0a66b4e1b0c9","We propose a method to address challenges in unconstrained face detection, such as arbitrary pose variations and occlusions. First, a new image feature called Normalized Pixel Difference (NPD) is proposed. NPD feature is computed as the difference to sum ratio between two pixel values, inspired by the Weber Fraction in experimental psychology. The new feature is scale invariant, bounded, and is able to reconstruct the original image. Second, we propose a deep quadratic tree to learn the optimal subset of NPD features and their combinations, so that complex face manifolds can be partitioned by the learned rules. This way, only a single soft-cascade classifier is needed to handle unconstrained face detection. Furthermore, we show that the NPD features can be efficiently obtained from a look up table, and the detection template can be easily scaled, making the proposed face detector very fast. Experimental results on three public face datasets (FDDB, GENKI, and CMU-MIT) show that the proposed method achieves state-of-the-art performance in detecting unconstrained faces with arbitrary pose variations and occlusions in cluttered scenes. © 1979-2012 IEEE.","AdaBoost; cascade classifier; normalized pixel difference; regression tree; Unconstrained face detection"
"Liu Q., Deng J., Tao D.","Dual sparse constrained cascade regression for robust face alignment","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009513508&doi=10.1109%2fTIP.2015.2502485&partnerID=40&md5=6a04da649792357955e922c29d3d651d","Localizing facial landmarks is a fundamental step in facial image analysis. However, the problem continues to be challenging due to the large variability in expression, illumination, pose, and the existence of occlusions in real-world face images. In this paper, we present a dual sparse constrained cascade regression model for robust face alignment. Instead of using the least-squares method during the training process of regressors, sparse constraint is introduced to select robust features and compress the size of the model. Moreover, sparse shape constraint is incorporated between each cascade regression, and the explicit shape constraints are able to suppress the ambiguity in local features. To improve the model's adaptation to large pose variation, face pose is estimated by five fiducial landmarks located by deep convolutional neuron network, which is used to adaptively design the cascade regression model. To the best of our best knowledge, this is the first attempt to fuse explicit shape constraint (sparse shape constraint) and implicit context information (sparse feature selection) for robust face alignment in the framework of cascade regression. Extensive experiments on nine challenging wild data sets demonstrate the advantages of the proposed method over the state-of-the-art methods. © 2015 IEEE.","Cascade regression; Robust face alignment; Sparse feature selection; Sparse shape constraint"
"Bellil W., Brahim H., Ben Amar C.","Gappy wavelet neural network for 3D occluded faces: detection and recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953638822&doi=10.1007%2fs11042-014-2294-6&partnerID=40&md5=e5d7d42e44edd21d1de8b6e4cc7bdd48","The first handicap in 3D faces recognizing under unconstrained problem is the largest variability of the visual aspect when we use various sources. This great variability complicates the task of identifying persons from their 3D facial scans and it is the most reason that bring to face detection and recognition of the major problems in pattern recognition fields, biometrics and computer vision. We propose a new 3D face identification and recognition method based on Gappy Wavelet Neural Network (GWNN) that is able to provide better accuracy in the presence of facial occlusions. The proposed approach consists of three steps: the first step is face detection. The second step is to identify and remove occlusions. Occluded regions detection is done by considering that occlusions can be defined as local face deformations. These deformations are detected by a comparison between the input facial test wavelet coefficients and wavelet coefficients of generic face model formed by the mean data base faces. They are beneficial for neighborhood relationships between pixels rotation, dilation and translation invariant. Then, occluded regions are refined by removing wavelet coefficient above a certain threshold. Finally, the last stage of processing and retrieving is made based on wavelet neural network to recognize and to restore 3D occluded regions that gathers the most. The experimental results on this challenging database demonstrate that the proposed approach improves recognition rate performance from 93.57 to 99.45 % which represents a competitive result compared to the state of the art. © 2014, Springer Science+Business Media New York.","3D face recognition; Wavelets; Gappy data; Occlusion detection; Wavelet neural network"
"Guo J., Xu J., Liu S., Huang D., Wang Y.","Occlusion-robust face detection using shallow and deep proposal based faster R-CNN","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992465104&doi=10.1007%2f978-3-319-46654-5_1&partnerID=40&md5=4954f079ce2860c060b92bea2ebf8396","As the first essential step of automatic face analysis, face detection always receives high attention. The performance of current state-of-the-art face detectors cannot fulfill the requirements in realworld scenarios especially in the presence of severe occlusions. This paper proposes a novel and effective approach to occlusion-robust face detection. It combines two major phases, i.e. proposal generation and classification. In the former, we combine both the proposals given by a coarseto- fine shallow pipeline and a Region Proposal Network (RPN) based deep one respectively, to generate a more comprehensive set of candidate regions. In the latter, we further decide whether the regions are faces using a well-trained Faster R-CNN. Experiments are conducted on the WIDER FACE benchmark, and the results clearly prove the competency of the proposed method at detecting occluded faces. © Springer International Publishing AG 2016.","Face detection; Faster R-CNN; Occlusion; Shallow and deep proposal"
"Luu K., Zhu C., Bhagavatula C., Le T.H.N., Savvides M.","A Deep learning approach to joint face detection and segmentation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978194723&doi=10.1007%2f978-3-319-25958-1_1&partnerID=40&md5=20f070afdaf73b5961d0bbd85315f08a","Robust face detection and facial segmentation are crucial pre-processing steps to support facial recognition, expression analysis, pose estimation, building of 3D facial models, etc. In previous approaches, the process of face detection and facial segmentation are usually implemented as sequential, mostly separated modules. In these methods, face detection algorithms are usually first implemented so that facial regions can be located in given images. Segmentation algorithms are then carried out to find the facial boundaries and other facial features, such as the eyebrows, eyes, nose, mouth, etc. However, both of these tasks are challenging due to numerous variations of face images in the wild, e.g. facial expressions, illumination variations, occlusions, resolution, etc. In this chapter, we present a novel approach to detect human faces and segment facial features from given images simultaneously. Our proposed approach performs accurate facial feature segmentation and demonstrates its effectiveness on images from two challenging face databases, i.e. Multiple Biometric Grand Challenge (MBGC) and Labeled Faces in the Wild (LFW). © Springer International Publishing Switzerland 2016.",
"Zhang Y., Lu Y., Wu H., Wen C., Ge C.","Face occlusion detection using cascaded convolutional neural network","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992446648&doi=10.1007%2f978-3-319-46654-5_79&partnerID=40&md5=ae80cc086d35be6e60c08ae8b32d4cdb","With the rise of crimes associated with ATM, face occlusion detection has gained more and more attention because it facilitates the surveillance system of ATM to enhance the safety by pinpointing disguised among customers and giving alarms when suspicious customer is found. Inspired by strong learning ability of deep learning from data and high efficient feature representation ability, this paper proposes a cascaded Convolutional Neural Network (CNN) based face occlusion detection method. In the proposed method, three cascaded CNNs are used to detect head, eye occlusion and mouth occlusion. Experimental results show that the proposed method is very effective on two test datasets. © Springer International Publishing AG 2016.","ATM; Cascaded convolutional neural network; Face occlusion detection"
"Mohanraj V., Vimalkumar M., Mithila M., Vaidehi V.","Robust Face Recognition System in Video using Hybrid Scale Invariant Feature Transform","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985961135&doi=10.1016%2fj.procs.2016.07.240&partnerID=40&md5=71faf098f82677a3fe9a183022dd1afa","Face recognition plays a significant role in the research field of biometric and computer vision. The important goal of an efficient Face Recognition (FR) system is to have negligible misclassification rate. In video-based face recognition system, the illumination and pose variation problems are predominant. Most of the efficient FR systems are developed for controlled or indoor environment, hence they fail to give accurate recognition in outdoor environment of different illumination variation. Other challenges include occlusion and facial expression. The illumination problem is handled by Histogram Equalization in existing methods. The original Scale Invariant Feature Transform (SIFT) also works well only for pose variation and fails to produce satisfactory results under varying illumination. Hence Hybrid Scale Invariant Feature Transform (HSIFT) with Weighting Factor in feature matching is proposed in this paper which uses a fixed facial landmark localization technique and orientation assignment of SIFT to extract illumination and pose invariant features. The extracted features are then matched using Fast Library for Approximation of Nearest Neighbor (FLANN). The proposed method has been implemented in OpenCV to give a recognition rate of 98% and 95.5% in YouTube celebrity and Extended Yale B dataset respectively. © 2016 The Authors. Published by Elsevier B.V.","Ensemble of regression trees; Face recognition; SIFT; Weighting factor"
"Shao L., Zhu R., Zhao Q.","Glasses detection using convolutional neural networks","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992446357&doi=10.1007%2f978-3-319-46654-5_78&partnerID=40&md5=0787df598b3152e491473b6bd93c8d69","Glasses detection plays an important role in face recognition and soft biometrices for person identification. However, automatic glasses detection is still a challenging problem under real application scenarios, because face variations, light conditions, and self-occlusion, have significant influence on its performance. Inspired by the success of Deep Convolutional Neural Networks (DCNN) on face recognition, object detection and image classification, we propose a glasses detection method based on DCNN. Specifically, we devise a Glasses Network (GNet), and pre-train it as a face identification network with a large number of face images. The pre-trained GNet is finally fine-tuned as a glasses detection network by using another set of facial images wearing and not wearing glasses. Evaluation experiments have been done on two public databases, Multi- PIE and LFW. The results demonstrate the superior performance of the proposed method over competing methods. © Springer International Publishing AG 2016.","Deep convolutional neural network; Deep learning; Glasses detection; GNet"
"Sang G., Li J., Zhao Q.","Pose-invariant face recognition via RGB-D images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956884806&doi=10.1155%2f2016%2f3563758&partnerID=40&md5=6bb8579f409c7c3865120caa5da90399","Three-dimensional (3D) face models can intrinsically handle large pose face recognition problem. In this paper, we propose a novel pose-invariant face recognition method via RGB-D images. By employing depth, our method is able to handle self-occlusion and deformation, both of which are challenging problems in two-dimensional (2D) face recognition. Texture images in the gallery can be rendered to the same view as the probe via depth. Meanwhile, depth is also used for similarity measure via frontalization and symmetric filling. Finally, both texture and depth contribute to the final identity estimation. Experiments on Bosphorus, CurtinFaces, Eurecom, and Kiwi databases demonstrate that the additional depth information has improved the performance of face recognition with large pose variations and under even more challenging conditions. © 2016 Gaoli Sang et al.",
"Deng Z., Li K., Zhao Q., Chen H.","Face landmark localization using a single deep network","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992459050&doi=10.1007%2f978-3-319-46654-5_8&partnerID=40&md5=6c3a2c7fda5aeb6e184613eb1f13dbd0","Existing Deep Convolutional Neural Network (DCNN) methods for Face Landmark Localization are based on Cascaded Networks or Tasks- Constrained Deep Convolutional Network (TCDCN), which are complicated and difficult to train. To solve this problem, this paper proposes a new Single Deep CNN (SDN). Unlike cascaded CNNs, SDN stacks three layer groups: each group consists of two convolutional layers and a max-pooling layer. This network structure can extract more global high-level features, which express the face landmarks more precisely. Extensive experiments show that SDN outperforms existing DCNN methods and is robust to large pose variation, lighting and even severe occlusion. While the network complexity is also reduced obviously compared to other methods. © Springer International Publishing AG 2016.","DCNN; Face landmark localization; SDN"
"Hollingsworth K., Bowyer K.W., Flynn P.J.","Useful features for human verification in near-infrared periocular images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995345816&doi=10.1016%2fj.imavis.2012.08.005&partnerID=40&md5=5044f6ee5971ea4740a06c4ca3f744d8","The periocular region is the part of the face immediately surrounding the eye, and researchers have recently begun to investigate how to use the periocular region for recognition. Understanding how humans recognize faces helped computer vision researchers develop algorithms for face recognition. Likewise, understanding how humans analyze periocular images could benefit researchers developing algorithms for periocular recognition. We conducted two experiments to determine how humans analyze periocular images. In these experiments, we presented pairs of images and asked volunteers to determine whether the two images showed eyes from the same subject or from different subjects. In the first experiment, subjects were paired randomly to create different-subject queries. Our volunteers correctly determined the relationship between the two images in 92% of the queries. In the second experiment, we considered multiple factors in forming different-subject pairs; queries were formed from pairs of subjects with the same gender and race, and with similar eye color, makeup, eyelash length, and eye occlusion. In addition, we limited the amount of time volunteers could view a query pair. On this harder experiment, the correct verification rate was 79%. We asked volunteers to describe what features in the images were helpful to them in making their decisions. In both experiments, eyelashes were reported to be the most helpful feature. © 2011.","Near-infrared light; Ocular biometrics; Periocular recognition"
"Feng S.","Robust face recognition under varying illumination and occlusion via single layer networks","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992449631&doi=10.1007%2f978-3-319-46654-5_11&partnerID=40&md5=186aa395baf1d5a3137edf4063e63edf","Feature extraction plays a significant role in face recognition, it is desired to extract robust feature to eliminate the effect of variations caused by illumination and occlusion. Motivated by convolutional architecture of deep learning and the advantages of KMeans algorithm in filters learning. In this paper, a simple yet effective face recognition approach is proposed, which consists of three components: convolutional filters learning, nonlinear transformation and feature pooling. Concretely, firstly, KMeans is employed to construct the convolutional filters quickly on preprocessed image patches. Secondly, hyperbolic tangent is applied for nonlinear transformation on the convoluted images. Thirdly, multi levels of spatial pyramid pooling is utilized to incorporate spatial geometry information of learned features. Recognition phase only requires an efficient linear regression classifier. Experimental results on two representative databases AR and ExtendedYaleB demonstrate strong robustness of our method against real disguise, illumination, block occlusion, as well as pixel corruption. © Springer International Publishing AG 2016.","Convolutional architecture; Face recognition; KMeans; Linear regression; Spatial pyramid pooling"
"Partala J., Fylakis A., Pramila A., Keskinarkaus A., Seppänen T.","Improving Robustness of Biometric Identity Determination with Digital Watermarking","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994571001&doi=10.1155%2f2016%2f6390741&partnerID=40&md5=bb23721671d07e1d06fae3463b8c3e58","The determination of an identity from noisy biometric measurements is a continuing challenge. In many applications, such as identity-based encryption, the identity needs to be known with virtually 100% certainty. The determination of identities with such precision from face images taken under a wide range of natural situations is still an unsolved problem. We propose a digital watermarking based method to aid face recognizers to tackle this problem in applications. In particular, we suggest embedding multiple face dependent watermarks into an image to serve as expert knowledge on the corresponding identities to identity-based schemes. This knowledge could originate, for example, from the tagging of those people on a social network. In our proposal, a single payload consists of a correction vector that can be added to the extracted biometric template to compile a nearly noiseless identity. It also supports the removal of a person from the image. If a particular face is censored, the corresponding identity is also removed. Based on our experiments, our method is robust against JPEG compression, image filtering, and occlusion and enables a reliable determination of an identity without side information. © 2016 Juha Partala et al.",
"Dou P., Zhang L., Wu Y., Shah S.K., Kakadiaris I.A.","Pose-robust face signature for multi-view face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962900920&doi=10.1109%2fBTAS.2015.7358788&partnerID=40&md5=b80000fb0790ba63c205feebd4e26bab","Despite the great progress achieved in unconstrained face recognition, pose variations still remain a challenging and unsolved practical issue. We propose a novel framework for multi-view face recognition based on extracting and matching pose-robust face signatures from 2D images. Specifically, we propose an efficient method for monocular 3D face reconstruction, which is used to lift the 2D facial appearance to a canonical texture space and estimate the self-occlusion. On the lifted facial texture we then extract various local features, which are further enhanced by the occlusion encodings computed on the self-occlusion mask, resulting in a pose-robust face signature, a novel feature representation of the original 2D facial image. Extensive experiments on two public datasets demonstrate that our method not only simplifies the matching of multi-view 2D facial images by circumventing the requirement for pose-adaptive classifiers, but also achieves superior performance. © 2015 IEEE.",
"Chen L., Ferryman J.","Combining 3D and 2D for less constrained periocular recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962888228&doi=10.1109%2fBTAS.2015.7358753&partnerID=40&md5=20a46a89c1a4eebb7ba03e56d9f8ff9a","Periocular recognition has recently become an active topic in biometrics. Typically it uses 2D image data of the periocular region. This paper is the first description of combining 3D shape structure with 2D texture. A simple and effective technique using iterative closest point (ICP) was applied for 3D periocular region matching. It proved its strength for relatively unconstrained eye region capture, and does not require any training. Local binary patterns (LBP) were applied for 2D image based periocular matching. The two modalities were combined at the score-level. This approach was evaluated using the Bosphorus 3D face database, which contains large variations in facial expressions, head poses and occlusions. The rank-1 accuracy achieved from the 3D data (80%) was better than that for 2D (58%), and the best accuracy (83%) was achieved by fusing the two types of data. This suggests that significant improvements to periocular recognition systems could be achieved using the 3D structure information that is now available from small and inexpensive sensors. © 2015 IEEE.",
"Azom V., Adewumi A., Tapamo J.-R.","Face and Iris biometrics person identification using hybrid fusion at feature and score-level","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962460827&doi=10.1109%2fRoboMech.2015.7359524&partnerID=40&md5=92c18f9435b2878d97b50de0a5e1cdf0","Face and Iris biometrics are amongst the studied unimodal systems by researchers over the past years due to their ease of acquisition and accuracy, respectively, during the recognition process. However unimodal systems are not perfect when deployed to real-world applications due to non-ideal conditions such as off-angle gaze, illumination, occlusion and variation in posing. These limitations have led to an increase of research in multi-biometrics. In recent times, researchers have worked on combining unimodal templates with different methods with each having to compensate for the shortcomings of the unimodal systems. In this work we present a hybridized fusion strategy that combines, three classifiers based on feature and score level fusion using a decision level fusion rule. We compare the recognition rate of the proposed method with other fusion methods in literature. We have obtained a recognition accuracy of 98.75%. The proposed method was validated using the ORL face and CASIA iris datasets. © 2015 IEEE.","Face recognition; Feature extraction; feature fusion and decision fusion; Iris recognition; Multimodal biometrics; Score fusion"
"Mery D., Bowyer K.","Automatic facial attribute analysis via adaptive sparse representation of random patches","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948121918&doi=10.1016%2fj.patrec.2015.05.005&partnerID=40&md5=206fe99c37f3c426fcb2fa606bc3ea2c","It is well known that some facial attributes -like soft biometric traits- can increase the performance of traditional biometric systems and help recognition based on human descriptions. In addition, other facial attributes, such as facial expressions, can be used in human-computer interfaces, image retrieval, talking heads and human emotion analysis. This paper addresses the problem of automated recognition of facial attributes by proposing a new general approach called Adaptive Sparse Representation of Random Patches (ASR+). The proposed method consists of two stages: in the learning stage, random patches are extracted from representative face images of each class (e.g., in gender recognition -a two-class problem-, images of females/males) in order to construct representative dictionaries. A stop list is used to remove very common words of the dictionaries. In the testing stage, random test patches of the query image are extracted, and for each non-stopped test patch a dictionary is built concatenating the 'best' representative dictionary of each class. Using this adapted dictionary, each non-stopped test patch is classified following the Sparse Representation Classification (SRC) methodology. Finally, the query image is classified by patch voting. Thus, our approach is able to learn a model for each recognition task dealing with a larger degree of variability in ambient lighting, pose, expression, occlusion, face size and distance from the camera. Experiments were carried out on eight face databases in order to recognize facial expression, gender, race, disguise and beard. Results show that ASR+ deals well with unconstrained conditions, outperforming various representative methods in the literature in many complex scenarios. © 2015 Elsevier B.V.","Expression recognition; Facial attribute analysis; Gender recognition; Race recognition; Soft biometrics; Sparse representations"
"Bellaaj M., Frikha Elleuch J., Sellami D., Khanfir Kallel I.","An Improved Iris Recognition System Based on Possibilistic Modeling","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968736716&doi=10.1145%2f2837126.2837156&partnerID=40&md5=35a899943c2605caaa2569aec6a538c9","The biometric systems face variability, incompleteness and insufficiency in data, which affects the performance of the recognition system. In iris recognition systems, several conditions cause different types of degradations on iris data such as the poor quality of the acquired pictures, the iris region which can be partially occluded due to light spots, or by lenses, eyeglasses, hair or eyelids, and adverse illuminations or contrasts. All of these limitations are open problems in the iris recognition and affect the performance of iris localization, iris feature extraction or decision making process, and appear as imperfections in the extracted signature. This paper addresses the use of the uncertainty theory for modeling iris system imperfections. Several comparative experiments were conducted on three subsets, namely CASIA.Ver4: synthetic, thousand and interval iris databases. Experimental results show that our proposed system, based on the possibility theory, improves the iris recognition system in terms ROC, AUC, FAR, FRR and PIN, compared to other iris identification systems. © 2015 ACM.","imperfections; Iris recognition system; possibilistic matching; possibility theory; probability intervals"
"Zehngut N., Juefei-Xu F., Bardia R., Pal D.K., Bhagavatula C., Savvides M.","Investigating the feasibility of image-based nose biometrics","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956643585&doi=10.1109%2fICIP.2015.7350853&partnerID=40&md5=285fcecca50e190f5780be7538971f50","The search for new biometrics is never ending. In this work, we investigate the use of image based nasal features as a biometric. In many real-world recognition scenarios, partial occlusions on the face leave the nose region visible (e.g. sunglasses). Face recognition systems often fail or perform poorly in such settings. Furthermore, the nose region naturally contain more invariance to expression than features extracted from other parts of the face. In this study, we extract discriminative nasal features using Kernel Class-Dependence Feature Analysis (KCFA) based on Optimal Trade-off Synthetic Discriminant Function (OTSDF) filters. We evaluate this technique on the FRGC ver2.0 database and the AR Face database, training and testing exclusively on nasal features and have compared the results to the full face recognition using KCFA features. We find that the between-subject dis-criminability in nasal features is comparable to that found in facial features. This shows that nose biometrics have a potential to support and boost biometric identification, that has largely been under utilized. Moreover, our extracted KCFA nose features have significantly outperformed the PittPatt face matcher which works with the original JPEG images on the AR facial occlusion database. This shows that nose biometrics can be used as a stand-alone biometric trait when the subjects are under occlusions. © 2015 IEEE.","Nose Biometrics"
"Wang Y., Tang Y.Y., Li L.","Robust Face Recognition via Minimum Error Entropy-Based Atomic Representation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959455957&doi=10.1109%2fTIP.2015.2492819&partnerID=40&md5=fccd2ebe3fb611e1797be1ebdc90d59c","Representation-based classifiers (RCs) have attracted considerable attention in face recognition in recent years. However, most existing RCs use the mean square error (MSE) criterion as the cost function, which relies on the Gaussianity assumption of the error distribution and is sensitive to non-Gaussian noise. This may severely degrade the performance of MSE-based RCs in recognizing facial images with random occlusion and corruption. In this paper, we present a minimum error entropy-based atomic representation (MEEAR) framework for face recognition. Unlike existing MSE-based RCs, our framework is based on the minimum error entropy criterion, which is not dependent on the error distribution and shown to be more robust to noise. In particular, MEEAR can produce discriminative representation vector by minimizing the atomic norm regularized Renyi's entropy of the reconstruction error. The optimality conditions are provided for general atomic representation model. As a general framework, MEEAR can also be used as a platform to develop new classifiers. Two effective MEE-based RCs are proposed by defining appropriate atomic sets. The experimental results on popular face databases show that MEEAR can improve both the recognition accuracy and the reconstructed results compared with the state-of-the-art MSE-based RCs. © 2015 IEEE.","Atomic representation; face recognition; information-theoretic learning; minimum error entropy"
"Feng Z.-H., Hu G., Kittler J., Christmas W., Wu X.-J.","Cascaded Collaborative Regression for Robust Facial Landmark Detection Trained Using a Mixture of Synthetic and Real Images with Dynamic Weighting","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959505180&doi=10.1109%2fTIP.2015.2446944&partnerID=40&md5=1dfdeb4fa789a0fb33a805c1451e6157","A large amount of training data is usually crucial for successful supervised learning. However, the task of providing training samples is often time-consuming, involving a considerable amount of tedious manual work. In addition, the amount of training data available is often limited. As an alternative, in this paper, we discuss how best to augment the available data for the application of automatic facial landmark detection. We propose the use of a 3D morphable face model to generate synthesized faces for a regression-based detector training. Benefiting from the large synthetic training data, the learned detector is shown to exhibit a better capability to detect the landmarks of a face with pose variations. Furthermore, the synthesized training data set provides accurate and consistent landmarks automatically as compared to the landmarks annotated manually, especially for occluded facial parts. The synthetic data and real data are from different domains; hence the detector trained using only synthesized faces does not generalize well to real faces. To deal with this problem, we propose a cascaded collaborative regression algorithm, which generates a cascaded shape updater that has the ability to overcome the difficulties caused by pose variations, as well as achieving better accuracy when applied to real faces. The training is based on a mix of synthetic and real image data with the mixing controlled by a dynamic mixture weighting schedule. Initially, the training uses heavily the synthetic data, as this can model the gross variations between the various poses. As the training proceeds, progressively more of the natural images are incorporated, as these can model finer detail. To improve the performance of the proposed algorithm further, we designed a dynamic multi-scale local feature extraction method, which captures more informative local features for detector training. An extensive evaluation on both controlled and uncontrolled face data sets demonstrates the merit of the proposed algorithm. © 2015 IEEE.","3D morphable model; cascaded collaborative regression; dynamic multi-scale local feature extraction; Facial landmark detection"
"Emersic Z., Peer P.","Toolbox for ear biometric recognition evaluation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961732880&doi=10.1109%2fEUROCON.2015.7313758&partnerID=40&md5=39300b3d86a97d5cfda77831bc521cf8","Ears are not subjected to facial expressions like faces are and do not require closer inspection like fingerprints do. However, there is a problem of occlusion, different lightning conditions and angles. These properties mean that the final outcome depends heavily on the selected database and classification procedures used in the evaluation process. Moreover, the results metrics are often difficult to compare, different sections of evaluation procedure mask the important steps, and frameworks that are usually build on-the-fly take time to develop. With our toolbox we propose the solution to those problems enabling faster development in the field of ear biometric recognition. © 2015 IEEE.",
"Juefei-Xu F., Pal D.K., Singh K., Savvides M.","A preliminary investigation on the sensitivity of COTS face recognition systems to forensic analyst-style face processing for occlusions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942466585&doi=10.1109%2fCVPRW.2015.7301316&partnerID=40&md5=2d938b738b309836a137308b170c864d","Modern day law enforcement banks heavily on the use of commercial off-the-shelf (COTS) face recognition systems (FRS) as a tool for biometric evaluation and identification. However, in many real-world scenarios, when the face of an individual is occluded or degraded in some way, commercial recognition systems fail to accept the face for evaluation or simply return unusable matched faces. In these kinds of cases, forensic experts rely on image processing techniques and tools, to make the face fit to be processed by the commercial recognition systems (e.g. use partial face images from another subject to fill in the occluded parts of the face of interest, or have a tight crop around the face). In this study, we evaluate the sensitivity of commercial recognition systems to such forensic techniques. More specifically, we study the change in the rank-1 identification result that is caused by forensic processing of faces-of-interest that are unusable by the commercial recognition systems. Further, forensic processing of such faces is more of an art and it is extremely difficult to process faces consistently such that there is a predictable effect on the rank-n identification result. This study is meant to serve as an evaluation of the effect of a few forensic techniques intended to allow commercial recognition systems to process and match face images that were otherwise unusable. Our results indicate that COTS FRS can be sensitive to the subjectivity in facial part swapping and cropping, resulting in inconsistencies in the identification rankings and similarity scores. © 2015 IEEE.","Databases; Face; Face recognition; Forensics; Law enforcement; Probes; Sensitivity"
"Patil H., Kothari A., Bhurchandi K.","3-D face recognition: features, databases, algorithms and challenges","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941419993&doi=10.1007%2fs10462-015-9431-0&partnerID=40&md5=c90b8821f623bcb40665d0010a316ef6","Face recognition is being widely accepted as a biometric technique because of its non-intrusive nature. Despite extensive research on 2-D face recognition, it suffers from poor recognition rate due to pose, illumination, expression, ageing, makeup variations and occlusions. In recent years, the research focus has shifted toward face recognition using 3-D facial surface and shape which represent more discriminating features by the virtue of increased dimensionality. This paper presents an extensive survey of recent 3-D face recognition techniques in terms of feature detection, classifiers as well as published algorithms that address expression and occlusion variation challenges followed by our critical comments on the published work. It also summarizes remarkable 3-D face databases and their features used for performance evaluation. Finally we suggest vital steps of a robust 3-D face recognition system based on the surveyed work and identify a few possible directions for research in this area. © 2015, Springer Science+Business Media Dordrecht.","3-D Face databases; 3-D faces; Biometrics; Classifiers; Face matching; Face recognition; Feature extraction"
"Ragashe M.U., Goswami M.M., Raghuwanshi M.M.","Approach towards real time face recognition in streaming video under partial occlusion","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959097692&doi=10.1109%2fISCO.2015.7282394&partnerID=40&md5=356fb4751af63bbf6f0d38c9eb7cb57e","Security system basically relies on biometrics. which gain vital importance for implementing a security systems. Biometrics such as iris, fingerprints, face, etc. Among this biometrics face is most prominent and trust worthy for implementing security system. It plays a vital role in identification and verification in various security based system. Face recognition is widely considered as one of the most promising biometric techniques. It allows high recognition rates without being too intrusive. Generally face recognition is used for two primary tasks: 1. verification (one-to-one matching. 2. Identification (one-to-many matching): Many approaches has been presented to solve the problem of face recognition in still images but a very less work is carried on face recognition in streaming video under uncontrolled condition. This paper illustrates various issues on face recognition in streaming video under, partial occlusion. Occlusion refers to any hindrance in the view of face. Occlusion can be natural and artificial. Natural occlusion refers to the facade of the face image which is differ from original face image caused due to natural calamity or disasters. whereas artificial occlusion refers to the artificial blockage of intentionally covering the face image's view by artificial accessories like sunglasses, makeup, hair wrapping, hands, scarf's, etc. Further on the basis of face recognition approach in presence of partial occlusion a real-time system for recognizing faces in a video stream provided by a surveillance camera was implemented, having real-time face detection. © 2015 IEEE.","biometrics; detection; face recognition; partial occlusion; surveillance"
"Soldera J., Alberto Ramirez Behaine C., Scharcanski J.","Customized Orthogonal Locality Preserving Projections with Soft-Margin Maximization for Face Recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939240937&doi=10.1109%2fTIM.2015.2415012&partnerID=40&md5=5da1b2903ac0b5765bc29f54107f6a31","Face recognition still is a challenging task since face images may be affected by changes in the scene, such as in head pose, face expression, or illumination. In addition, face pattern representation often requires several dimensions, which poses additional challenges for face recognition. We propose a novel face recognition method based on projections of high-dimensional face image representations into lower dimensionality and highly discriminative spaces. This is achieved by a modified orthogonal locality preserving projection (OLPP) method that uses a customized locality definition scheme to preserve the face class structure in the lower dimensionality face feature space. The proposed method can work with sparse and dense face image representations (i.e., it can use subsets or all face image pixels) and tends to be robust to data outliers and noise. Besides, we introduce a sparse representation using interpolated landmarks, designed to preserve important details in high-resolution color face images (e.g., eyes), and compensate for uncertainties in landmark positioning during face image feature extraction. The face images are classified in this lower dimensionality feature space using a trained soft-margin support vector machine, so it performs better than the nearest neighbor rule used in the typical OLPP method. A set of experiments was designed to evaluate the proposed scheme under various conditions found in practice (such as changes in head pose, face expression, illumination, and in the presence of occlusion artifacts). The experimental results were obtained using five challenging public face databases (namely, Poznan University of Technology, Fundação Educacional Inaciana, Facial Recognition Technology, Yale, and Our Database of Faces). These experiments suggest that our sparse representation for high-resolution face color images, integrated to the proposed lower dimensionality feature space and classification scheme, tends to obtain higher accuracy values than those obtained using typical sparse and dense representations for the same face images in grayscale. To evaluate the generality of our lower dimensionality feature space and classification scheme, additional tests using full low-resolution grayscale face images were performed, as often used in face recognition (e.g., typical OLPP method). Our experiments suggest that the proposed approach can also provide higher accuracy values than comparable state-of-the-art methods available in the literature when using full low-resolution grayscale face images (i.e., dense representations). © 1963-2012 IEEE.","Biometrics; face recognition; pattern recognition; subspace methods; support vector machines (SVMs)."
"Voynichka I.V., Megherbi D.B.","Analysis of the effect of using non-composite multi-channel raw color images on face recognition accuracy with arbitrary large off-the-plane rotations","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955451148&doi=10.1109%2fTHS.2015.7225314&partnerID=40&md5=6d7f78d7c7b8fa1dc9fd711502828ae1","The need for a solution capable of identifying individuals from a distance, possibly wearing a disguise and in a crowded and busy environment is steadily increasing in many homeland security applications. The use of face recognition techniques has unique advantages when compared to other biometric methodologies - face images can be obtained from a distance and without the cooperation of the subject. A recent example demonstrating the growing need for such solution are the videos released by some terrorist organizations where the suspect's face is occluded with only the eyes being visible. Research has yielded several state-of-the-art algorithms but their accuracy is greatly lowered in the presence of various factors. Face recogition with arbitrary large face off-the-plane rotation remains one very challenging and open research problem. In order to build better face recognition algorithms, it is important to identify and analyze what and how factors affect the accuracy of said algorithms so these methods can be improved and made more robust. In our previous work we presented how factors such as image registration, number and type of training templates and the presence of varying amount of partial face information that can be used to improve the performance of three very popular widely used face recognition algorithms. In this paper, we examine how using multi-channel color images instead of their one-channel grayscale/color composite improves face recognition accuracy in the challenging case when face arbitrary large off-the-plane rotation is present. We demonstrate the improvement to face recognition accuracy through the very popular and widely used Eigenface-based, Fisherface-based and Direct Correlation-based algorithms. Our findings and experimental results with the data, show that when using frontal-facing images as external test images with frontal-facing images as training set images, the additional information contained in the multi-channel color images does not improve the composite gray-scale face recogntition accuracy. However, in the case where the algorithms are trained using only images with slight or considerable off-the-plane rotation, and externally tested either on frontal-facing images or images with arbitrary off-the-plane rotation, the information provided by the multi-channel color images boosts the face recognition accuracy for all three recognition algorithms. © 2015 IEEE.","Biometrics; Computational Intelligence; Computer and Machine Vision; Correlation-based Face Recognition; Digital Image Processing; Eigenfaces; Face Recognition; Fisher-faces; Machine Learning"
"Matzner S., Heredia-Langner A., Amidan B., Boettcher E.J., Lochtefeld D., Webb T.","Standoff human identification using body shape","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955447081&doi=10.1109%2fTHS.2015.7225300&partnerID=40&md5=b8a216da59755092d48e0c66a153fb7d","The ability to identify individuals is a key component of maintaining safety and security in public spaces and around critical infrastructure. Monitoring an open space is challenging because individuals must be identified and re-identified from a standoff distance non-intrusively, making methods like fingerprinting and even facial recognition impractical. We propose using body shape features as a means for identification from standoff sensing, either complementing other identifiers or as an alternative. An important challenge in monitoring open spaces is reconstructing identifying features when only a partial observation is available, because of the view-angle limitations and occlusion or subject pose changes. To address this challenge, we investigated the minimum number of features required for a high probability of correct identification, and we developed models for predicting a key body feature - height - from a limited set of observed features. We found that any set of nine randomly selected body measurements was sufficient to correctly identify an individual in a dataset of 4041 subjects. For predicting height, anthropometric measures were investigated for correlation with height. Their correlation coefficients and associated linear models were reported. These results - a sufficient number of features for identification and height prediction from a single feature - contribute to developing systems for standoff identification when views of a subject are limited. © 2015 IEEE.","anthropometrics; biometrics; feature selection"
"Kokila S., Yogameena B.","Face recognition based person specific identification for video surveillance applications","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960953125&doi=10.1145%2f2791405.2791454&partnerID=40&md5=220049168d6bd169eacf38a02740927a","Face detection is an important aspect for applications like biometrics, video surveillance and human computer interaction. Videos provide abundant information and also that can be leveraged by temporal variations in pose, expression changes and occlusion. These challenging problems motivate to identify the specific person by face recognition for video surveillance applications. This paper presents face detection and recognition algorithm to identify/recognize the wanted person in a surveillance video. First, face detection is done by 'Viola-Jones' algorithm. Subsequently, the detected face has been cropped to recognize the specific person's face. For the cropped faces, clustering is applied to cluster the face parts. For the detected face parts HOG and LBP features are obtained. Existing approaches use Histogram of Oriented Gradients (HOG) and Local Binary Pattern (LBP) separately to recognize face in static images. The contribution of the work is to implement HOG and LBP for surveillance video and combine both the features to address the issues such as pose variations, illumination changes, expression changes and occlusion for face recognition. SVM classifier is used to classify the weak and strong features and strong features are used to recognize the person. The proposed algorithm has been tested on various datasets and its performance is found to be good in most cases. Experimental results show that the method of detection and recognition achieves very encouraging results with good accuracy and simple computations. © 2015 ACM.","Face detection; Person identification; Recognition; Surveillance; Video"
"Ismail A.I., Ali H.S., Farag F.A.","Efficient enhancement and matching for iris recognition using SURF","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964059456&doi=10.1109%2fNSITNSW.2015.7176409&partnerID=40&md5=b4606d35ec6d0d577b334cd9077089d7","Iris recognition is gaining more attention and the development of the field is increasing rapidly. This paper presents a complete iris recognition system. The iris features are obtained using Speeded Up Robust Features (SURF) after enhancing the image using Contrast Limited Adaptive Histogram Equalization (CLAHE). A novel matching algorithm based on applying fusion rules at different levels is proposed. The algorithm has the advantage of reduced data storage and fast matching. It can also handle efficiently the problem of rotation, scaling, illumination variation and occlusions. The proposed algorithm is implemented and tested using CASIA (V4) database. The recognition accuracies obtained are 99% using left images and 99.5% using right images. Results show that fusion of right and left images scores increases the recognition accuracy. The recognition accuracies obtained after fusion are 99.5% and 100% using minimum and sum rules respectively. Moreover, the proposed algorithm has an excellent robustness with respect to increasing the number of subjects. © 2015 IEEE.","Contrast Limited Adaptive Histogram Equalization; Image Warping; Iris Recognition; Recognition Accuracy; Score Fusion; SURF"
"Yang H., He X., Jia X., Patras I.","Robust face alignment under occlusion via regional predictive power estimation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929468961&doi=10.1109%2fTIP.2015.2421438&partnerID=40&md5=f14e7491a5052379c3cef1740d889c30","Face alignment has been well studied in recent years, however, when a face alignment model is applied on facial images with heavy partial occlusion, the performance deteriorates significantly. In this paper, instead of training an occlusion-aware model with visibility annotation, we address this issue via a model adaptation scheme that uses the result of a local regression forest (RF) voting method. In the proposed scheme, the consistency of the votes of the local RF in each of several oversegmented regions is used to determine the reliability of predicting the location of the facial landmarks. The latter is what we call regional predictive power (RPP). Subsequently, we adapt a holistic voting method (cascaded pose regression based on random ferns) by putting weights on the votes of each fern according to the RPP of the regions used in the fern tests. The proposed method shows superior performance over existing face alignment models in the most challenging data sets (COFW and 300-W). Moreover, it can also estimate with high accuracy (72.4% overlap ratio) which image areas belong to the face or nonface objects, on the heavily occluded images of the COFW data set, without explicit occlusion modeling. © 2015 IEEE.","cascaded pose regression; Face alignment; model adaptation; occlusion; random forest"
"Zhang H., Patel V.M., Chellappa R.","Robust multimodal recognition via multitask multivariate low-rank representations","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944909080&doi=10.1109%2fFG.2015.7163146&partnerID=40&md5=472e84f35a4f5fc4670067b264c541e9","We propose multi-task, multivariate low-rank representation-based methods for multimodal biometrics recognition. Our methods can be viewed as a generalized version of multivariate low-rank regression, where low-rank representation across all the modalities is imposed. One of our methods takes into account coupling information among different biometric modalities simultaneously by enforcing the common low-rank representation within each biometric's observations. We further modify our methods by including a background occlusion term that is assumed to be sparse. Alternating direction method of multipliers is proposed to solve the proposed optimization problems. Extensive experiments using face and touch gesture dataset show that our method compares favorably with other feature level fusion-based methods. © 2015 IEEE.",
"Li H., Huang D., Morvan J.-M., Wang Y., Chen L.","Towards 3D Face Recognition in the Real: A Registration-Free Approach Using Fine-Grained Matching of 3D Keypoint Descriptors","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939949330&doi=10.1007%2fs11263-014-0785-6&partnerID=40&md5=e89019b8bd090159f9b7875702ccf3e6","Registration algorithms performed on point clouds or range images of face scans have been successfully used for automatic 3D face recognition under expression variations, but have rarely been investigated to solve pose changes and occlusions mainly since that the basic landmarks to initialize coarse alignment are not always available. Recently, local feature-based SIFT-like matching proves competent to handle all such variations without registration. In this paper, towards 3D face recognition for real-life biometric applications, we significantly extend the SIFT-like matching framework to mesh data and propose a novel approach using fine-grained matching of 3D keypoint descriptors. First, two principal curvature-based 3D keypoint detectors are provided, which can repeatedly identify complementary locations on a face scan where local curvatures are high. Then, a robust 3D local coordinate system is built at each keypoint, which allows extraction of pose-invariant features. Three keypoint descriptors, corresponding to three surface differential quantities, are designed, and their feature-level fusion is employed to comprehensively describe local shapes of detected keypoints. Finally, we propose a multi-task sparse representation based fine-grained matching algorithm, which accounts for the average reconstruction error of probe face descriptors sparsely represented by a large dictionary of gallery descriptors in identification. Our approach is evaluated on the Bosphorus database and achieves rank-one recognition rates of 96.56, 98.82, 91.14, and 99.21 % on the entire database, and the expression, pose, and occlusion subsets, respectively. To the best of our knowledge, these are the best results reported so far on this database. Additionally, good generalization ability is also exhibited by the experiments on the FRGC v2.0 database. © 2014, Springer Science+Business Media New York.","3D keypoint descriptors; Expression, pose and occlusion; Fine-grained matching; Registration-free 3D face recognition"
"Arigbabu O.A., Ahmad S.M.S., Adnan W.A.W., Yussof S.","Recent advances in facial soft biometrics","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928707776&doi=10.1007%2fs00371-014-0990-x&partnerID=40&md5=f5b39204e664164ae689b2b330abba1e","Face as a biometric attribute has been extensively studied over the past few decades. Even though, satisfactory results are already achieved in controlled environments, the practicality of face recognition in realistic scenarios is still limited by several challenges, such as, expression, pose, occlusion, etc. Recently, the research direction is concentrating on the prospects of complementing face recognition systems with facial soft biometric traits. The ease of extracting facial soft biometrics under several varying conditions has mainly resulted in the ability of using the traits to, either improve the performance of traditional face recognition systems, or performing recognition solely based on many facial soft biometrics. This paper presents state-of-the-art techniques in facial soft biometrics research by describing the type of traits, feature extraction methods, and the application domains. It indicates the most recent and valuable results attained, while also highlighting some possible future scientific research directions to be investigated. © 2014, Springer-Verlag Berlin Heidelberg.","Face recognition; Image retrieval; Measured descriptor; Semantic descriptor; Soft biometrics"
"Monteiro J.C., Cardoso J.S.","A cognitively-motivated framework for partial face recognition in unconstrained scenarios","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921465223&doi=10.3390%2fs150101903&partnerID=40&md5=32294adfd595b9b0355200a5deaddcdf","Humans perform and rely on face recognition routinely and effortlessly throughout their daily lives. Multiple works in recent years have sought to replicate this process in a robust and automatic way. However, it is known that the performance of face recognition algorithms is severely compromised in non-ideal image acquisition scenarios. In an attempt to deal with conditions, such as occlusion and heterogeneous illumination, we propose a new approach motivated by the global precedent hypothesis of the human brain’s cognitive mechanisms of perception. An automatic modeling of SIFT keypoint descriptors using a Gaussian mixture model (GMM)-based universal background model method is proposed. A decision is, then, made in an innovative hierarchical sense, with holistic information gaining precedence over a more detailed local analysis. The algorithm was tested on the ORL, ARand Extended Yale B Face databases and presented state-of-the-art performance for a variety of experimental setups. © 2015 by the authors; licensee MDPI, Basel, Switzerland.","Biometrics; Face recognition; Gaussian mixture models; Partial data; Universal background model"
"Ragashe M.U., Goswami M.M., Raghuwanshi M.M.","A face recognition technique for partial occluded faces in streaming video","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942805096&partnerID=40&md5=8b8a9c2dd43244342715c9a859c18e92","Security system basically relies on biometrics. which gain vital importance for implementing a security systems. Biometrics such as iris, fingerprints, face, etc. Among this biometrics face is most prominent and trust worthy for implementing security system. It plays a vital role in identification and verification in various security based system.Face recognition is widely considered as one of the most promising biometric techniques. It allows high recognition rates without being too intrusive. Generally face recognition is used for two primary tasks:1.verification (one-to-one matching. 2.Identification (one-to-many matching): Many approaches has been presented to solve the problem of face recognition in still images but a very less work is carried on face recognition in streaming video under uncontrolled condition. While face detection seems a solved problem under general conditions, most state-of-the-art systems degrade rapidly when faces are partially occluded by other objects. This paper presents a solution to detect partially occluded faces by reasonably modifying the AdaBoost-based face detector. Our basic idea is that the weak classifiers in the AdaBoost-based face detector, each corresponding to a Haar-like feature, are inherently a patch-based model. Therefore, one can divide the whole face region into multiple patches, and map those weak classifiers to the patches. The weak classifiers belonging to each patch are re-formed to be a new classifier to determine if it is a valid face patch—without occlusion. Finally, we combine all of the valid face patches by assigning the patches with different weights to make the final decision whether the input sub-window is a face. The experimental results show that the proposed method is promising for the detection of occluded faces. © Research India Publications.","Biometrics; Detection; Partial occlusion; Patch; Surveillance; Terms—face recognition"
"Haghighat M., Abdel-Mottaleb M., Alhalabi W.","Computationally efficient statistical face model in the feature space","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937924440&doi=10.1109%2fCIBIM.2014.7015453&partnerID=40&md5=948e99b0b8f7839fe315c0575279d33f","In this paper, we present a computationally efficient statistical face modeling approach. The efficiency of our proposed approach is the result of mathematical simplifications in the core formula of a previous face modeling method and the use of the singular value decomposition. In order to reduce the errors in our resulting models, we preprocess the facial images to normalize for pose and illumination and remove little occlusions. Then, the statistical face models for the enrolled subjects are obtained from the normalized face images. The effects of the variations in pose, facial expression, and illumination on the accuracy of the system are studied. Experimental results demonstrate the reduction in the computational complexity of the new approach and its efficacy in modeling the face images. © 2014 IEEE.",
"Cheney J., Klein B., Jain A.K., Klare B.F.","Unconstrained face detection: State of the art baseline and challenges","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943271008&doi=10.1109%2fICB.2015.7139089&partnerID=40&md5=e255afa0abb309d53971e30994d39c43","A large scale study of the accuracy and efficiency of face detection algorithms on unconstrained face imagery is presented. Nine different face detection algorithms are studied, which are acquired through either government rights, open source, or commercial licensing. The primary data set utilized for analysis is the IAPRA Janus Benchmark A (IJB-A), a recently released unconstrained face detection and recognition dataset which, at the time of this study, contained 67,183 manually localized faces in 5,712 images and 20,408 video frames. The goal of the study is to determine the state of the art in face detection with respect to unconstrained imagery which is motivated by the saturation of recognition accuracies on seminal unconstrained face recognition datasets which are filtered to only contain faces detectable by a commodity face detection algorithm. The most notable finding from this study is that top performing detectors still fail to detect the vast majority of faces with extreme pose, partial occlusion, and/or poor illumination. In total, over 20% of faces fail to be detected by all nine detectors studied. The speed of the detectors was generally correlated with accuracy: faster detectors were less accurate than their slower counterparts. Finally, key considerations and guidance is provided for performing face detection evaluations. All software using these methods to conduct the evaluations and plot the accuracies are made available in the open source. © 2015 IEEE.",
"Uzair M., Mahmood A., Mian A., McDonald C.","Periocular region-based person identification in the visible, infrared and hyperspectral imagery","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922537253&doi=10.1016%2fj.neucom.2014.07.049&partnerID=40&md5=b092bc01c64c2ccd1d0d4d99c17bacc0","Face recognition performance degrades significantly under occlusions that occur intentionally or unintentionally due to head gear or hair style. In many incidents captured by surveillance videos, the offenders cover their faces leaving only the periocular region visible. We present an extensive study on periocular region based person identification in video. While, previous techniques have handpicked a single best frame from videos, we formulate, for the first time, periocular region based person identification in video as an image-set classification problem. For thorough analysis, we perform experiments on periocular regions extracted automatically from RGB videos, NIR videos and hyperspectral image cubes. Each image-set is represented by four heterogeneous feature types and classified with six state-of-the-art image-set classification algorithms. We propose a novel two stage inverse Error Weighted Fusion algorithm for feature and classifier score fusion. The proposed two stage fusion is superior to single stage fusion. Comprehensive experiments were performed on four standard datasets, MBGC NIR and visible spectrum (Phillips et al., 2005), CMU Hyperspectral (Denes et al., 2002) and UBIPr (Padole and Proenca, 2012). We obtained average rank-1 recognition rates of 99.8, 98.5, 97.2, and 99.5% respectively which are significantly higher than the existing state of the art. Our results demonstrate the feasibility of image-set based periocular biometrics for real world applications. © 2014 Elsevier B.V.","Face and iris biometric; Hyperspectral face recognition; Image-set classification; Partial facial occlusion; Periocular biometric"
"Banupriya K., Poornima S.","Face detection from hazy samples","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942437215&partnerID=40&md5=c01c19d4dda70281936e314c0d08b9ed","Biometrics plays a vital role in identifying an individual through their unique features such as iris, face, voice, etc. Face has been most commonly used by humans and many real time applications as his/her first feature for identification or verification. Many research works in face detection and recognition from various inputs like frontal face, noisy face, side face, different emotions, expressions, occlusions has been presented in the literature. However, it is very hard to identify/verify an individual having partial features of face with artificial occlusions such as sunglass, scarf, bandage and hair. We cannot expect a clear visible sample input always. Unconstrained inputs are focused more in the recent research works. In circumstances it is difficult and necessary to find the face region when it is covered or hidden in the sample. This paper presents a robust way of detecting the face region from hazy image samples with different occlusion. The goal of this work is to detect the face region from hazy sample and imply it for recognition of an individual. © Research India Publications.","Biometrics; Dark channel prior; Dehazing; Detection; Viola-Jones"
"Chen X., Li W., Liu Z., Zhou Z.","Fractional low-order independent component analysis for face recognition robust to partial occlusion","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922818865&doi=10.1109%2fISBAST.2014.7013084&partnerID=40&md5=90f1c5a499609df546d04004dbe6fee6","As biometric vector may not follow the Gaussian distribution under complex light, pose and accessories, systems often yield unacceptable performance when subjected to impulsive, non-Gaussian noise. This paper adopts signal symmetric alpha stable distribution theory to construct fractional low-order independent component analysis algorithm (FLOD-ICA) and applied FLOD-ICA to solve the partial occlusion face recognition problem. Experiments verified that our proposed scheme is effective for face recognition under partial occlusion. © 2014 IEEE.","face recognition; fractional low-order independent component analysis; Gaussian noise; symmetric alpha stable distribution"
"Struc V., Krizaj J., Dobrisek S.","Modest face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936131517&doi=10.1109%2fIWBF.2015.7110235&partnerID=40&md5=843449100cd066475318414920379c7e","The facial imagery usually at the disposal for forensics investigations is commonly of a poor quality due to the unconstrained settings in which it was acquired. The captured faces are typically non-frontal, partially occluded and of a low resolution, which makes the recognition task extremely difficult. In this paper we try to address this problem by presenting a novel framework for face recognition that combines diverse features sets (Gabor features, local binary patterns, local phase quantization features and pixel intensities), probabilistic linear discriminant analysis (PLDA) and data fusion based on linear logistic regression. With the proposed framework a matching score for the given pair of probe and target images is produced by applying PLDA on each of the four feature sets independently - producing a (partial) matching score for each of the PLDA-based feature vectors - and then combining the partial matching results at the score level to generate a single matching score for recognition. We make two main contributions in the paper: i) we introduce a novel framework for face recognition that relies on probabilistic MOdels of Diverse fEature SeTs (MODEST) to facilitate the recognition process and ii) benchmark it against the existing state-of-the-art. We demonstrate the feasibility of our MODEST framework on the FRGCv2 and PaSC databases and present comparative results with the state-of-the-art recognition techniques, which demonstrate the efficacy of our framework. © 2015 IEEE.","diversefeature sets; Face recognition; modest framework; probabilistic modeling"
"Jaliya U.K., Rathod J.M.","A novel preprocessing approach for human face recognition invariant to illumination","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924066851&doi=10.1007%2f978-81-322-2268-2_28&partnerID=40&md5=c41f503680c1d6e1ea3dd83cdbeeb091","Human Face recognition is one of the widely used biometric techniques for face identification and verification. It includes several subproblems like illumination variation, expression changes, aging, occlusion, and rotation of face images. Varying illumination is one of the well-known and challenging problems in human face recognition applications. In this paper, we proposed a novel approach to solve varying illumination problems in face images. The different stages include adaptive histogram equalization (AHE), Gaussian filtering, Log transform, difference of AHE+Gaussian filtering+Log image, and AHE+Log image, and then, we perform normalization. We are using principle component analysis (PCA) method for face recognition. The experimental results of proposed approach are compared with existing approaches, and it shows that our approach improves the performance of recognition under varying illumination conditions on Yale Face Database B. © 2015, Springer India.","Adaptive histogram equalization (AHE); Gaussian filter; Log filter; Principle component analysis (PCA); Yale face database B"
"Mery D., Bowyer K.","Recognition of facial attributes using adaptive sparse representations of random patches","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928778273&doi=10.1007%2f978-3-319-16181-5_59&partnerID=40&md5=dc6778543ea954f8d78161ecec3d5c3e","It is well known that some facial attributes –like soft biometric traits– can increase the performance of traditional biometric systems and help recognition based on human descriptions. In addition, other facial attributes –like facial expressions– can be used in human– computer interfaces, image retrieval, talking heads and human emotion analysis. This paper addresses the problem of automated recognition of facial attributes by proposing a new general approach called Adaptive Sparse Representation of Random Patches (ASR+). In the learning stage, random patches are extracted from representative face images of each class (e.g., in gender recognition –a two-class problem–, images of females/males) in order to construct representative dictionaries. In the testing stage, random test patches of the query image are extracted, and for each test patch a dictionary is built concatenating the ‘best’ representative dictionary of each class. Using this adapted dictionary, each test patch is classified following the Sparse Representation Classification (SRC) methodology. Finally, the query image is classified by patch voting. Thus, our approach is able to learn a model for each recognition task dealing with a larger degree of variability in ambient lighting, pose, expression, occlusion, face size and distance from the camera. Experiments were carried out on seven face databases in order to recognize facial expression, gender, race and disguise. Results show that ASR+ deals well with unconstrained conditions, outperforming various representative methods in the literature in many complex scenarios. © Springer International Publishing Switzerland 2015.","Facial expression recognition; Gender recognition; Race recognition; Soft biometrics; Sparse representation"
"Gao H., Ekenel H.K., Stiefelhagen R.","Combining view-based pose normalization and feature transform for cross-pose face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943272636&doi=10.1109%2fICB.2015.7139114&partnerID=40&md5=70542785796bfb1dfb9249c23d700009","Automatic face recognition across large pose changes is still a challenging problem. Previous solutions apply a transform in image space or feature space for normalizing the pose mismatch. For feature transform, the feature vector extracted on a probe facial image is transferred to match the gallery condition with regression models. Usually, the regression models are learned from paired gallery-probe conditions, in which pose angles are known or accurately estimated. The solution based on image transform is able to handle continuous pose changes, yet the approach suffers from warping artifacts due to misalignment and self-occlusion. In this work, we propose a novel approach, which combines the advantage of both methods. The algorithm is able to handle continuous pose mismatch in gallery and probe set, mitigating the impact of inaccurate pose estimation in feature-transform-based method. We evaluate the proposed algorithm on the FERET face database, where the pose angles are roughly annotated. Experimental results show that our proposed method is superior to solely image/feature transform methods, especially when the pose angle difference is large. © 2015 IEEE.",
"Li X., Tao Q., Zhao J., Mao Y., Zhan S.","Robust face detection based on enhanced local sensitive support vector machine","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950239310&doi=10.1007%2f978-3-319-25417-3_13&partnerID=40&md5=a4774b0140375265d0f9ba35be7d70aa","In recent years, local classifiers have obtained great success in classification task due to its powerful discriminating ability on local regions. Based on it, we employ a locality-sensitive SVM (LSSVM) to build a local model on each local region to solve the problem of large intra-class variances between different face images. On the other hand, the use of SVM with local kernels was presented. Compared with the conventional global kernel, it’s more robust since it can utilize the local features which are influenced only specific parts under partial occlusion. So in order to detect face effectively, we want to utilize the global and local features of face comprehensively. Thus we combine the global and local kernels and apply the combination kernel to the LSSVM algorithm, proposing a robust face detection algorithm. Extensive experiments on the widely used CMU+MIT dataset and FDDB dataset demonstrate the robustness and validity of our algorithm. © Springer International Publishing Switzerland 2015.","Face detection; Kernel combination; Local classifier; Support vector machine"
"Shah J.H., Sharif M., Raza M., Murtaza M., Saeed-Ur-rehman","Robust face recognition technique under varying illumination","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936750747&partnerID=40&md5=42c3fdb5208a613624368fc2d14c01cf","Face recognition is one of a complex biometrics in the field of pattern recognition due to the constraints imposed by variation in the appearance of facial images. These changes in appearance are affected by variation in illumination, expression or occlusions etc. Illumination can be considered a complex problem in both indoor and outdoor pattern matching. Literature studies have revealed that two problems of textural based illumination handling in face recognition seem to be very common. Firstly, textural values are changed during illumination normalization due to increase in the contrast that changes the original pixels of face. Secondly, it minimizes the distance between inter-classes which increases the false acceptance rates. This paper addresses these issues and proposes a robust algorithm that overcomes these limitations. The limitations are resolved through transforming pixels from non-illumination side to illuminated side. It has been revealed that proposed algorithm produced better results as compared to existing related algorithms.","Face; Illumination; Pixels; Recognition; Textural features"
"Li X., Dou Y., Niu X., Xu J., Xiao R.","An Efficient Robust Eye Localization by Learning the Convolution Distribution Using Eye Template","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945395472&doi=10.1155%2f2015%2f709072&partnerID=40&md5=701a063e6af1eb11404f875da2f6387f","Eye localization is a fundamental process in many facial analyses. In practical use, it is often challenged by illumination, head pose, facial expression, occlusion, and other factors. It remains great difficulty to achieve high accuracy with short prediction time and low training cost at the same time. This paper presents a novel eye localization approach which explores only one-layer convolution map by eye template using a BP network. Results showed that the proposed method is robust to handle many difficult situations. In experiments, accuracy of 98% and 96%, respectively, on the BioID and LFPW test sets could be achieved in 10 fps prediction rate with only 15-minute training cost. In comparison with other robust models, the proposed method could obtain similar best results with greatly reduced training time and high prediction speed. © 2015 Xuan Li et al.",
"Khryashchev V., Priorov A., Stepanova O., Nikitin A.","Face recognition using local quantized patterns and Gabor filters","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936765952&doi=10.5194%2fisprsarchives-XL-5-W6-59-2015&partnerID=40&md5=0ef6585129791078aeba18fca04aa089","The problem of face recognition in a natural or artificial environment has received a great deal of researchers' attention over the last few years. A lot of methods for accurate face recognition have been proposed. Nevertheless, these methods often fail to accurately recognize the person in difficult scenarios, e.g. low resolution, low contrast, pose variations, etc. We therefore propose an approach for accurate and robust face recognition by using local quantized patterns and Gabor filters. The estimation of the eye centers is used as a preprocessing stage. The evaluation of our algorithm on different samples from a standardized FERET database shows that our method is invariant to the general variations of lighting, expression, occlusion and aging. The proposed approach allows about 20% correct recognition accuracy increase compared with the known face recognition algorithms from the OpenCV library. The additional use of Gabor filters can significantly improve the robustness to changes in lighting conditions.","Eye center localization; Face recognition; Gabor filters; Histogram comparing; Local quantized patterns"
"Tharwat A.","Personal identification using ears based on statistical features","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958167393&doi=10.5565%2frev%2felcvia.704&partnerID=40&md5=79707c4f33ec62d25b09fb1c3a7db33f","Biometrics is an automated method of recognizing a person based on physiological (e.g. face, iris, or retina) or behavioral (e.g. gait, signature, or dynamic keystrokes) characteristics. Ear recognition is one of the phys- iological biometrics' types that have been gaining interested in the recent years. Ear recognition, achieves good accuracy and has many advantages such as it is not affected by expressions, health, and it is more stable than many other biometrics. However, it has many challenges such as the pose of the face, lighting variation, occlusion with hair or clothes.",
"Fathy M.E., Patel V.M., Chellappa R.","Face-based Active Authentication on mobile devices","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946063794&doi=10.1109%2fICASSP.2015.7178258&partnerID=40&md5=5108490834aff53708ec5f7766cfa568","As mobile devices are becoming more ubiquitous, it becomes important to continuously verify the identity of the user during all interactions rather than just at login time. This paper investigates the effectiveness of methods for fully-automatic face recognition in solving the Active Authentication (AA) problem for smartphones. We report the results of face authentication using videos recorded by the front camera. The videos were acquired while the users were performing a number of tasks under three different ambient conditions to capture the type of variations caused by the 'mobility' of the devices. An inspection of these videos reveal a combination of favorable and challenging properties unique to smartphone face videos. In addition to variations caused by the mobility of the device, other challenges in the dataset include occlusion, occasional pose changes, blur and face/fiducial points localization errors. We evaluate still image and image set-based authentication algorithms using intensity features extracted around fiducial points. The recognition rates drop dramatically when enrollment and test videos come from different sessions. We will make the dataset and the computed features publicly available1 to help the design of algorithms that are more robust to variations due to factors mentioned above. © 2015 IEEE.","active authentication; biometrics recognition; Face recognition; mobile devices"
"Gu J., Liu L., Hu H.","Patch-based sparse dictionary representation for face recognition with single sample per person","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950252988&doi=10.1007%2f978-3-319-25417-3_15&partnerID=40&md5=c732626ec530695fe36c6a47cdbacefb","In this paper, we solve the problem of robust face recognition (FR) with single sample per person (SSPP). FR with SSPP is a very challenging task due to in such a scenario lacking of information to predict the variations of the query sample. We propose a novel method patch-based sparse dictionary representation (PSDR) to tackle the problem of various variations e.g. expressions, illuminations, corruption, occlusion and disguises in FR with SSPP. The key idea of our scheme is to combine a local sparse representation and a patch-based generic variation dictionary learning to predict the possible facial variations of query image and classification. To extract more feature information in classification, we adopt a patch-based method. Our experiments on Extended Yale B and AR databases show that our method outperforms the state-of-art approaches. © Springer International Publishing Switzerland 2015.","Local sparse representation; Patch-based generic variation dictionary"
"Upraity H., Arya K.V.","Efficient face recognition using morphological operations","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924233502&doi=10.1109%2fICIINFS.2014.7036567&partnerID=40&md5=32633cb949993a7f5480b9c2b9ea5007","There are many applications in which morphological operations play an important role. Morphology is a very useful mathematical tool or method to be used in image processing. It has many application like edge detection and extraction form images for specific purpose, feature extraction based on the boundary information etc. It has many advantages over other image processing tools like the complete outcome of the method lies in the selection of Structure Element(SE) and sequence of operations to be used. In face recognition also it has been used but only for binary images using the square shaped SE. Compensation for hair growth and cut have been assumed to be uniform which are not in real. There are also issues in image processing like corruption, occlusion, different facial expressions, poses which are tried to be solved by this method. A proposed methodology for a biométrie system is described in this work. In this work the morphological operations are used for feature extraction in face biometrics while solving the above mentioned issues. In the preprocessing basic morphological operations are performed using circular SE for denoising and smoothing image. Feature extraction is done using the existing method of sparse representation based classification. Feature matching is done using eigenfaces and after getting initial results images are treated with more morphological transformations iteratively for getting better results. Here motto is to increase the efficiency of the biométrie system for better results and less computation time using morphological operations. The morphological operations used here are based on the maximum and minimum intensity values so that they can be used for grayscale images. The system is tested on a customized database made from Indian face database (HT K) and Essex University database. © 2014 IEEE.","Biometrics; Face recognition; Feature extraction; Morphological operations; Morphology; Very high resolution images"
"Roy S., Shivakumara P., Mondal P., Raghavendra R., Pal U., Lu T.","A new multi-modal technique for bib number/text detection in natural images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984640031&doi=10.1007%2f978-3-319-24075-6_47&partnerID=40&md5=2bbba08d999771ca746a3a6fea0e49c8","The detection and recognition of racing bib number/text, which is printed on paper, cardboard tag, or t-shirt in natural images in marathon, race and sports, is challenging due to person movement, non-rigid surface, distortion by non-illumination, severe occlusions, orientation variations etc. In this paper, we present a multi-modal technique that combines both biometric and textual features to achieve good results for bib number/text detection. We explore face and skin features in a new way for identifying text candidate regions from input natural images. For each text candidate region, we propose to use text detection and recognition methods for detecting and recognizing bib numbers/texts, respectively. To validate the usefulness of the proposed multi-modal technique, we conduct text detection and recognition experiments before text candidate region detection and after text candidate region detection in terms of recall, precision and f-measure. Experimental results show that the proposed multi-modal technique outperforms the existing bib number detection method. © Springer International Publishing Switzerland 2015.","Bib number detection; Bib number recognition; Face detection; Multi-modal text detection; Skin detection; Text detection"
"Satyanarayana Tallapragada V.V., Rajan E.G.","Morphology based non ideal iris recognition using decision tree classifier","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929257899&doi=10.1109%2fPERVASIVE.2015.7087104&partnerID=40&md5=ad3c0ad6264b8cc7105638cbeea889e6","With the technological advancement security lapse is of major concern. Hence different techniques are adopted to provide better security. In this juncture, biometrics is widely used. Iris is one of such biometric which can provide high security when compared to other existing biometric traits. In this paper we propose a novel segmentation method for segmenting the iris part which is occluded and can be seen partially. Proposed segmentation has resulted in 90% accurate segmentation over MMU Iris database and with 1.8 seconds time for segmenting each iris. Further different features are extracted from the segmented iris part and are combined to form a feature vector. These are classified using decision tree classifier. Results show improved performance when compared to the existing techniques. © 2015 IEEE.","Decision Tree Classifier; Iris; MMU; Security; Segmentation"
"Punyani P., Gupta R.","Iris recognition system using morphology and sequential addition based grouping","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941249429&doi=10.1109%2fABLAZE.2015.7154976&partnerID=40&md5=1b54cca728c771817fb2e90749caab4e","Iris recognition is one of the most reliable and efficient methods for biometric identification because of its richness in texture information. The proposed method is based on Morphology and Sequential addition based grouping that reduces the complexity and improves the performance of the Iris recognition system. In this method, pupil localization is done using negative function and four neighbours so that any type of pupil boundary, either circular or ellipse, is detected accurately. Then, Morphology and Region of interest (ROI) extraction is done for Iris localization in order to isolate the useful iris regions without eyelashes and other occlusions. Furthermore, the resultant iris portion is transformed into polar coordinates system for normalization process using Daugman's rubber sheet model. Histogram equalization is applied for enhancing the normalized iris image. Finally, feature extraction and matching is performed using Sequential Addition-based grouping and hamming distance approach. The Chinese Academy of Sciences-institute of Automation (CASIA) database is used to stimulate the studies. The proposed algorithm reduced the computational time and increased the recognition accuracy to a great extent as compared with existing algorithms. © 2015 IEEE.","Hamming distance; Iris localization; Morphology; Pupil localization; Sequential addition"
"Sawant A., Gupta S.","Iris recognition using support vector machine","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007287707&partnerID=40&md5=f33c43fb3c826f0259e16f85149398b4","Biometrics involves identification of an individual from certain secernating features of human beings. These include speech, retina, iris, fingerprints, facial features, script and hand geometry. Amongst these, iris is unique, has highly discerning pattern, does not change with age and is easy to acquire. This work concentrates on iris recognition system that consists of an automatic segmentation system based on Hough transform, which separates out the circular iris and pupil region, occlusion of eyelids and eyelashes, and reflections. The extracted iris region was then normalized to constant dimensions to eliminate imaging inconsistencies. Further, 1D Log-Gabor filter was extracted and quantized to four levels to encode the epigenetic pattern of the iris into a bit-wise biometric template. SVM has been used for classification purposes which is a kernel-based supervised method. RBF kernel proves to be more prominent over Polynomial kernel.","Hough transform; Iris recognition; Kernel function; Normalisation; Support vector machine"
"Wei X., Li C.-T., Lei Z., Yi D., Li S.Z.","Dynamic image-to-class warping for occluded face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911215301&doi=10.1109%2fTIFS.2014.2359632&partnerID=40&md5=50017468b9d1967049b55c03cffc452c","Face recognition (FR) systems in real-world applications need to deal with a wide range of interferences, such as occlusions and disguises in face images. Compared with other forms of interferences such as nonuniform illumination and pose changes, face with occlusions has not attracted enough attention yet. A novel approach, coined dynamic image-to-class warping (DICW), is proposed in this work to deal with this challenge in FR. The face consists of the forehead, eyes, nose, mouth, and chin in a natural order and this order does not change despite occlusions. Thus, a face image is partitioned into patches, which are then concatenated in the raster scan order to form an ordered sequence. Considering this order information, DICW computes the image-to-class distance between a query face and those of an enrolled subject by finding the optimal alignment between the query sequence and all sequences of that subject along both the time dimension and within-class dimension. Unlike most existing methods, our method is able to deal with occlusions which exist in both gallery and probe images. Extensive experiments on public face databases with various types of occlusions have confirmed the effectiveness of the proposed method. © 2014 IEEE.","biometrics; dynamic time warping; Face recognition; image-to-class distance; occlusion"
"Lai Z.-R., Dai D.-Q., Ren C.-X., Huang K.-K.","Multilayer surface albedo for face recognition with reference images in bad lighting conditions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907543069&doi=10.1109%2fTIP.2014.2356292&partnerID=40&md5=05a4183ed77790e33829a52ad551918d","In this paper, we propose a multilayer surface albedo (MLSA) model to tackle face recognition in bad lighting conditions, especially with reference images in bad lighting conditions. Some previous researches conclude that illumination variations mainly lie in the large-scale features of an image and extract small-scale features in the surface albedo (or surface texture). However, this surface albedo is not robust enough, which still contains some detrimental sharp features. To improve robustness of the surface albedo, MLSA further decomposes it as a linear sum of several detailed layers, to separate and represent features of different scales in a more specific way. Then, the layers are adjusted by separate weights, which are global parameters and selected for only once. A criterion function is developed to select these layer weights with an independent training set. Despite controlled illumination variations, MLSA is also effective to uncontrolled illumination variations, even mixed with other complicated variations (expression, pose, occlusion, and so on). Extensive experiments on four benchmark data sets show that MLSA has good receiver operating characteristic curve and statistical discriminating capability. The refined albedo improves recognition performance, especially with reference images in bad lighting conditions. © 1992-2012 IEEE.","bad lighting conditions; deep decomposition and adjustment; Face recognition; multiple layers; surface albedo; uncontrolled illumination"
"Mamta, Hanmandlu M.","Robust authentication using the unconstrained infrared face images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901989924&doi=10.1016%2fj.eswa.2014.03.040&partnerID=40&md5=960ef523ad036ac93e8104977857f1e0","Face recognition under the unconstrained conditions that exist in surveillance is the need of the present times. Thus for high end security the research on IR based face recognition assumes importance because of its insensitivity to illumination, disguise and surgery. This paper presents IR face based biometric authentication using the information-set based four types of interactive features and two classifiers. The information sets originate from a fuzzy set on representing the uncertainty associated with the information source instead of a membership function which gives only the degree of association to the fuzzy set. The four feature types include the effective exponential information source (EEI), the effective Gaussian information source (EGI), the effective multi quadratic information source (EMQDI) and inverse of this feature (EIMQDI). The interactive features are obtained by taking the s-norms on the features from the successive windows. Two classifiers called the Hanman Classifier and the weighted Hanman Classifier are formulated using t-norms. The features and classifiers are tested on the created databases incorporating the unconstrained conditions such as occlusion, less resolution and noise. © 2014 Elsevier Ltd. All rights reserved.","Euclidean Classifier (EC); Hanman Classifier (HC); Infrared face recognition (IR face recognition); Weighted Hanman Classifier (WHC)"
"Zhang L., Ding Z., Li H., Lu J.","3DMKDSRC: A novel approach for 3D face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937468152&doi=10.1109%2fICME.2014.6890177&partnerID=40&md5=e4ca5cc0383006bbc3054f88a63b8b03","Recent years have witnessed a growing interest in developing methods for 3D face recognition. However, 3D scans often suffer from the problems of missing parts, large facial expressions, and occlusions. In this paper, we propose a novel general approach to deal with the 3D face recognition problem by making use of multiple keypoint descriptors (MKD) and the sparse representation-based classifier (SRC). We call the proposed method 3DMKDSRC for short. Specifically, with 3DMKDSRC, each 3D face scan is represented as a set of descriptor vectors extracted from keypoints by meshSIFT. Descriptor vectors of gallery samples form the gallery dictionary. Given a probe 3D face scan, its descriptors are extracted at first and then its identity can be determined by using a multitask SRC. The effectiveness of 3DMKDSRC has been corroborated by extensive experiments. © 2014 IEEE.","3D face recognition; biometrics; keypoint descriptor; meshSIFT; sparse representation"
"Aisha A., Muhammad S., Hussain S.J., Mudassar R.","Face recognition invariant to partial occlusions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905254091&doi=10.3837%2ftiis.2014.07.017&partnerID=40&md5=cb2804c0cf9e181cf33ecaac4e745b6b","Face recognition is considered a complex biometrics in the field of image processing mainly due to the constraints imposed by variation in the appearance of facial images. These variations in appearance are affected by differences in expressions and/or occlusions (sunglasses, scarf etc.). This paper discusses incremental Kernel Fisher Discriminate Analysis on sub-classes for dealing with partial occlusions and variant expressions. This framework focuses on the division of classes into fixed size sub-classes for effective feature extraction. For this purpose, it modifies the traditional Linear Discriminant Analysis into incremental approach in the kernel space. Experiments are performed on AR, ORL, Yale B and MIT-CBCL face databases. The results show a significant improvement in face recognition. © 2014 KSII.","Feature extraction; Incremental approach; Linear discriminate analysis; Partial occlusion; Sub-classes"
"Alyuz N., Gokberk B., Akarun L.","Robust 3D face identification in the presence of occlusions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946152123&doi=10.4018%2f978-1-4666-5966-7.ch006&partnerID=40&md5=d61e9e56ecd4e5d71e549c84a7cd3073","The face is one of the most natural biometrics, and as such, its acceptance by users is high. While biometrics such as fingerprint and iris can only be acquired with active cooperation of the user, the face can be acquired from a distance. This makes it an attractive modality for uncooperative scenarios. However, in such scenarios, occlusion is a common problem. The focus of this chapter is to illustrate the problems caused by 3D occlusion, and to go over solutions. The authors review 3D face identification approaches with focus on occlusion scenarios, introduce 3D databases containing occlusions, and present a prototype system with solutions for occlusion at landmarking, registration, feature extraction, and matching stages. © 2014 by IGI Global. All rights reserved.",
"Wechsler H., Li F.","Biometrics and Robust Face Recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902236470&doi=10.1016%2fB978-0-12-398537-8.00010-9&partnerID=40&md5=3675dac45c42b04ca4b695056c97426d","The use of conformal prediction in general, and transduction in particular, is discussed in terms of scope, challenges, and vulnerabilities for biometrics with robust face recognition as application domain of interest. Robustness refers to the ability to cope with uncontrolled settings characteristic of incomplete and/or corrupt (adversarial) biometric information on one side, and varying image quality on the other side. The motivation for the conformal prediction approach comes from the use of discriminative methods, such as likelihood ratios, to link biometrics and forensics. The methods and algorithms proposed are realized using transductive inference (transduction for brevity). They leverage nonconfidence measures (NCM), make use of both labeled (annotated) and unlabeled biometric data, address multilayer categorization, and provide measures of reliability in the predictions made, such as credibility and confidence. Toward that end we describe a novel Transduction Confidence Machine for Detection and Recognition (TCM-DR) that expands on the traditional Transduction Confidence Machine (TCM). The two machines, TCM and TCM-DR, are suitable for closed and open-set recognition, respectively, with TCM-DR also suitable for verification. Basic concepts, architectures, and empirical results are presented for open set face recognition and watch list/surveillance using TCM-DR. Recognition-by-parts using transduction and boosting is the adversarial learning solution that addresses vulnerabilities due to occlusion and disguise. Future venues for biometric research are discussed including reidentification using sensitivity analysis and revision for the purpose of metaprediction in general, and interoperability and identity management in particular. © 2014 Elsevier Inc. All rights reserved.","Biometrics; Boosting; Closed set recognition; Face recognition; Face verification; Open set recognition; Recognition-by-parts; Reidentification; Score normalization; Surveillance"
"Travieso C.M., Del Pozo-Baños M., Ticay-Rivas J.R., Alonso J.B.","Influence of the intra-modal facial information for an identification approach","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946000283&doi=10.4018%2f978-1-4666-5808-0.ch013&partnerID=40&md5=e7b0a2fdf97de3e2a11c92c5641ae3fb","This chapter presents a comprehensive study on the influence of the intra-modal facial information for an identification approach. It was developed and implemented a biometric identification system by merging different intra-multimodal facial features: mouth, eyes, and nose. The Principal Component Analysis, Independent Component Analysis, and Discrete Cosine Transform were used as feature extractors. Support Vector Machines were implemented as classifier systems. The recognition rates obtained by multimodal fusion of three facial features has reached values above 97% in each of the databases used, confirming that the system is adaptive to images from different sources, sizes, lighting conditions, etc. Even though a good response has been shown when the three facial traits were merged, an acceptable performance has been shown when merging only two facial features. Therefore, the system is robust against problems in one isolate sensor or occlusion in any biometric trait. In this case, the success rate achieved was over 92%. © 2014 by IGI Global. All rights reserved.",
"Oh K., Oh B.-S., Toh K.-A., Yau W.-Y., Eng H.-L.","Combining sclera and periocular features for multi-modal identity verification","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893682394&doi=10.1016%2fj.neucom.2013.01.066&partnerID=40&md5=cb1c76c803e5c342c9e2f763d458b25b","In this paper, we propose to combine sclera and periocular features for identity verification. The proposal is particularly useful in applications related to face recognition when the face is partially occluded with only periocular region revealed. Due to its relatively new exposition in the literature of biometrics, particular attention will be paid to sclera feature extraction in this work. For periocular feature extraction, structured random projections were adopted to extract compressed vertical and horizontal components of image features. The binary sclera features are eventually fused with the periocular features at a score level. Extensive experiments have been performed on UBIRIS v1 session1 and session2 databases to assess the verification performance before and after fusion. Around 5% of equal error rate performance was observed to be enhanced by fusing sclera with periocular features comparing with that before fusion. © 2013 Elsevier B.V.","Multi-modal biometrics; Periocular biometric; Sclera biometric"
"Yang M., Feng Z., Shiu S.C.K., Zhang L.","Fast and robust face recognition via coding residual map learning based adaptive masking","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887025084&doi=10.1016%2fj.patcog.2013.08.003&partnerID=40&md5=ec31008eac18ae41f03fab11fe88f80e","Robust face recognition (FR) is an active topic in computer vision and biometrics, while face occlusion is one of the most challenging problems for robust FR. Recently, the representation (or coding) based FR schemes with sparse coding coefficients and coding residual have demonstrated good robustness to face occlusion; however, the high complexity of l1-minimization makes them less useful in practical applications. In this paper we propose a novel coding residual map learning scheme for fast and robust FR based on the fact that occluded pixels usually have higher coding residuals when representing an occluded face image over the non-occluded training samples. A dictionary is learned to code the training samples, and the distribution of coding residuals is computed. Consequently, a residual map is learned to detect the occlusions by adaptive thresholding. Finally the face image is identified by masking the detected occlusion pixels from face representation. Experiments on benchmark databases show that the proposed scheme has much lower time complexity but comparable FR accuracy with other popular approaches. © 2013 Elsevier Ltd.","Adaptive masking; Coding residual map; Robust face recognition"
"He R., Zheng W.-S., Tan T., Sun Z.","Half-quadratic-based iterative minimization for robust sparse representation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891600080&doi=10.1109%2fTPAMI.2013.102&partnerID=40&md5=c119e6904a85761a252d5f5f220b2464","Robust sparse representation has shown significant potential in solving challenging problems in computer vision such as biometrics and visual surveillance. Although several robust sparse models have been proposed and promising results have been obtained, they are either for error correction or for error detection, and learning a general framework that systematically unifies these two aspects and explores their relation is still an open problem. In this paper, we develop a half-quadratic (HQ) framework to solve the robust sparse representation problem. By defining different kinds of half-quadratic functions, the proposed HQ framework is applicable to performing both error correction and error detection. More specifically, by using the additive form of HQ, we propose an (\ell-1)-regularized error correction method by iteratively recovering corrupted data from errors incurred by noises and outliers; by using the multiplicative form of HQ, we propose an (\ell-1)-regularized error detection method by learning from uncorrupted data iteratively. We also show that the (\ell-1)-regularization solved by soft-thresholding function has a dual relationship to Huber M-estimator, which theoretically guarantees the performance of robust sparse representation in terms of M-estimation. Experiments on robust face recognition under severe occlusion and corruption validate our framework and findings. © 2014 IEEE.","(\ell-1)-minimization; correntropy; half-quadratic optimization; M-estimator; sparse representation"
"Venkatakrishnan D., Hariram C., Anantharaj N., Muthulakshmi A.","3D face recognition with occlusions using fisher faces projection","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904389858&doi=10.4028%2fwww.scientific.net%2fAMM.573.442&partnerID=40&md5=6f2eae2019f9172923da4a52debd3997","In recent years, the 3-D face has become biometric modal, for security applications. Dealing with occlusions covering the facial surface is difficult to handle. Occlusion means blocking of face images by objects such as sun glasses, kerchiefs, hands, hair and so on. Occlusions are occurred by facial expressions, poses also. Basically consider two things: i) Occlusion handling for surface registration and ii). Missing data handling for classification. For registration to use an adaptivelyselected- model based registration scheme is used. After registering occlusions are detected and removed. In order to handle the missing data we use a masking strategy call masked projection technique called Fisher faces Projection. Registration based on the adaptively selected model together with the masked analysis offer an occlusion robust face recognition system. © (2014) Trans Tech Publications, Switzerland.","Face recognition; Masked projection; Occlusion"
"Alyuz N., Gokberk B., Akarun L.","Detection of realistic facial occlusions for robust 3D face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919934821&doi=10.1109%2fICPR.2014.73&partnerID=40&md5=ce3d4b21457e849d3f57c4ae678e6b6d","Face is a highly utilized biometric, and 3D modality is preferred due to better handling of variations such as pose and illumination. However, occlusions covering the face alter the 3D surface and degrade the recognition performance. To improve recognition rates, the occluded parts should be detected prior to any surface comparison. In this paper, we consider two different occlusion detection approaches: The first one is based on statistical facial surface modeling, where pixel-wise Gaussian Mixture Models are trained. The second algorithm considers occlusion detection as a binary image segmentation problem: The regional cues of depth values are incorporated with neighborhood cues, and the acquired surface is modeled as a graph. The surface pixels are labeled as either face or occlusion via the graph cut technique. Experiments on the Bosphorus and the UMB-DB databases, including realistic occlusion variations, show that both methods improve occlusion detection and face recognition rates as compared to the baseline technique. © 2014 IEEE.",
"Naruniec J.","Discrete area filters in accurate detection of faces and facial features","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908320241&doi=10.1016%2fj.imavis.2014.09.004&partnerID=40&md5=552fd34955dc9a6e012c36d70372a7c3","This paper introduces a new method for detection of faces and facial features. Proposed algorithm denies the thesis that bottom-up solutions can't work at reasonable speed. It introduces fast detection - about 9 frames per second for a 384 × 256 image - while preserving accurate details of the detection. Main experiments focus on the detection of the eye centers - crucial in many computer vision systems such as face recognition, eye movement detection or iris recognition, however algorithm is tuned to detect 15 fiducial face points. Models were trained on nearly frontal faces. Bottom-up approach allows to detect objects under partial occlusion - particularly two out of four face parts (left eye, right eye, nose, mouth) must be localized. Precision of the trained model is verified on the Feret dataset. Robustness of the face detection is evaluated on the BioID, LFPW, Feret, GT, Valid and Helen databases in comparison to the state of the art detectors. © 2014 Elsevier B.V. All rights reserved.","Discrete area filers; Face detection; Facial features detection; mLDA cascade"
"Bindu A., Kumar C.N.R.","Inpainting for big data","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899050531&doi=10.1109%2fICSIP.2014.14&partnerID=40&md5=11ad5aa3577b07d6e9a050f68778f048","In the current day World with ever rising crime rate, it becomes evident to keep a watch on the secure authentication and retrieval of Human identities. Face Biometrics is a dedicated and one amongst the most popular arena which relies on the facial (biological) traits for unique identity retrieval. Real Time Applications of efficient identity retrieval using face biometric are posed by many hindrances in the form of occlusions/distortions which subsequently result in the drastic reduction of the system response time with the increase in database size. Efficient and error free Real Time face recognition demands the backup of a mammoth database with due considerations to the degrees of occlusion, age variations, distortions, background variations, lighting conditions, moods etc., which pose a major setback to maintain a balance between the Real Time system efficiency, its response time and optimum database size! This lacuna is addressed in the current Novel work of Research to tap the intra facial feature logical relationships to evolve the occluded/distorted facial boundary and features with precision and perfection and also cut short the size of the Real Time Identity Retrieval system database to a great extent! © 2014 IEEE.","Big Data; Identity Retrieval; Inpainting; Occlusion; Real Time Face Recognition"
"Bhowmik M.K., Saha K., Saha P., Bhattacharjee D.","DeitY-TU face database: Its design, multiple camera capturing, characteristics, and evaluation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940268436&doi=10.1117%2f1.OE.53.10.102106&partnerID=40&md5=b497ed4931283bef5960c25fe1648454","The development of the latest face databases is providing researchers different and realistic problems that play an important role in the development of efficient algorithms for solving the difficulties during automatic recognition of human faces. This paper presents the creation of a new visual face database, named the Department of Electronics and Information Technology-Tripura University (DeitY-TU) face database. It contains face images of 524 persons belonging to different nontribes and Mongolian tribes of north-east India, with their anthropometric measurements for identification. Database images are captured within a room with controlled variations in illumination, expression, and pose along with variability in age, gender, accessories, make-up, and partial occlusion. Each image contains the combined primary challenges of face recognition, i.e., illumination, expression, and pose. This database also represents some new features: soft biometric traits such as mole, freckle, scar, etc., and facial anthropometric variations that may be helpful for researchers for biometric recognition. It also gives an equivalent study of the existing two-dimensional face image databases. The database has been tested using two baseline algorithms: linear discriminant analysis and principal component analysis, which may be used by other researchers as the control algorithm performance score. © 2014 Society of Photo-Optical Instrumentation Engineers.","anthropometry; classification; database characteristics; DeitY-TU face database; face recognition; soft biometrics"
"Guan Y., Wei X., Li C.-T., Keller Y.","People identification and tracking through fusion of facial and gait features","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84915786217&doi=10.1007%2f978-3-319-13386-7_17&partnerID=40&md5=67765d0b0d0a60fbc4f48a57eb61667c","This paper reviews the contemporary (face, gait, and fusion) computational approaches for automatic human identification at a distance. For remote identification, there may exist large intra-class variations that can affect the performance of face/gait systems substantially. First, we review the face recognition algorithms in light of factors, such as illumination, resolution, blur, occlusion, and pose. Then we introduce several popular gait feature templates, and the algorithms against factors such as shoe, carrying condition, camera view, walking surface, elapsed time, and clothing. The motivation of fusing face and gait, is that, gait is less sensitive to the factors that may affect face (e.g., low resolution, illumination, facial occlusion, etc.), while face is robust to the factors that may affect gait (walking surface, clothing, etc.). We review several most recent face and gait fusion methods with different strategies, and the significant performance gains suggest these two modality are complementary for human identification at a distance. © 2014, Springer Verlag. All rights reserved.",
"Syafeeza A.R., Khalil-Hani M., Liew S.S., Bakhteri R.","Convolutional neural network for face recognition with pose and illumination variation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899995651&partnerID=40&md5=3135733530c3edb00ce3c9e2cebd1576","Face recognition remains a challenging problem till today. The main challenge is how to improve the recognition performance when affected by the variability of non-linear effects that include illumination variances, poses, facial expressions, occlusions, etc. In this paper, a robust 4-layer Convolutional Neural Network (CNN) architecture is proposed for the face recognition problem, with a solution that is capable of handling facial images that contain occlusions, poses, facial expressions and varying illumination. Experimental results show that the proposed CNN solution outperforms existing works, achieving 99.5% recognition accuracy on AR database. The test on the 35-subjects of FERET database achieves an accuracy of 85.13%, which is in the similar range of performance as the best result of previous works. More significantly, our proposed system completes the facial recognition process in less than 0.01 seconds.","Biometric identification; Convolutional neural network; Face recognition; Stochastic diagonal levenberg-marquardt"
"Meena K., Suruliandi A., Rose R.R.","Enhancing the performance of texture-based face recognition through multi-resolution techniques","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961291214&doi=10.1504%2fIJBM.2014.067132&partnerID=40&md5=9f0f2c77533d9c261ac2a0b547b17497","Automatic face recognition is an emerging active research area spanning several disciplines such as image processing, computer vision and pattern recognition. Face recognition is a challenging problem because of diversity in faces and variations caused by expressions, illuminations, pose, occlusion, aging and so on. In this paper, multi-resolution techniques are combined with texture features to mitigate the effect of facial variations. Multi-resolution techniques investigated in this paper are discrete wavelet transform (DWT), ridgelet, curvelet and contourlet. Texture features are extracted from these transforms by using local binary pattern (LBP), local texture pattern (LTP), local derivative pattern (LDP), local tetra patterns (LTrPs) and local derivative ternary pattern (LDTP). The proposed method is tested on JAFFE, ORL, Yale, Essex and Georgia Tech databases containing more than 4,000 face images. From the results, it is observed that, the combined approach of multi-resolution techniques with texture features enhances the face recognition rate. In particular, contourlet transform with LDTP perform better than the other techniques considered for investigation. Copyright © 2014 Inderscience Enterprises Ltd.","Biometrics; Face recognition; G-statistics; K-nearest neighbour; Multi-resolution analysis; Texture analysis; Texture features"
"Azeem A., Sharif M., Raza M., Murtaza M.","A survey: Face recognition techniques under partial occlusion","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899848172&partnerID=40&md5=765cd03bec91954fdd6981948593e631","Systems that rely on Face Recognition (FR) biometric have gained great importance ever since terrorist threats imposed weakness among the implemented security systems. Other biometrics i.e., fingerprints or iris recognition is not trustworthy in such situations whereas FR is considered as a fine compromise. This survey illustrates different FR practices that laid foundations on the issue of partial occlusion dilemma where faces are disguised to cheat the security system. Occlusion refers to facade of the face image which can be due to sunglasses, hair or wrapping of facial image by scarf or other accessories. Efforts on FR in controlled settings have been in the picture for past several years; however identification under uncontrolled conditions like illumination, expression and partial occlusion is quite a matter of concern. Based on literature a classification is made in this paper to solve the recognition of face in the presence of partial occlusion. These methods are named as part based methods that make use of Principal Component Analysis (PCA), Linear Discriminate Analysis (LDA), Non-negative Matrix Factorization (NMF), Local Non-negative Matrix Factorization (LNMF), Independent Component Analysis (ICA) and other variations. Feature based and fractal based methods consider features around eyes, nose or mouth region to be used in the recognition phase of algorithms. Furthermore the paper details the experiments and databases used by an assortment of authors to handle the problem of occlusion and the results obtained after performing diverse set of analysis. Lastly, a comparison of various techniques is shown in tabular format to give a precise overview of what different authors have already projected in this particular field.","Feature based methods; FR; Fractal-based methods; Part based methods; Partial occlusion; Recognition rates"
"Panchal K., Shah H.","3D face recognition based on pose correction using euler angle method","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909994308&doi=10.1109%2fICMIRA.2013.99&partnerID=40&md5=cffdb969d66897ba52e806303ba9ad56","Face recognition is one of the biometric method, to identification of given face image using main features of the face. 3D face recognition approach handles the challenges of 2D face recognition such as pose, illumination, expression, etc in a better way. The exploration of 3D face recognition is widely used for security at many places like airport, organizations, crime detection etc. uncontrolled condition of real-world biometric applications is pose which is a great challenge to any face recognition approach. Such pose variations can cause extensive occlusions, resulting in missing data. This work presents 3D face recognition method which is invariant to pose. The method handles pose correction problem with rotation matrix based on Euler angle. Further dimensionality of face image is reduced by the principal component analysis and the recognition is done by the Euclidean distance algorithm. we used GAVAB 3D face database for simulation and measured performance like Recognition rate, False acceptance rate (FAR), False rejection rate (FRR) and Equal error rate (EER) are used to evaluate performance of the method. We have achieved 1.12 % improvement in Recognition rate and 0.15% improvement in equal error rate for probes with neutral and non-neutral, respectively. © 2013 IEEE.","Face Recognition; Pose Correction; principal component analysis"
"Mishra R., Subban R.","Face detection for video summary using enhancement-based fusion strategy under varying illumination conditions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926058608&doi=10.1109%2fICSEMR.2014.7043648&partnerID=40&md5=e0e10aad2761b2a7ab2fffcadd550e56","A biometric-based techniques emerge as the promising approach for most of the real-time applications including security systems, video surveillances, human-computer interaction and many more. Among all biométrie methods, face recognition offers more benefits as compared to others. Diagnosing human faces and localizing them in images or videos is the priori step of tracking and recognizing. But the performance of face detection is limited by certain factors namely lighting conditions, pose variation, occlusions, low resolution images and complex background. To overcome the problems, this paper examines a fusion strategy in the enhancement-based skin-color segmentation approach that can improve the performance of face detection algorithm. The method is robust against complex background, ethnicity and lighting variations. The method consists of three steps. The first step receives spatial transform techniques in parallel to enhance the contrast of the image, change the color space of the enhanced images to YCbCr, apply skin segmentation technique and yield the binary segmented images. The second step ascertains the weight of accuracy (WoA) of each of the segmented image and fed it into the fusion strategy to get the final skin detected region. Finally, the last step localizes the human face. The methodology is not constrained to just frontal face identification. However it is invariant with the diverse head postures, enlightment condition, and size of faces. The experimental result demonstrates the improvement in the accuracy and precision along with the reduction in FPR as compared to other enhancement classifiers. © 2014 IEEE.","enhancement techniques; face detection; fusion strategy; illumination; skin detection"
"Mishra R., Subban R.","Face detection for video summary using enhancement-based fusion strategy under varying illumination conditions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926050094&doi=10.1109%2fICSEMR.2014.7043634&partnerID=40&md5=ea0334212e69bfc972e844464a4f18f6","A biometric-based techniques emerge as the promising approach for most of the real-time applications including security systems, video surveillances, human-computer interaction and many more. Among all biométrie methods, face recognition offers more benefits as compared to others. Diagnosing human faces and localizing them in images or videos is the priori step of tracking and recognizing. But the performance of face detection is limited by certain factors namely lighting conditions, pose variation, occlusions, low resolution images and complex background. To overcome the problems, this paper examines a fusion strategy in the enhancement-based skin-color segmentation approach that can improve the performance of face detection algorithm. The method is robust against complex background, ethnicity and lighting variations. The method consists of three steps. The first step receives spatial transform techniques in parallel to enhance the contrast of the image, change the color space of the enhanced images to YCbCr, apply skin segmentation technique and yield the binary segmented images. The second step ascertains the weight of accuracy (WoA) of each of the segmented image and fed it into the fusion strategy to get the final skin detected region. Finally, the last step localizes the human face. The methodology is not constrained to just frontal face identification. However, it is invariant with the diverse head postures, enlightment condition and size of faces. The experimental result demonstrates the improvement in the accuracy and precision along with the reduction in FPR as compared to other enhancement classifiers. © 2014 IEEE.","enhancement techniques; face detection; fusion strategy; illumination; skin detection"
"Thenmozhi M., Gnanaskanda Parthiban P.","Robust face recognition from NIR dataset via sparse representation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904382702&doi=10.4028%2fwww.scientific.net%2fAMM.573.495&partnerID=40&md5=5b0a153a9b127c39781c135482f651ca","A biometric identification system may be a pc application for mechanically distinctive or confirmative of an individual from a digital image or a video frame from a video supply. One in all the ways that to try and do this can be by examination designated face expression from the image and a facial information. This paper planned dynamic face recognition from near-infrared images by exploitation sparse representation classifier. Most of the prevailing datasets for facial expressions are captured in a very visible light spectrum. However, the visible light (VIS) will modify with time and placement, causing important variations in look and texture. This new framework was designed to attain strength to pose variation and occlusion and to resolve uncontrolled environmental illumination for reliable biometric identification. This paper gift a unique analysis on a dynamic facial features recognition, exploitation near-infrared (NIR) datasets and LBP(Local binary patterns) feature descriptors. It shows sensible and strong results against illumination variations by exploitation infrared imaging system. © (2014) Trans Tech Publications, Switzerland.","Face recognition; Feature extraction; Local binary patterns(LBP); Near-infrared (NIR); Occlusion and corruption; Sparse representation; Visible light (VIS)"
"Khaji R., Li H., Hasan T.M., Li H., Ali Q.","Relaxed collaborative representation for face recognition based low-rank matrix recovery","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021346500&doi=10.1109%2fICWAPR.2014.6961289&partnerID=40&md5=fc68b82cb0bf5ac5e0da8e2846c4f909","Face recognition is of paramount importance in computer vision and biometrics systems. In this paper we propose an improved method which is suitable to handle variations in image configurations like pose, illumination, and facial expressions as well as occlusion and disguise, in order to provide high efficiencyi in the face recognition. This method integrates the low-rank matrix which is recovered by using robust principal component analysis (RPCA) with relaxed collaborative representation (RCR). Low-rank representation allows us to better discriminate information which benefits to face identification, and R-CR contributes to the reduction of the variance of coding vector after coding each feature vector on its associated dictionary to allow flexibility of feature coding, thus addressing the similarity among features. Furthermore, it is characterized by the exploitation of the distinctiveness of different features by weighting its distance to other features in the coding domain. The effectiveness of the proposed method is validated by extensive experiments on different benchmark face databases. © 2014 IEEE.","Face Recognition; Low-Rank Matrix; PRCA; Relaxed Collaborative Representation; Sparse Representation"
"Benzaoui A., Boukrouche A.","Face analysis, description and recognition using improved local binary patterns in one dimensional space","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920186492&partnerID=40&md5=720e1875e70550d1bb41443746e44de8","In this study of a biometric system, Improved One Dimensional Local Binary Patterns (I1DLBP) are developed and tested for use in face analysis, description and recognition. The extraction of facial features is based on the principal that the human visual system combines local and global features to differentiate between people. The proposed method starts by decomposing the facial image into several blocks with different resolutions. Each block is then projected in one dimensional space, and the developed descriptor is applied on each projected block. Finally, Principal Component Analysis (PCA) is used to reduce the dimensionalities of the concatenated vectors from each block and to keep only the relevant information. The K-nearest neighbors (KNN) algorithm is used as a classifier. Experiments were carried out under varying conditions of occlusion, rotation, and facial expressions, using the ORL and AR databases. Results show that the developed feature extraction approach can effectively describe the micro characteristics of the human face and that it outperforms well-known and classical feature extraction descriptors.","1DLBP; Biometrics; Face recognition; I1DLBP; LBP; PCA"
"Juefei-Xu F., Savvides M.","Subspace-based discrete transform encoded local binary patterns representations for robust periocular matching on NIST's face recognition grand challenge","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904294496&doi=10.1109%2fTIP.2014.2329460&partnerID=40&md5=672f232be9ac61113ef9ace4e39cd638","In this paper, we employ several subspace representations (principal component analysis, unsupervised discriminant projection, kernel class-dependence feature analysis, and kernel discriminant analysis) on our proposd discrete transform encoded local binary patterns (DT-LBP) to match periocular region on a large data set such as NIST's face recognition grand challenge (FRGC) ver2 database. We strictly follow FRGC Experiment 4 protocol, which involves 1-to-1 matching of 8014 uncontrolled probe periocular images to 16 028 controlled target periocular images (~128 million pairwise face match comparisons). The performance of the periocular region is compared with that of full face with different illumination preprocessing schemes. The verification results on periocular region show that subspace representation on DT-LBP outperforms LBP significantly and gains a giant leap from traditional subspace representation on raw pixel intensity. Additionally, our proposed approach using only the periocular region is almost as good as full face with only 2.5% reduction in verification rate at 0.1% false accept rate, yet we gain tolerance to expression, occlusion, and capability of matching partial faces in crowds. In addition, we have compared the best standalone DT-LBP descriptor with eight other state-of-the-art descriptors for facial recognition and achieved the best performance. The two general frameworks are our major contribution: 1) a general framework that employs various generative and discriminative subspace modeling techniques for DT-LBP representation and 2) a general framework that encodes discrete transforms with local binary patterns for the creation of robust descriptors. © 1992-2012 IEEE.","discrete transform; FRGC; local binary patterns (LBP); Periocular"
"Jain P.K., Shukla S., Thakur S.S.","User authentication using multimodel face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939163897&partnerID=40&md5=0fd4796b0f244cc9e2f5166701ed98f5","Face recognition has received much attention in the recent years due to its wide range of applications. The available face recognition algorithm's performance in the presence of multiple variations such as illumination, pose, expression and occlusion is not satisfactory. Multimodal biometric systems utilize multiple biometric sources in order to increase robustness as compared to single biometric system. In this paper, a multimodal biometric system is introduced which integrates face verification by three different methods. A Fuzzy based decision making system is designed which takes input from the three recognition made by different methods and gives an identity of recognized person. Preliminary experiment results demonstrate that the identity recognized by this integrated system is more reliable than the identity established by the available face recognition algorithms in literature. © Research India Publications.","Face Recognition; Fuzzy Fusion; ICA; ILDA; PCA"
"Barr J.R., Bowyer K.W., Flynn P.J.","The effectiveness of face detection algorithms in unconstrained crowd scenes","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904606324&doi=10.1109%2fWACV.2014.6835992&partnerID=40&md5=3cae168ef068bfb439642d652867dbcf","The 2013 Boston Marathon bombing represents a case where automatic facial biometrics tools could have proven invaluable to law enforcement officials, yet the lack of robustness of current tools in unstructured environments limited their utility. In this work, we focus on complications that confound face detection algorithms. We first present a simple multi-pose generalization of the Viola-Jones algorithm. Our results on the Face Detection Data set and Benchmark (FDDB) show that it makes a significant improvement over the state of the art for published algorithms. Conversely, our experiments demonstrate that the improvements attained by accommodating multiple poses can be negligible compared to the gains yielded by normalizing scores and using the most appropriate classifier for uncontrolled data. We conclude with a qualitative evaluation of the proposed algorithm on publicly available images of the Boston Marathon crowds. Although the results of our evaluations are encouraging, they confirm that there is still room for improvement in terms of robustness to out-of-plane rotation, blur and occlusion. © 2014 IEEE.",
"Wei C.-P., Chen C.-F., Wang Y.-C.F.","Robust face recognition with structurally incoherent low-rank matrix decomposition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903557959&doi=10.1109%2fTIP.2014.2329451&partnerID=40&md5=2f02460d73450ec88e44838785ad2f86","For the task of robust face recognition, we particularly focus on the scenario in which training and test image data are corrupted due to occlusion or disguise. Prior standard face recognition methods like Eigenfaces or state-of-the-art approaches such as sparse representation-based classification did not consider possible contamination of data during training, and thus their recognition performance on corrupted test data would be degraded. In this paper, we propose a novel face recognition algorithm based on low-rank matrix decomposition to address the aforementioned problem. Besides the capability of decomposing raw training data into a set of representative bases for better modeling the face images, we introduce a constraint of structural incoherence into the proposed algorithm, which enforces the bases learned for different classes to be as independent as possible. As a result, additional discriminating ability is added to the derived base matrices for improved recognition performance. Experimental results on different face databases with a variety of variations verify the effectiveness and robustness of our proposed method. © 2014 IEEE.","Face recognition; low-rank matrix decomposition; structural incoherence"
"Chessa M., Garibotti M., Maiello G., Caroggio L., Huang H., Sabatini S., Solari F.","Detection of 3D position of eyes through a consumer RGB-D camera for stereoscopic mixed reality environments","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930464315&doi=10.1109%2fIC3D.2014.7032592&partnerID=40&md5=a079496df82cdca36d572f5512d99789","A novel approach to track the 3D position of the user's eyes in stereoscopic virtual environments, where stereo glasses are worn, is proposed. Such an approach improves a state-of-the-art real-time face tracking algorithm by addressing the occlusion due the stereo glasses and providing estimation of eye position based on biométrie features. More generally, our solution can be seen as a proof of concept for a more robust approach to improving motion tracking techniques. In particular, the proposed technique yields accurate and stable estimates of the 3D position of the user's eyes, while the user moves in front of the stereoscopic display. The correct tracking of both eyes' 3D position is a crucial step in order to achieve a more natural human-computer interaction which diminishes visual fatigue. The proposed approach is validated through quantitative tests: (i) we assessed the accuracy of our algorithm for tracking the 3D position of users' eyes with and without stereo glasses; (ii) we have performed a perceptual assessment of the natural interaction in the virtual environments through experimental sessions with several users. © 2014 IEEE.","Augmented reality; computer vision; Human-computer interactions; stereoscopic 3D entertainment system; Virtual reality"
"Ingwar M.I., Jensen C.D.","Remote biometrics for robust persistent authentication","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958530304&doi=10.1007%2f978-3-642-54568-9_16&partnerID=40&md5=5caf57c86451b7bee46d949d6e4f5095","This paper examines the problem of providing a robust non-invasive authentication service for mobile users in a smart environment. We base our work on the persistent authentication model (PAISE), which relies on available sensors to track principals from the location where they authenticate, e.g., through a smart card based access control system, to the location where the authentication is required by a location-based service. The PAISE model is extended with remote biometrics to prevent the decay of authentication confidence when authenticated users encounter and interact with other users in the environment. The result is a calm approach to authentication, where mobile users are transparently authenticated towards the system, which allows the provision of location-based services. The output of the remote biometrics are fused using error-rate-based fusion to solve a common problem that occurs in score level fusion, i.e., the scores of each biometric system are usually incompatible, as they have different score ranges as well as different probability distributions. We have integrated remote biometrics with the PAISE prototype and the experimental results on a publicly available dataset, show that fusion of two remote biometric modalities, facial recognition and appearance analysis, gives a significant improvement over each of the individual experts. Furthermore, the experimental results show that using remote biometrics increases the performance of tracking in persistent authentication, by identifying principals who are difficult to track due to occlusions in crowded scenes. © 2014 Springer-Verlag Berlin Heidelberg.",
"Chen X., Bhanu B.","Soft biometrics integrated multi-target tracking","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919928077&doi=10.1109%2fICPR.2014.710&partnerID=40&md5=297ccc6a68bf7b503852fe1c8023f8a7","In this paper, we present a soft biometrics based appearance model for multi-target tracking in a single camera. Track lets, the short-term tracking results, are generated by linking detections in consecutive frames based on conservative constraints. Our goal is to 're-stitching' the adjacent track lets that contain the same target so that robust long-term tracking results can be achieved. As the appearance of the same target may change greatly due to heavy occlusion, pose variations and changing lighting conditions, a discriminative appearance model is crucial for association-based tracking. Unlike most previous methods which simply use the similarity of color histograms or other low level features to construct the appearance model, we propose to use the fusion of soft biometrics generated from sub-track lets to learn a discriminative appearance model in an online manner. Compared to low level features, soft biometrics are robust against appearance variation. The experimental results demonstrate that our method is robust and greatly improves the tracking performance over the state-of-the-art method. © 2014 IEEE.",
"Barra S., De Marsico M., Nappi M., Riccio D.","Unconstrained ear processing: What is possible and what must be done","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958529543&doi=10.1007%2f978-3-642-54080-6_6&partnerID=40&md5=b6c226c3e211ec38051c2831b78fa8ac","Ear biometrics, compared with other physical traits, presents both advantages and limits. First of all, the small surface and the quite simple structure play a controversial role. On the positive side, they allow faster processing than, say, face recognition, as well as less complex recognition strategies than, say, fingerprints. On the negative side, the small ear area itself makes recognition systems especially sensitive to occlusions. Moreover, the prominent 3D structure of distinctive elements like the pinna and the lobe makes the same systems sensible to changes in illumination and viewpoint. Overall, the best accuracy results are still achieved in conditions that are significantly more favorable than those found in typical (really) uncontrolled settings. This makes the use of this biometrics in real world applications still difficult to propose, since a commercial use requires a much higher robustness. Notwithstanding the mentioned limits, ear is still an attractive topic for biometrics research, due to other positive aspects. In particular, it is quite easy to acquire ear images remotely, and these anatomic features are also relatively stable in size and structure along time. Of course, as any other biometric trait, they also call for some template updating. This is mainly due to age, but not in the commonly assumed way. The apparent bigger size of elders' ears with respect to those of younger subjects, is due to the fact that aging causes a relaxation of the skin and of some muscle-fibrous structures that hold the so called pinna, i.e. the most evident anatomical element of the ear. This creates the belief that ears continue growing all life long. On the other hand, a similar process holds for the nose, for which the relaxation of the cartilage tissue tends to cause a curvature downwards. In this chapter we will present a survey of present techniques for ear recognition, from geometrical to 2D-3D multimodal, and will attempt a reasonable hypothesis about the future ability of ear biometrics to fulfill the requirements of less controlled/covert data acquisition frameworks. © 2014 Springer-Verlag Berlin Heidelberg.",
"Monwar M.M., Vijayakumar B.V.K., Boddeti V.N., Smereka J.M.","Rank information fusion for challenging ocular image recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889045862&doi=10.1109%2fICCI-CC.2013.6622241&partnerID=40&md5=7dc178c07debbb0c6b2463dae72054f4","Under challenging imaging conditions which include lower resolution, occlusion, motion and de-focus blur, iris recognition performance degrades. In such conditions ocular region has been suggested as a new biometric modality which has the ability to overcome some of the above mentioned drawbacks. In this work, we investigate the performance of rank level fusion approach that fuses the output s of three ocula r region matching algorithms, namely, Probabilistic Deformation Model (PDM), modified Scale-Invariant Fe ature Transform (m-SIFT) and Gradient Orientation Histogram (GOH), employed for recognizing challenging ocula r images in the Face and Ocular Challenge Series (FOCS) dataset. We investigate different rank fusion schemes including the highest rank, Borda count, plurality voting and Markov chain and demonstrate that rank-level fu sion can lead to improved recognition performance. © 2013 IEEE.","Gradient orientation histogram; Ocular recognition; Probabilistic deformation model; Rank level fusion; Scale invariant feature transform"
"Jozef B., Matej F., L'uboš O., Miloš O., Jarmila P.","Face recognition under partial occlusion and noise","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888595905&doi=10.1109%2fEUROCON.2013.6625266&partnerID=40&md5=2e8a7e74b50043688addc77ae9057eca","The human face is one of the most popular characteristic which can be used in the biometric security system to identify or verify a user. Face is an acceptable biometric modality because it can be captured from a distance, even without physical contact of the user being identified. Thus the identification or verification does not require cooperation of the user. Recognition systems based on human face are used for a wide variety of applications, due to these benefits. However, the crucial task is still to provide reliable recognition accuracy, but it is a challenging problem under real-world conditions. There have been proposed many methods, but only a few of them are being used in the real-world applications. Even the most recent face recognition algorithms are still facing problems when there is non-ideal imaging, varying illumination, occlusions in the scene or noise of used cameras. We solve these issues within The Next-Generation Hybrid Broadcast Broadband project (HBB-Next) [1]. In this project, we also deal with development of face recognition application, as part of multimodal interface, which will interact with HBB-TV user. In this paper we provide a comparative study of several conventional face recognition methods (PCA a.k.a. Eigenfaces, RBF) and novel kernel methods (KPCA, GDA and SVM) that are suitable to work properly under these conditions. We evaluate the influence of noise and partial occlusion on face recognition accuracy. We are focused on occlusions of eyes and eyebrows as these are the most significant features of a face. Face recognition rates achieved by machine learning methods with accuracy achieved by human perception only are compared. In addition we explore these methods for cases where only a few (up to 4) training samples is available. © 2013 IEEE.","Face recognition; Machine learning methods; Noise; Partial occlusion"
"Bindu A., Ravi Kumar C.N.","Novel Inpainting Algorithm for heavily occluded face reconstruction","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891912343&doi=10.1109%2fICACCI.2013.6637458&partnerID=40&md5=9fe84ef3755dede52da3fe4dcf76d3ff","Face biometric adores a prime spot amongst various other Biometrics for being most easily accessible. At the present age with ever rising crime rate, Biometric Authentication has earned itself an inseparable berth in the public security system applications which require highly proficient Real Time identity retrieval. But, the efficiency is deterred by erratic and various degrees of Occlusions across the face in Real Time Applications. The degree and position of Occlusions cannot be predefined with precision. Thereby making the task of efficient identity retrieval of heavily occluded facial images an intriguing Challenge. The Proposed Algorithm is an initiative towards extracting the logical relations existing between the different facial features which serve as a key towards the accomplishment of efficient reconstruction under heavily occluded cases. © 2013 IEEE.","Face Biometric; Heavy Occlusion; Inpainting; Logical Relation; Real Time identity retrieval"
"Wang C.H., Hu A.K., Han F.L.","All common subsequences for face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900364331&doi=10.3991%2fijoe.v9i4.2818&partnerID=40&md5=5706ad8d466255aba175fb466b8fa7d5","In recent years, face recognition has become one of the hottest research topics aimed at biometric applications. Comparing with other biometrics recognition, face recognition provides more natural means for perceptual interface. However, face recognition algorithms weakly perform under some common conditions, which include the variation of facial expressions or lightening conditions, the occlusion of faces like wearing glasses or mask, the low resolution or noises of input images, and the like. The other problem is the recognition efficiency, especially when the facial database is tremendous. This paper presents all common subsequences (ACS) as the kernel function (similarity method) to solve the time series problem. Experiments on 4 public face databases: Caltech, Jaffe, Orl and Yale databases, demonstrate that ACS can achieve higher recognition accuracy than some classic face recognition methods, e.g. 2DPCA and 2DLDA.These instructions give you basic guidelines for preparing camera-ready papers for conference proceedings.","2DLDA; 2DPCA; All common subsequences (ACS); Face recognition; kNN; SVM"
"Zhang P., Zheng H., Yang C.","Robust face recognition based on spatially-weighted sparse coding","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893037999&doi=10.1007%2f978-3-319-02961-0_3&partnerID=40&md5=f83e608ae732cebb6af84d8a01372464","Recently sparse representation has been widely used in face recognition. It has been shown that under maximum likelihood estimation of the sparse coding problem, robustness of face representation and recognition can be improved. In this paper, we propose to weight spatial locations based on their discriminabilities in sparse coding for robust face recognition. More specifically, we estimate the weights at image locations based on a class-specific discriminative scheme, so as to highlight locations in face images that are important for classification. Furthermore, since neighboring locations in face images are often strongly correlated, spatial weights are smoothed to enforce similar values at adjacent locations. Extensive experiments on benchmark face databases demonstrate that our method is very effective in dealing with face occlusion, corruption, lighting and expression changes, etc. © Springer International Publishing 2013.","Face recognition; Sparse coding; Spatial weighting"
"Bharadwaj S., Vatsa M., Singh R.","Can holistic representations be used for face biometric quality assessment?","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897766881&doi=10.1109%2fICIP.2013.6738575&partnerID=40&md5=b41c648d030b50a62f59a3d42374569a","A face quality metric must quantitatively measure the usability of an image as a biometric sample. Though it is well established that quality measures are an integral part of robust face recognition systems, automatic measurement of bio-metric quality in face is still challenging. Inspired by scene recognition research, this paper investigates the use of holistic super-ordinate representations, namely, Gist and sparsely pooled Histogram of Orientated Gradient (HOG), in classifying images into different quality categories that are derived from matching performance. The experiments on the CAS-PEAL and SCFace databases containing covariates such as illumination, expression, pose, low-resolution and occlusion by accessories, suggest that the proposed algorithm can efficiently classify input face image into relevant quality categories and be utilized in face recognition systems. © 2013 IEEE.","biometrics; face quality assessment; performance prediction"
"Nasrollahi K., Moeslund T.B.","Are haar-like rectangular features for biometric recognition reducible?","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893185485&doi=10.1007%2f978-3-642-41827-3_42&partnerID=40&md5=02d65d2ed26134fbe143ba510bf339b6","Biometric recognition is still a very difficult task in real-world scenarios wherein unforeseen changes in degradations factors like noise, occlusion, blurriness and illumination can drastically affect the extracted features from the biometric signals. Very recently Haar-like rectangular features which have usually been used for object detection were introduced for biometric recognition resulting in systems that are robust against most of the mentioned degradations [9]. The problem with these features is that one can define many different such features for a given biometric signal and it is not clear whether all of these features are required for the actual recognition or not. This is exactly what we are dealing with in this paper: How can an initial set of Haar-like rectangular features, that have been used for biometric recognition, be reduced to a set of most influential features? This paper proposes total sensitivity analysis about the mean for this purpose for two different biometric traits, iris and face. Experimental results on multiple public databases show the superiority of the proposed system, using the found influential features, compared to state-of-the-art biometric recognition systems. © Springer-Verlag 2013.",
"Belhumeur P.N., Jacobs D.W., Kriegman D.J., Kumar N.","Localizing parts of faces using a consensus of exemplars","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887569228&doi=10.1109%2fTPAMI.2013.23&partnerID=40&md5=86fa94d33ccd7b15b3ac8bd33960f4e7","We present a novel approach to localizing parts in images of human faces. The approach combines the output of local detectors with a nonparametric set of global models for the part locations based on over 1,000 hand-labeled exemplar images. By assuming that the global models generate the part locations as hidden variables, we derive a Bayesian objective function. This function is optimized using a consensus of models for these hidden variables. The resulting localizer handles a much wider range of expression, pose, lighting, and occlusion than prior ones. We show excellent performance on real-world face datasets such as Labeled Faces in tH.W.ld (LFW) and a new Labeled Face Parts in tH.W.ld (LFPW) and show that our localizer achieves state-of-the-art performance on the less challenging BioID dataset. © 2013 IEEE.","biometrics; faces; fiducial points; Part localization"
"Lai J., Jiang X.","Robust face recognition using trimmed linear regression","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890500418&doi=10.1109%2fICASSP.2013.6638204&partnerID=40&md5=ebd69bcba7e2ef8e659ee54874f11eca","In this work, we focus on the problem of partially occluded face recognition. Using a robust estimator, we detect and trim the contaminated pixels from query sample. The corresponding pixels in the training samples are trimmed as well. The linear regression is applied to the trimmed images. Finally, the query image is labeled to the class with minimum normalized reconstruction error. Extensive experiments on benchmark face datasets demonstrate that the proposed approach is much more robust than state-of-the-art methods in dealing with occluded faces. © 2013 IEEE.","Biometrics; disguise; face recognition; partial occlusion; robust linear regression"
"Chen W., Gao Y.","Face recognition using ensemble string matching","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885117082&doi=10.1109%2fTIP.2013.2277920&partnerID=40&md5=054fb8ff2f2ef2a76f9bfc740f8e8df7","In this paper, we present a syntactic string matching approach to solve the frontal face recognition problem. String matching is a powerful partial matching technique, but is not suitable for frontal face recognition due to its requirement of globally sequential representation and the complex nature of human faces, containing discontinuous and non-sequential features. Here, we build a compact syntactic Stringface representation, which is an ensemble of strings. A novel ensemble string matching approach that can perform non-sequential string matching between two Stringfaces is proposed. It is invariant to the sequential order of strings and the direction of each string. The embedded partial matching mechanism enables our method to automatically use every piece of non-occluded region, regardless of shape, in the recognition process. The encouraging results demonstrate the feasibility and effectiveness of using syntactic methods for face recognition from a single exemplar image per person, breaking the barrier that prevents string matching techniques from being used for addressing complex image recognition problems. The proposed method not only achieved significantly better performance in recognizing partially occluded faces, but also showed its ability to perform direct matching between sketch faces and photo faces. © 1992-2012 IEEE.","Ensemble string matching; face recognition; occlusion; partial matching; sketch recognition; stringface; syntactic"
"Wei X., Li C.-T.","Fixation and saccade based face recognition from single image per person with various occlusions and expressions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884926993&doi=10.1109%2fCVPRW.2013.18&partnerID=40&md5=86347c28d67559d45cdfd455f4dab4a0","Face recognition technique is widely used in the real-world applications over the past decade. Different from other biometric traits such as fingerprint and iris, face is the biological nature for humans to recognise a person even met just once. In this paper, we propose a novel method, which simulates the mechanism of fixations and saccades in human visual perception, to handle the face recognition from single image per person problem. Our method is robust to the local deformations of the face (i.e., expression changes and occlusions). Especially for the occlusion related problems, which have not received enough attentions compared with other challenging variations of illumination, expression and pose, our method significantly outperforms the state-of-the-art approaches despite various types of occlusions. Experimental results on the FRGC and the AR databases confirm the effectiveness of our method. © 2013 IEEE.","biometrics; expression; face; face recognition; fixation; human visual perception; occlusion; saccade"
"Devi A., Kavitha A., Marimuthu A.","An improved self-updating face recognition authentication system","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884263113&partnerID=40&md5=c8f009b449dfe49b7e6bfbac1dbdf376","Face recognition authentication system has become an active research area in the field of biometrics and security. A number of research works have been developed and is available in the literature. Although the available approaches provide good results under particular conditions, the illumination alterations, occlusions and recognition time are still main issues in face recognition authentication systems (FRAS). The main reason for the overall performance degradation is due to the transformations in appearance of the user based on the aspects like ageing, beard growth, sun-tan etc. In order to overcome the above drawback, Self-update process has been developed in which, the system learns the biometric attributes of the user every time the user interacts with the system and the information gets updated automatically. A more common issue in biometric systems is the corruption of biometric traits due to misclassification. This research utilizes an efficient FRAS, based on three classification algorithms. The proposed method consists of various processes like Face segmentation, Face Normalization and Classification. Efficient techniques have been used in each phase of the FRAS to get improved results. © 2013 Praise Worthy Prize S.r.l. - All rights reserved.","Adaptive Systems; Face Recognition; Self-Confidence Measures; Self-Update Procedure; Template Update"
"Sharma M., Prakash S., Gupta P.","An efficient partial occluded face recognition system","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878488306&doi=10.1016%2fj.neucom.2011.12.063&partnerID=40&md5=1bed727ea552e1ab23ddeab02481e089","This paper presents an efficient face recognition system which is invariant to partial occlusion. The proposed system makes use of Eigen faces and Gabor wavelet filters to handle occlusion. It divides each face image into a set of sub-images and makes use of Gabor filters to extract features from non-occluded sub-images. Matching between two face images is performed by comparing features of non-occluded regions of two images. The system has been tested on AR face database containing 2600 occluded images of 100 subjects. Experimental results reveal better performance compared to all well known systems which are invariant to partial occlusion. © 2012 Elsevier B.V.","City block distance; Eigen faces; Gabor filter; Principal component analysis"
"Vera-Rodriguez R., Tome P., Fierrez J., Exposito N., Vega F.J.","Analysis of the variability of facial landmarks in a forensic scenario","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881346887&doi=10.1109%2fIWBF.2013.6547304&partnerID=40&md5=d967d161bd6265a3e15e794e62cac2ec","This paper reports an study of the variability of facial landmarks in a forensic scenario. This variability is affected by two factors: on the one hand, the precision in which the landmarks are tagged (manually or automatically), and on the other hand some other variability factors such as the pose, expression, occlusions, etc. For this study, a mugshot database of 50 persons has been collected following the procedure used by the Spanish Guardia Civil. Mugshots are taken with three distances between the persons and the camera (3, 2, 1 meters) showing the full body, the upper body and the face respectively, obtaining in total 1200 images. 21 facial landmarks are defined and the database was manually tagged imitating the procedure followed by a forensic examiner. This paper analyses the facial landmarking variability for the three distances considered, and also considering the differences obtained for male and female. Results show that landmarks located in the outer part of the face (highest end of the head, ears and chin) present a higher level of variability compared to the landmarks located the inner face (eye region, and nose). Regarding the gender, the landmarks placed in the outer part of the face present a higher level of variability for women compared to men. © 2013 IEEE.","data analysis; face recognition; Forensics"
"Wei X., Li C.-T., Hu Y.","Robust face recognition with occlusions in both reference and query images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881335455&doi=10.1109%2fIWBF.2013.6547305&partnerID=40&md5=c7531343614e745da121188f417392b6","Face recognition (FR) systems in real environment need to deal with uncontrolled variations in face images such as occlusions and disguise. Most of the current FR algorithms do not consider the fact that occlusions may exist in both reference and query images. In this paper, we summarise three occlusion cases that a realistic FR system should take account of. We present a novel non-parametric classification method to handle the occlusion related problems. Our method represents a face image as a sub-patch sequence which maintains the inherent structure information of the face. Matching is based on the Image-to-Class distance from a query sequence to all reference sequences of an enrolled class. Experimental results on public databases verify the effectiveness and robustness of the proposed method. © 2013 IEEE.","Biometrics; Dynamic Time Warping; Face recognition; Image-to-Class distance; Occlusion"
"Abaza A., Harrison M.F.","Ear recognition: A complete system","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881044796&doi=10.1117%2f12.2015946&partnerID=40&md5=3c6930d80d192bbc71c520961760e679","Ear Recognition has recently received significant attention in the literature. Even though current ear recognition systems have reached a certain level of maturity, their success is still limited. This paper presents an efficient complete ear-based biometric system that can process five frames/sec; Hence it can be used for surveillance applications. The ear detection is achieved using Haar features arranged in a cascaded Adaboost classifier. The feature extraction is based on dividing the ear image into several blocks from which Local Binary Pattern feature distributions are extracted. These feature distributions are then fused at the feature level to represent the original ear texture in the classification stage. The contribution of this paper is three fold: (i) Applying a new technique for ear feature extraction, and studying various optimization parameters for that technique; (ii) Presenting a practical ear recognition system and a detailed analysis about error propagation in that system; (iii) Studying the occlusion effect of several ear parts. Detailed experiments show that the proposed ear recognition system achieved better performance (94:34%) compared to other shape-based systems as Scaleinvariant feature transform (67:92%). The proposed approach can also handle efficiently hair occlusion. Experimental results show that the proposed system can achieve about (78%) rank-1 identification, even in presence of 60% occlusion. © 2013 SPIE.","Ear recognition; Haar cascade adaboost classifier; Hair occlusion; Local binary pattern"
"Drira H., Ben Amor B., Srivastava A., Daoudi M., Slama R.","3D Face recognition under expressions, occlusions, and pose variations","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880908756&doi=10.1109%2fTPAMI.2013.48&partnerID=40&md5=4bf9bde4671ecf69df46448b7ee8446d","We propose a novel geometric framework for analyzing 3D faces, with the specific goals of comparing, matching, and averaging their shapes. Here we represent facial surfaces by radial curves emanating from the nose tips and use elastic shape analysis of these curves to develop a Riemannian framework for analyzing shapes of full facial surfaces. This representation, along with the elastic Riemannian metric, seems natural for measuring facial deformations and is robust to challenges such as large facial expressions (especially those with open mouths), large pose variations, missing parts, and partial occlusions due to glasses, hair, and so on. This framework is shown to be promising from both&#x2014;empirical and theoretical&#x2014;perspectives. In terms of the empirical evaluation, our results match or improve upon the state-of-the-art methods on three prominent databases: FRGCv2, GavabDB, and Bosphorus, each posing a different type of challenge. From a theoretical perspective, this framework allows for formal statistical inferences, such as the estimation of missing facial parts using PCA on tangent spaces and computing average shapes. © 1979-2012 IEEE.","3D face recognition; biometrics; data restoration; quality control; shape analysis"
"Bindu A., Ravi Kumar C.N., Harsha S., Bhaskar N.","Facial boundary image reconstruction using elliptical approximation and convex hull","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880678911&doi=10.1007%2f978-81-322-1143-3_2&partnerID=40&md5=f9a789c966d1770155815bbbfefd3125","The Stretch of Biometrics' applications can only be limited by limiting ones' imagination! Biometrics is the Science and Technology of measuring and analyzing biological data for authentication purposes. In addition to verification the guiding force behind biometric verification has been convinience. Face enjoys a prime position in the realm of biometrics because it is very easily accessible when compared to the other biometrics. Efficient accomplishment of Face Recognition confronts innumerable hurdles in the form of variations in lighting conditions during image capture, Occlusions, damage in facial portions due to accidents etc. The application of Facial Image Inpainting also fails when the occlusions or the deformalities are present across the boundary of the object of interest(face), since the bounds for the application of the inpainting algorithm is not precisely defined. Hence recovery of the complete picture of a human face from partially occluded images is quite a challenge in Image Processing. The proposed FIREACH algorithm concentrates on the generation of a convex hull and a non linear elliptical approximation of the depleted and partially visible boundary of the human face, given different parameters to achieve an Efficient Boundary Recovery. The Boundary Recovery Algorithm is a pre-processing step which aids in setting up of a suitable platform for the proficient application of the Facial Image Inpainting. © 2013 Springer.","Contour recovery; Convex hull; Identity retrieval; Nonlinear elliptical approximation; Region of interest"
"Jhodge S., Chiddarwar G., Shinde G.","A new SAFR tool for face recognition using EGVLBP-CMI-LDA wrapped with secured DWT based steganography","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879847846&doi=10.1109%2fIAdCC.2013.6514370&partnerID=40&md5=8f1301c376065c46d20bdb2a3fc1f654","Face recognition technique nowadays is emerging as the most significant and challenging aspects in terms of security for identification of images in various fields viz. banking, police records, biometric etc. other than an individual's thumb and documented identification proofs. Till date for efficient net banking to be initiated, one has to provide the appropriate user name and password for purpose of authentication. This project introduces a vehicle to take a step forward in easy and more reliable authentication of an individual by providing Face Image along with User Name and Password to the system. In this an individual's face is identified by biometric authentication support with which, only a person whose account is, can access it. However while transferring this sensitive data of user image, from client machine to bank server it has to be protected from hackers and intruders from manhandling it, hence it is transferred using covert communication called Wavelet Decomposition based steganography. As face images are affected by different expressions, poses, occlusions, illuminations and aging over a period of time and it differs from the same person than those from different ones is the main difficult task in face recognition. Whenever image information is jointly co-ordinated in three aspects viz. image space, scale and orientation domains they carry much higher clues than seen in each domain individually. In the proposed method combination of Local Binary Pattern (LBP) and Gabor features are used to increase the face recognition performance significantly to compare individual's face presentations. Hence face recognition and representation of Gabor faces are done using E-GV-LBP and CMI-LDA based feature recognition method. Gabor faces uses space, scale and orientation to support accurate face recognition, making net banking easier, authentic, reliable and user friendly. © 2013 IEEE.","CMI (Conditional Mutual Information); DWT (Discrete Wavelet Transformation); E-GV-LBP (Effective Gabor Volume Linear Binary Pattern)"
"Vijaya Kumar B.V.K., Boddeti V.N., Smereka J.M., Thornton J., Savvides M.","Application of bayesian graphical models to iris recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878082542&doi=10.1016%2fB978-0-444-53859-8.00015-1&partnerID=40&md5=ce51091db2a5bd287bbaafeb2a021914","Recognition of humans based on their biometric signatures is becoming of increasing importance because of its applications in access security, reliable identification for benefits distribution and homeland security among others. Popular biometric modalities include face images, fingerprints, iris images, palm prints, gait patterns, voice, etc. Iris images are of significant interest because of the excellent recognition rates they offer in controlled image acquisition conditions where the image quality is expected to be good enough to capture the details of the iris. However, in more realistic scenarios, iris images may not be of necessary quality because of image distortions and occlusions due to eyelids and eyelashes and the recognition rates provided by standard approaches may not be sufficient. In this chapter, we discuss how Bayesian graphical models can be used to achieve improved iris recognition in the presence of image impairments such as nonlinear deformations and occlusions. We illustrate the performance of these methods on sample iris image data sets. © 2013 Elsevier B.V.","Biometrics; Correlation filters; FOCS data; Graphical models; Iris; MAP estimation; ROC curve"
"Alyuz N., Gokberk B., Akarun L.","3-D face recognition under occlusion using masked projection","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876798626&doi=10.1109%2fTIFS.2013.2256130&partnerID=40&md5=a03af22f246e481592c7554a86b64795","With advances in sensor technology, the three-dimensional (3-D) face has become an emerging biometric modality, preferred especially in high security applications. However, dealing with occlusions covering the facial surface is a great challenge, which should be handled to enable applicability to fully automatic security systems. In this paper, we propose a fully automatic 3-D face recognition system which is robust to occlusions. We basically consider two problems: 1) occlusion handling for surface registration, and 2) missing data handling for classification based on subspace analysis techniques. For the alignment problem, we employ an adaptively-selected-model-based registration scheme, where a face model is selected for an occluded face such that only the valid nonoccluded patches are utilized. After registering to the model, occlusions are detected and removed. In the classification stage, a masking strategy, which we call masked projection, is proposed to enable the use of subspace analysis techniques with incomplete data. Furthermore, a regional scheme suitable for occlusion handling is incorporated in classification to improve the overall results. Experimental results on two databases with realistic facial occlusions, namely, the Bosphorus and the UMB-DB, are reported. Experimental results confirm that registration based on the adaptively selected model together with the masked subspace analysis classification offer an occlusion robust face recognition system. © 2005-2012 IEEE.","3-D face recognition; 3-D registration; biometrics; curvature descriptors"
"Yang M., Zhang L., Yang J., Zhang D.","Regularized robust coding for face recognition.","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883661521&doi=10.1109%2fTIP.2012.2235849&partnerID=40&md5=98eccc0ecc4cc1f703c2b5b863eabebc","Recently the sparse representation based classification (SRC) has been proposed for robust face recognition (FR). In SRC, the testing image is coded as a sparse linear combination of the training samples, and the representation fidelity is measured by the l2-norm or l1 -norm of the coding residual. Such a sparse coding model assumes that the coding residual follows Gaussian or Laplacian distribution, which may not be effective enough to describe the coding residual in practical FR systems. Meanwhile, the sparsity constraint on the coding coefficients makes the computational cost of SRC very high. In this paper, we propose a new face coding model, namely regularized robust coding (RRC), which could robustly regress a given signal with regularized regression coefficients. By assuming that the coding residual and the coding coefficient are respectively independent and identically distributed, the RRC seeks for a maximum a posterior solution of the coding problem. An iteratively reweighted regularized robust coding (IR(3)C) algorithm is proposed to solve the RRC model efficiently. Extensive experiments on representative face databases demonstrate that the RRC is much more effective and efficient than state-of-the-art sparse representation based methods in dealing with face occlusion, corruption, lighting, and expression changes, etc.",
"Singh G., Kolekar M.H.","A distributed weighted voting approach for accurate eye center estimation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878128828&partnerID=40&md5=7f94a3ecc3b846d716e200a6abc98e7d","This paper proposes a novel approach for accurate estimation of eye center in face images. A distributed voting based approach in which every pixel votes is adopted for potential eye center candidates. The votes are distributed over a subset of pixels which lie in a direction which is opposite to gradient direction and the weightage of votes is distributed according to a novel mechanism. First, image is normalized to eliminate illumination variations and its edge map is generated using Canny edge detector. Distributed voting is applied on the edge image to generate different eye center candidates. Morphological closing and local maxima search are used to reduce the number of candidates. A classifier based on spatial and intensity information is used to choose the correct candidates for the locations of eye center. The proposed approach was tested on BioID face database and resulted in better Iris detection rate than the state-of-the-art. The proposed approach is robust against illumination variation, small pose variations, presence of eye glasses and partial occlusion of eyes. © 2013, DESIDOC.","Biomarkers; Biometrics; Eye center estimation; Iris recognition"
"Li X.-X., Dai D.-Q., Zhang X.-F., Ren C.-X.","Structured sparse error coding for face recognition with occlusion","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875144046&doi=10.1109%2fTIP.2013.2237920&partnerID=40&md5=a295676175b09a5364faef495e45b254","Face recognition with occlusion is common in the real world. Inspired by the works of structured sparse representation, we try to explore the structure of the error incurred by occlusion from two aspects: the error morphology and the error distribution. Since human beings recognize the occlusion mainly according to its region shape or profile without knowing accurately what the occlusion is, we argue that the shape of the occlusion is also an important feature. We propose a morphological graph model to describe the morphological structure of the error. Due to the uncertainty of the occlusion, the distribution of the error incurred by occlusion is also uncertain. However, we observe that the unoccluded part and the occluded part of the error measured by the correntropy induced metric follow the exponential distribution, respectively. Incorporating the two aspects of the error structure, we propose the structured sparse error coding for face recognition with occlusion. Our extensive experiments demonstrate that the proposed method is more stable and has higher breakdown point in dealing with the occlusion problems in face recognition as compared to the related state-of-the-art methods, especially for the extreme situation, such as the high level occlusion and the low feature dimension. © 1992-2012 IEEE.","Face recognition; high-breakdown point classification; malicious occlusion; outlier detection; structured sparse representation"
"De Marsico M., Nappi M., Riccio D., Tortora G.","Entropy-based template analysis in face biometric identification systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876094774&doi=10.1007%2fs11760-013-0451-4&partnerID=40&md5=59e74ed21f456953e0028edb28d9d173","The accuracy of a biometric matching algorithm relies on its ability to better separate score distributions for genuine and impostor subjects. However, capture conditions (e. g. illumination or acquisition devices) as well as factors related to the subject at hand (e. g. pose or occlusions) may even take a generally accurate algorithm to provide incorrect answers. Techniques for face classification are still too sensitive to image distortion, and this limit hinders their use in large-scale commercial applications, which are typically run in uncontrolled settings. This paper will join the notion of quality with the further interesting concept of representativeness of a biometric sample, taking into account the case of more samples per subject. Though being of excellent quality, the gallery samples belonging to a certain subject might be very (too much) similar among them, so that even a moderately different sample of the same subject in input will cause an error. This seems to indicate that quality measures alone are not able to guarantee good performances. In practice, a subject gallery should include a sufficient amount of possible variations, in order to allow correct recognition in different situations. We call this gallery feature representativeness. A significant feature to consider together with quality is the sufficient representativeness of (each) subject's gallery. A strategy to address this problem is to investigate the role of the entropy, which is computed over a set of samples of a same subject. The paper will present a number of applications of such a measure in handling the galleries of the different users who are registered in a system. The resulting criteria might also guide template updating, to assure gallery representativeness over time. © 2013 Springer-Verlag London.","Entropy; Face recognition; Image Quality Index; Pose and illumination distortions"
"Liu P., Wang Y., Huang D., Zhang Z., Chen L.","Learning the spherical harmonic features for 3-D face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873305344&doi=10.1109%2fTIP.2012.2222897&partnerID=40&md5=6a8c7bc9c7d33565666458b4bc989bd5","In this paper, a competitive method for 3-D face recognition (FR) using spherical harmonic features (SHF) is proposed. With this solution, 3-D face models are characterized by the energies contained in spherical harmonics with different frequencies, thereby enabling the capture of both gross shape and fine surface details of a 3-D facial surface. This is in clear contrast to most 3-D FR techniques which are either holistic or feature based, using local features extracted from distinctive points. First, 3-D face models are represented in a canonical representation, namely, spherical depth map, by which SHF can be calculated. Then, considering the predictive contribution of each SHF feature, especially in the presence of facial expression and occlusion, feature selection methods are used to improve the predictive performance and provide faster and more cost-effective predictors. Experiments have been carried out on three public 3-D face datasets, SHREC2007, FRGC v2.0, and Bosphorus, with increasing difficulties in terms of facial expression, pose, and occlusion, and which demonstrate the effectiveness of the proposed method. © 1992-2012 IEEE.","3-D face recognition; feature selection; spherical depth map; spherical harmonics"
"Ali Akber Dewan M., Granger E., Roli F., Sabourin R., Marcialis G.L.","Comparison of adaptive appearance methods for tracking faces in video surveillance","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906828574&partnerID=40&md5=c0a52fd1984fe23ad582e25d2091bba0","Face recognition is increasingly employed by public safety organizations in decision support systems for video surveillance, to detect the presence of individuals of interest. In the context of spatiotemporal face recognition, tracking is an important function used to locate, follow and regroup faces of different individuals in a scene. Techniques for face tracking in video surveillance should be robust to changes in pose, expression and illumination, as well as occlusion in cluttered scenes. Given these challenges, trackers based on adaptive appearance modelling (AAM) typically improve target's state estimation because they initiate and update an internal face model per individual according to changes in facial appearance. In this paper, the performance of three AAM trackers - Incremental Visual Tracking (IVT), Tracking Learning Detection (TLD) and Discriminative Sparse Coding based Tracking (DSCT) - are compared for face tracking with video surveillance applications in mind. These methods are evaluated according to area overlap error, tracking error and time complexity using Chokepoint videos collected in uncontrolled video-surveillance environments, where individuals walk through portals. Results indicate that IVT outperforms the others in its ability to accurately track faces in the presence of occlusion, and under variations in pose, scale and lighting. Further characterization of IVT indicates that using a small batch size and forgetting factor during update provide better tracking accuracy when face tracks changes in their capture conditions. When conditions change more gradually, IVT benefits from assessing facial quality before updating face models.","Adaptive appearance methods; Biometrics; Face tracking; On-line and incremental learning; Spatiotemporal face recognition; Video surveillance"
"Cui C., Asari V.K.","Adaptive weighted local textural features for illumination, expression, and occlusion invariant face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897466773&doi=10.1117%2f12.2037846&partnerID=40&md5=aa7a52a4026fbccde0c37eaa78d36a69","Biometric features such as fingerprints, iris patterns, and face features help to identify people and restrict access to secure areas by performing advanced pattern analysis and matching. Face recognition is one of the most promising biometric methodologies for human identification in a non-cooperative security environment. However, the recognition results obtained by face recognition systems are a affected by several variations that may happen to the patterns in an unrestricted environment. As a result, several algorithms have been developed for extracting different facial features for face recognition. Due to the various possible challenges of data captured at different lighting conditions, viewing angles, facial expressions, and partial occlusions in natural environmental conditions, automatic facial recognition still remains as a difficult issue that needs to be resolved. In this paper, we propose a novel approach to tackling some of these issues by analyzing the local textural descriptions for facial feature representation. The textural information is extracted by an enhanced local binary pattern (ELBP) description of all the local regions of the face. The relationship of each pixel with respect to its neighborhood is extracted and employed to calculate the new representation. ELBP reconstructs a much better textural feature extraction vector from an original gray level image in different lighting conditions. The dimensionality of the texture image is reduced by principal component analysis performed on each local face region. Each low dimensional vector representing a local region is now weighted based on the significance of the sub-region. The weight of each sub-region is determined by employing the local variance estimate of the respective region, which represents the significance of the region. The final facial textural feature vector is obtained by concatenating the reduced dimensional weight sets of all the modules (sub-regions) of the face image. Experiments conducted on various popular face databases show promising performance of the proposed algorithm in varying lighting, expression, and partial occlusion conditions. Four databases were used for testing the performance of the proposed system: Yale Face database, Extended Yale Face database B, Japanese Female Facial Expression database, and CMU AMP Facial Expression database. The experimental results in all four databases show the effectiveness of the proposed system. Also, the computation cost is lower because of the simplified calculation steps. Research work is progressing to investigate the effectiveness of the proposed face recognition method on pose-varying conditions as well. It is envisaged that a multilane approach of trained frameworks at different pose bins and an appropriate voting strategy would lead to a good recognition rate in such situation.","Enhanced Local Binary Pattern; Face Recognition; Feature Extraction; Weighted Modular Principal Component Analysis"
"Patil N.K., Vasudha S., Boregowda L.R.","Performance improvement of face recognition system by decomposition of local features using discrete wavelet transforms","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901363542&doi=10.1109%2fISED.2013.41&partnerID=40&md5=64f0717ad25a845128abbbed7537aafb","As one of the most sought after applications of image analysis, face recognition has received significant attention, especially during the past two decades. Automatic human face recognition has received substantial attention in the recent few years, from researchers in biometrics, pattern recognition and computer vision communities, owing to the high demand for advanced security and authentication needs. Although the existing automated machine recognition systems have certain level of maturity but their accomplishments are limited due to real time challenges. For example, face recognition for the images which are acquired in high contrast with different levels of illumination is a critical problem. Various applications in defense and commercial areas demand real time and high level precision face recognition systems. In turn accuracy involves many floating point operations which will be costly as well as complex in terms of implementation. The major metric in modeling the performance of a face recognition system is its accuracy of recognition. This paper proposes a novel method of face recognition using de-correlation of local features using Discrete Wavelet Transforms (DWT) which improves the recognition accuracy. It also avoids generalizability problem which is caused due to subspace discriminant analysis or statistical learning procedure by using a non-statistical procedure which avoids training step for face samples. This proposed method performs well with images with partial occlusion and images with lighting variations as the local patch of the face is divided into several different patches. © 2013 IEEE.","De-Correlation; Discrete Wavelet Transform; False Acceptance Ratio; False Rejection Ratio; Gabor filter; Local Binary Pattern; Performance modeling"
"Vasudha S., Patil N.K., Boregowda L.R.","Rule based features selection for the performance improvement of face recognition system","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898482487&doi=10.1109%2fC2SPCA.2013.6749387&partnerID=40&md5=3e0b4e4d3e474beb8647cb10244c244f","Face recognition is one of the important applications of image processing and it has gained significant attention in wide range of law enforcement areas in which security is the prime concern. Face image is most popular non-intrusive and non-invasive biometrics whose image can easily be taken without user co-operation. Although the existing automated machine recognition systems have certain level of maturity but their accomplishments are limited due to real time challenges and face recognition systems are impressively sensitive to appearance variations due to lighting, expression and aging. The major metric in modeling the performance of a face recognition system is its accuracy of recognition. This paper proposes a novel method which improves the recognition accuracy as well as avoids face datasets being tampered through image splicing techniques. It also avoids generalizability problem which is caused due to subspace discriminant analysis or statistical learning procedure by using a non-statistical procedure which avoids training step for face samples. This proposed method performs well with images with partial occlusion and images with lighting variations as the local patch of the face is divided into several different patches. The performance improvement is shown considerably high in terms of recognition rate and storage space by storing train images in compressed domain and selecting significant features from superset if feature vectors for actual recognition. © 2013 IEEE.","Discrete Cosine Transform; False Acceptance Ratio; False rejection Ratio; Gabor filter; Image splicing; Local Binary Pattern; Performance modeling"
"Frigerio E., Marcon M., Tubaro S.","Does the skin texture contain useful information to state the identity?","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906841066&partnerID=40&md5=113f1b38618b8198fa000b340c83d3c6","In this article we propose a new algorithm for face recognition based only on the appearance of the cheeks, the face-portion least affected by occlusions. Our aim is to demonstrate that skin contains useful information to automatically discriminate the identity of a person. The maximally homogeneous regions of each cheek are estimated and represented by the histograms of the occurrences of the uniform and rotation invariant Local Ternary Patterns. We test our algorithm in an identification and a verification scenario using the FRGC database. Experimental results show that the cheek skin is a valid biometric feature. Moreover the proposed method effectively addresses changes in lighting, pose (little changes) and expression.","Face identification; Local binary pattern; Rotation invariance; Skin texture; Uniform patterns"
"An L., Chen X., Kafai M., Yang S., Bhanu B.","Improving person re-identification by soft biometrics based reranking","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899542618&doi=10.1109%2fICDSC.2013.6778216&partnerID=40&md5=08701f4dfbc720c9ee4a9249ed985ead","The problem of person re-identification is to recognize a target subject across non-overlapping distributed cameras at different times and locations. The applications of person re-identification include security, surveillance, multi-camera tracking, etc. In a real-world scenario, person re-identification is challenging due to the dramatic changes in a subject's appearance in terms of pose, illumination, background, and occlusion. Existing approaches either try to design robust features to identify a subject across different views or learn distance metrics to maximize the similarity between different views of the same person and minimize the similarity between different views of different persons. In this paper, we aim at improving the re-identification performance by reranking the returned results based on soft biometric attributes, such as gender, which can describe probe and gallery subjects at a higher level. During reranking, the soft biometric attributes are detected and attribute-based distance scores are calculated between pairs of images by using a regression model. These distance scores are used for reranking the initially returned matches. Experiments on a benchmark database with different baseline re-identification methods show that reranking improves the recognition accuracy by moving upwards the returned matches from gallery that share the same soft biometric attributes as the probe subject. © 2013 IEEE.",
"Pushparaj V., Gurunathan U., Arumugam B.","Missing tooth identification and teeth numbering in dental X-ray and photographic imaging","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896729252&doi=10.1504%2fIJBET.2013.057931&partnerID=40&md5=e796d324e528f10c2cc0ccd2895ba0f3","In major disasters like air-plane crash, bomb-blast, fire accident and flood, the biometric means like finger print, retina, hand print, palm print, face details etc., may not be available. Hence in such a circumstance there is a need for another reliable, unique and useful means like tooth to develop an automated dental identification system. For dental biometric system the antemortem records has to be matched against the post mortem records. In the dental identification system, missing tooth detection and teeth numbering are few of the notable issues. This paper addresses these issues with the help of spline function, bifurcation techniques and template matching approaches. This review focuses these issues both for radiographic and photographic dental images since adequate radiographic records may not be available in almost all the instances. Experimental evaluation shows satisfied results which will abet the dental biometrics. Copyright © 2013 Inderscience Enterprises Ltd.","Bifurcation; Dental photographs; Dental radiography; Missing tooth; Morphological operation; Spline function"
"Min R., Dugelay J.-L.","Inpainting of sparse occlusion in face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875858579&doi=10.1109%2fICIP.2012.6467137&partnerID=40&md5=fb87836f9f42243518c6e0ff9e6031fe","Facial occlusion is a critical issue in many face recognition applications. Existing approaches of face recognition under occlusion conditions mainly focus on the conventional facial accessories (such as sunglasses and scarf) and thus presume that the occluded region is dense and contiguous. Yet due to the wide variety of natural sources which can occlude a human face in uncontrolled environments, methods based on the dense assumption are not robust to thin and randomly distributed occlusions. This paper presents the solution to a newly identified facial occlusion problem - sparse occlusion in the context of face biometrics in video surveillance. We show that the occluded pixels can be detected in the low-rank structure of a canonical face set under the Robust-PCA framework; and the occluded part can be inpainted solely based on the nonoccluded part and a Fields-of-Experts prior via spatial inference. Experiments demonstrate that the proposed approach significantly improve various face recognition algorithms in presence of complex sparse occlusions. © 2012 IEEE.","Face Recognition; Fields-of-Experts; Inpainting; Robust-PCA; Sparse Occlusion"
"Benzaoui A., Bourouba H., Boukrouche A.","System for automatic faces detection","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875834063&doi=10.1109%2fIPTA.2012.6469545&partnerID=40&md5=9e6e2ad05b1c79c56a14ec8c3e418979","The effectiveness of biometric authentication based on face mainly depends on the method used to locate the face in the image or video. This paper presents a hybrid system for faces detection, in a color image or video, in unconstrained cases, i.e. situations in which illumination, pose, occlusion and size of the face are uncontrolled. To do this, the new method of detection proposed in this system is based primarily on a technique of automatic learning by using the decision of three neural networks, a new method of feature extraction based on the principal of energy compaction in the DC coefficient using the discrete cosine transform and a technique of segmentation by skin color to reduce the space of research and to accelerate the process of detection. A whole of pictures (faces and no faces) are transformed to vectors of data which will be used for entrain the neural networks to separate between the two classes while the discrete cosine transform is used to reduce the dimension of the vectors, to eliminate the redundancies of information, and to store only the useful information in a minimum number of coefficients. The experimental results have showed that this hybridization of methods will gave a very significant improvement of the rate of the recognition, quality of detection and the time of execution. © 2012 IEEE.","discrete cosine transform; face detection; facial biometrics; neural networks"
"Das A.","Face recognition in reduced Eigen-plane","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874399125&doi=10.1109%2fCODIS.2012.6422279&partnerID=40&md5=68809e81cf4140feb1c4fdde190bcd15","This paper proposes a 2D face recognition technique in Eigen-Space with reduced feature vector size. In this paper image of each person are mapped to covariance Eigen plane to generate the feature vector. The technique is demonstrated to be a satisfactory real time face recognition approach as it can work on multiple types of face emotion instances and can handle varying degrees of occlusion. Moreover the feature representations of the faces are in scalar form and hence require low computational overheads. Absolute scalar difference is used for classification. The technique has achieved high recognition accuracy. © 2012 IEEE.","Biometrics; Computer vision; Covariance matrix; Eigen space; Face recognition"
"Lakshmiprabha N.S., Majumder S.","Face recognition system invariant to plastic surgery","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874366687&doi=10.1109%2fISDA.2012.6416547&partnerID=40&md5=532e70f7ca9cda41beb8f0648aca231b","Facial plastic surgery changes facial features to large extend and thus creating a major problem to face recognition system. This paper proposes a new face recognition system using novel shape local binary texture (SLBT) feature from face images cascaded with periocular feature for plastic surgery invariant face recognition. In-spite of many uniqueness and advantages, the existing feature extraction methods are capable of extracting either shape or texture feature. A method which can extract both shape and texture feature is more attractive. The proposed SLBT can extract global shape, local shape and texture information from a face image by extracting local binary pattern (LBP) instead of direct intensity values from shape free patch of active appearance model (AAM). The experiments conducted using MUCT and plastic surgery face database shows that the SLBT feature performs better than AAM and LBP features. Further increase in recognition rate is achieved by cascading SLBT features from face with LBP features from periocular regions. The result from surgical and non-surgical face database shows that the proposed face recognition system can easily tackle illumination, pose, expression, occlusion and plastic surgery variations in face images. © 2012 IEEE.","Active appearance model; Face recognition; Local binary pattern and Periocular biometrics; Plastic surgery; Shape local binary texture"
"Santiago-Ramírez E., González-Fraga J.Á., Lázaro-Martínez S.","Face recognition and tracking using unconstrained non-linear correlation filters","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872521221&doi=10.1016%2fj.proeng.2012.04.180&partnerID=40&md5=2b01ee294e962fb30bc3dd8340ffd63c","Recognizing and tracking a face in a video sequence is a challenging task, specially when dealing with people and uncontrolled environments. This due to the natural variability, such as expressions, illumination, pose, occlusions, etc. This paper propose and evaluate two strategies based on correlation for face recognition and face tracking, respectively. The proposals can be used in cascade for face tracking, first a face recognition filter is synthesized with facial regions that allow recognition of a person even when the facial image test is presented in partial form and/or contains variations in illumination, reaching approximately 95% of effectiveness. Then the face tracking in a video sequence, is done using an adaptive unconstrained non-linear composite filter. This filter is adapted to the changes that the face suffers through the video sequence. Both strategies can be combined or used separately in a biometric system that allows the identification and the tracking of a person in a video sequence. © 2012 Published by Elsevier Ltd.","Correlation filters; Face recognition; Face tracking; Performance tracking metrics"
"Erdogmus N., Daniel L., Dugelay J.-L.","Probabilistic fusion of regional scores in 3D face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875851163&doi=10.1109%2fICIP.2012.6467145&partnerID=40&md5=e2d278a8cb46aafc13ea4f58173af713","Information fusion in biometrics mostly relates to multi-biometric systems which attempt to improve the performance of individual matchers: multi-sensor, multi-algorithm, multimodal, etc. However, in addition to these scenarios, the need for methods to fuse the individual regional classifiers has also emerged, due to the increasing number of region-based methods proposed to overcome expression and occlusion problems in face recognition. In this paper, we present a combination approach by converting the regional match scores into probabilities with the help of estimated regional confidence measures. Initially, face is broken into several segments and similarity and confidence scores are obtained. Then, the posteriori probabilities of the user being genuine are calculated in each region given these two scores. For this calculation, the conditional densities are obtained on the training samples by applying non-parametric kernel density estimation separately for different intervals of confidence levels. Experimental results demonstrate that the inclusion of the regional confidence measures via probabilistic conversion is much more advantageous when compared to weighted sum of original scores. © 2012 IEEE.","face recognition; probabilistic approach; Region-based; score fusion"
"Ramkumar R.P., Arumugam S.","A novel iris recognition algorithm","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873312930&doi=10.1109%2fICCCNT.2012.6396075&partnerID=40&md5=2c7ecc58470ed8de58fc8a7ed394246b","Goal of the proposed iris recognition is to recognize human identity through the textural characteristics of one's iris muscular patterns. Even though eye color is dependent on heredity, in contrast to this, iris is independent and uncorrelated even for twins. Out of various biometrics such as finger and hand geometry, face, ear and voice recognition, iris recognition has been acknowledged as one of the most accurate biometric modalities because of its high recognition rate. In this proposed iris recognition method, pupil localization is done by using negative function and four neighbours method so that irrespective of pupil's contour, either circle or ellipse, the pupil's boundary is detected accurately. For iris outer boundary detection, contrast enhancement, special wedges and thresholding techniques are used to isolate the specific iris regions without eyelid and eyelash occlusions. Now the resultant iris portion alone is transformed into polar coordinate system for normalization process. Histogram equalization technique is used for enhancing the normalized iris image. For feature extraction and matching process, cumulative sum-based change analysis and hamming distance are employed. When compared with the existing algorithms, this proposed algorithm is robust, accurate and also has low computational time and complexity. © 2012 IEEE.","cumulative-sum; hamming distance; iris localization; iris segmentation; pupil localization; thresholding"
"Boyali A., Kavakli M.","A robust gesture recognition algorithm based on sparse representation, random projections and compressed sensing","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871691277&doi=10.1109%2fICIEA.2012.6360730&partnerID=40&md5=fc922a9ee8f414cb2b97b51273e0474b","Compressed Sensing (CS) and Sparse Representation (SR) influenced the ways of signals are processed half a decade. The elegant solution to sparse signal recovery problem has found ground in several research fields such as machine learning and pattern recognition. The use of sparse representation and the solution of equations using ℓ1 minimization were utilized for face recognition problem under varying illumination and occlusion. Afterwards the idea was applied in biometrics to classify iris data. Similar to those studies, we use the discriminating nature of sparsity for the signals acquired in various signal domains and apply them to gesture recognition problem. The proposed algorithm in this context gives accurate recognition results over a recognition rate of 99% for user independent and 100% for user dependent gesture sets for fairly rich gesture dictionaries. © 2012 IEEE.","compressed sensing; random projection based gesture recognition algorithm; robust gesture recognition"
"Bhaskar H.","Integrated human target detection, identification and tracking for surveillance applications","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869832309&doi=10.1109%2fIS.2012.6335178&partnerID=40&md5=5755b4a12161cf0af96b3265db56651f","In recent years, a large amount of research efforts have been spent in the tracking human targets using one or more visual sensors (cameras) in both indoor and outdoor security and surveillance environments such as airports, metro stations, etc. However, in majority, the problem of associating a reliable identification signature to a detected target when in motion, has often been complicated due to changing target appearance, changes in lighting conditions and also because of partial or full occlusion. Therefore control operators have always been engaged in supervising the process of tagging specific targets of interest. Although the complementary field of human target identification based on biometrics (particularly via face recognition) has been well researched and mature enough; not much efforts has been directed in combining these technologies in-order to make security and surveillance operations fully autonomous. In this paper, this integration of simultaneous detection, tracking, and face-recognition-based identification of human targets from a static camera is proposed. The accuracy, efficiency and robustness of the this proposed framework is assessed and illustrated over different standard datasets across a wide range of scenarios using appropriate performance metrics. © 2012 IEEE.","face recognition; human detection; identification; real-time; target tracking"
"Shejin T., Sao A.K.","Significance of dictionary for sparse coding based face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869394468&partnerID=40&md5=764c7254ff757844196319c8b79a6781","Sparse representation based classification (SRC) successfully addresses the problem of face recognition under various illumination and occlusion conditions, if sufficient training images are given. This paper discusses the significance of dictionary in sparse coding based face recognition. We primarily address the problem of sufficiency of training data in various illumination conditions. The dictionary is generated using a lower dimensional representation of image, which emphasizes the subject specific unique information of the face image. This representation is called weighted decomposition (WD) face image, because it attempts to give more weightage to unique information of face image. The effect of illumination in computation of WD face image is reduced using edginess based representation of image, which is derived using one-dimensional (1-D) processing of image. 1-D processing provides multiple partial evidences, which are combined to enhance the face recognition performance. The experimental results suggest that the proposed approach addresses the issue of sufficiency of training data efficiently. © 2012 Gesellschaft fr Informatik.",
"Alyuz N., Gokberk B., Spreeuwers L., Veldhuis R., Akarun L.","Robust 3D face recognition in the presence of realistic occlusions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866780788&doi=10.1109%2fICB.2012.6199767&partnerID=40&md5=ccf05107e22d7d7a0c16c69a4c70589e","Facial occlusions pose significant problems for automatic face recognition systems. In this work, we propose a novel occlusion-resistant three-dimensional (3D) facial identification system. We show that, under extreme occlusions due to hair, hands, and eyeglasses, typical 3D face recognition systems exhibit poor performance. In order to deal with occlusions, our proposed system employs occlusion-resistant registration, occlusion detection, and regional classifiers. A two-step registration module first detects the nose region on the curvedness-weighted convex shape index map, and then performs fine alignment using nose-based Iterative Closest Point (ICP) algorithm. Occluded areas are determined automatically via a generic face model. After non-facial parts introduced by occlusions are removed, a variant of Gappy Principal Component Analysis (Gappy PCA) is used to restore the full face from occlusion-free facial surfaces. Experimental results obtained on realistically occluded facial images from the Bosphorus 3D face database shows that, with the use of score-level fusion of regional Linear Discriminant Analysis (LDA) classifiers, the proposed method improves rank-1 identification accuracy significantly: from 76.12% to 94.23%. © 2012 IEEE.",
"Zhu J., Cao D., Liu S., Lei Z., Li S.Z.","Discriminant analysis with Gabor phase for robust face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866781681&doi=10.1109%2fICB.2012.6199752&partnerID=40&md5=90427fc96f9085c11f87f8c30124e396","This paper presents an occlusion robust image representation method and apply it to face recognition. Inspired from the recent work [15], we propose a Gabor phase difference representation for occlusion robust face recognition. Based on the good ability of Gabor filters to capture image structure and the robustness to image occlusion shown in this paper, Gabor phase features are expected to be discriminative and robust for face representation in occlusion case. Besides, we adopt spectral regression based discriminant analysis with the extracted Gabor phase features to find the most discriminant subspace to classify different faces. In this way, an occlusion robust face image discriminant subspace is derived. Extensive experiments with various occlusion cases show the efficacy of the proposed method. © 2012 IEEE.",
"Ballihi L., Srivastava A., Ben Amor B., Daoudi M., Aboutajdine D.","Which 3D geometric facial features give up your identity?","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866778295&doi=10.1109%2fICB.2012.6199768&partnerID=40&md5=4f10d6ac7cde05506d1e3fc9de2af51a","The 3D face recognition literature has many papers that represent facial shapes as collections of curves of different kinds (level-curves, iso-level curves, radial curves, profiles, geodesic polarization, iso-depth lines, iso-stripes, etc.). In contrast with the holistic approaches, the approaches that match faces based on whole surfaces, the curve-based parametrization allows local analysis of facial shapes. This, in turn, facilitates handling of pose variations (probe image may correspond to a part of the face) or missing data (probe image is altered by occlusions. An important question is: Does the use of full set of curves leads to better performances? Among all facial curves, are there ones that are more relevant than others for the recognition task? We explicitly address these questions in this paper. We represent facial surfaces by collections of radial curves and iso-level curves, such that shapes of corresponding curves are compared using a Riemmannian framework, select the most discriminative curves (geometric features) using boosting. The experiment involving FRGCv2 dataset demonstrates the effectiveness of this feature selection by achieving 98.02% as rank-1 recognition rate. This selection also results in a more compact signature which significantly reduces the computational cost and the storage requirements for the face recognition system. © 2012 IEEE.",
"Singh A., Tiwari S., Singh S.K.","Performance of face recognition algorithms on dummy faces","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865197032&doi=10.1007%2f978-3-642-30157-5_22&partnerID=40&md5=c6b6b856c19a250d7928232ac5b7f7cd","Face recognition is becoming increasingly important in the contexts of computer vision, neuroscience, psychology, surveillance, credit card fraud detection, pattern recognition, neural network, content based video processing, assistive devices for visual impaired, etc. Face is a strong biometric trait for identification and hence criminals always try to hide their face by different artificial means such as plastic surgery, disguise and dummy. The availability of a comprehensive face database is crucial to test the performance of these face recognition algorithms. However, while existing publicly-available face databases contain face images with a wide variety of covariates such as poses, illumination, gestures and face occlusions but there is no dummy face database is available in public domain. The contributions of this paper are: i) Preparation of dummy face database of 50 subjects ii) Testing of face recognition algorithms on the dummy face database, iii) Critical analysis of four algorithms on dummy face database. © 2012 Springer-Verlag GmbH.","biometrics; dummy faces; Face recognition"
"Križaj J., Štruc V., Dobrišek S.","Robust 3D face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865039553&partnerID=40&md5=0664080c5477f776956248a5d852bcb7","Face recognition in uncontrolled environments is hindered by variations in illumination, pose, expression and occlusions of faces. Many practical face-recognition systems are affected by these variations. One way to increase the robustness to illumination and pose variations is to use 3D facial images. In this paper 3D face-recognition systems are presented. Their structure and operation are described. The robustness of such systems to variations in uncontrolled environments is emphasized. We present some preliminary results of a system developed in our laboratory.","3D images; Biometric systems; Face recognition; Features"
"Tran Q.D., Kantartzis P., Liatsis P.","Improving fusion with optimal weight selection in Face Recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863646816&doi=10.3233%2fICA-2012-0403&partnerID=40&md5=29fc746791c7806dec4f63e848187afc","Face recognition has a large number of applications, including security/counterterrorism, person identification, Internet communications, E-commerce, and computer entertainment. Although research in automatic face recognition has been conducted since the 1960s, there exist research challenges in its practical application in the terms of performance accuracy, which deteriorates significantly with changes in illumination, pose, expression and occlusions. However, these inherent limitations can be potentially alleviated by fusing biometric information based on multiple facial features. Following this vision, the work presented here offers three contributions. Firstly, we present a Face Recognition System, where diverse biometrics features such as total face, eyes, nose, mouth, etc are extracted from the face image. Secondly, we analyse a number of approaches for combining the aforementioned information at matching score level. Thirdly, we proposed a new approach, based on a recently proposed optimisation technique, the Bees Algorithm, to determine the optimal weight parameters to enhance the performance of the fusion system. Experiments on the CASIA and ORL face databases indicate that the proposed method achieves consistently high recognition rates, compared to traditional FR approaches, such as the Eigenfaces, Fisherfaces, and D-LDA methods. © 2012-IOS Press and the author(s). All rights reserved.","Bees Algorithm; density based score fusion; Face recognition; Linear Discriminant Analysis; multibiometric system"
"Islam S.M.S., Bennamoun M., Owens R.A., Davies R.","A review of recent advances in 3D ear- and expression-invariant face biometrics","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863848136&doi=10.1145%2f2187671.2187676&partnerID=40&md5=3203d631a75fc79670b427e44c824b20","Biometric-based human recognition is rapidly gaining popularity due to breaches of traditional security systems and the lowering cost of sensors. The current research trend is to use 3D data and to combine multiple traits to improve accuracy and robustness. This article comprehensively reviews unimodal and multimodal recognition using 3D ear and face data. It covers associated data collection, detection, representation, and matching techniques and focuses on the challenging problem of expression variations. All the approaches are classified according to their methodologies. Through the analysis of the scope and limitations of these techniques, it is concluded that further research should investigate fast and fully automatic ear-face multimodal systems robust to occlusions and deformations. © 2012 ACM.","3D data representation; 3D ear; 3D face; Biometrics; Detection; Facial expressions; Multimodal recognitionl"
"Li P., Ma H.","Iris recognition in non-ideal imaging conditions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859158334&doi=10.1016%2fj.patrec.2011.06.017&partnerID=40&md5=0f0a69c3501b2f1d6e17e54a73427251","This paper studies the iris recognition problem in the degraded iris images captured in non-ideal imaging conditions. In these circumstances iris recognition becomes challenging because of noisy factors such as the off-axis imaging, pose variation, image blurring, illumination change, occlusion, specular highlights and noise. We introduce a robust algorithm based on the Random Sample Consensus (RANSAC) for localization of non-circular iris boundaries. It can localize the iris boundaries more accurately than the methods based on the Hough transform. To account for iris pattern deformation, we describe an image registration method based on the Lucas-Kanade algorithm. Operating on the filtered iris images, this method divides one image into small sub-images and solves registration problem for every small sub-image. Under some reasonable assumptions this method becomes very efficient while maintaining its effectiveness. Finally, we investigate how to extract highly distinctive features in the degraded iris images. We present a sequential forward selection method for seeking a sub-optimal subset of filters from a family of Gabor filters. The recognition performance is greatly improved with a very small number of filters selected. Experiments were conducted on the UBIRIS.v2 iris database and promising results were obtained. © 2011 Elsevier B.V. All rights reserved.","Filter selection; Image registration; Iris recognition; Random Sample Consensus (RANSAC)"
"Juefei-Xu F., Savvides M.","Unconstrained periocular biometric acquisition and recognition using COTS PTZ camera for uncooperative and non-cooperative subjects","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860693677&doi=10.1109%2fWACV.2012.6163051&partnerID=40&md5=431c942bdfcd5371095f1ae50bd40e82","We propose an acquisition and recognition system based only on periocular biometric using the COTS PTZ camera to tackle the difficulty that the full face recognition approach has encountered in highly unconstrained real-world scenario, especially for capturing and recognizing uncooperative and non-cooperative subjects with expression, closed eyes, and facial occlusions. We evaluate our algorithm on the periocular region and compare that to the performance of the full face on the Compass database we have collected. The results have shown that the periocular region, when tackling unconstrained matching, is a much better choice than the full face for face recognition even with less than 2/5 the size of the full face. To be more specific, the periocular matching across all facial manners, i.e., neutral expression, smiling expression, closed eyes, and facial occlusion, is able to achieve 60.7% verification rate at 0.1% false accept rate, a 16.9% performance boost over the full face. © 2012 IEEE.",
"Song M., Tao D., Huang X., Chen C., Bu J.","Three-dimensional face reconstruction from a single image by a coupled RBF network","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860110906&doi=10.1109%2fTIP.2012.2183882&partnerID=40&md5=a5594e1af61b1744009264b615a49089","Reconstruction of a 3-D face model from a single 2-D face image is fundamentally important for face recognition and animation because the 3-D face model is invariant to changes of viewpoint, illumination, background clutter, and occlusions. Given a coupled training set that contains pairs of 2-D faces and the corresponding 3-D faces, we train a novel coupled radial basis function network (C-RBF) to recover the 3-D face model from a single 2-D face image. The C-RBF network explores: 1) the intrinsic representations of 3-D face models and those of 2-D face images; 2) mappings between a 3-D face model and its intrinsic representation; and 3) mappings between a 2-D face image and its intrinsic representation. Since a particular face can be reconstructed by its nearest neighbors, we can assume that the linear combination coefficients for a particular 2-D face image reconstruction are identical to those for the corresponding 3-D face model reconstruction. Therefore, we can reconstruct a 3-D face model by using a single 2-D face image based on the C-RBF network. Extensive experimental results on the BU3D database indicate the effectiveness of the proposed C-RBF network for recovering the 3-D face model from a single 2-D face image. © 1992-2012 IEEE.","3-D face reconstruction; Coupled RBF network; single image"
"Shermina J., Vasudevan V.","Recognition of the face images with occlusion and expression","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865734259&doi=10.1142%2fS021800141256006X&partnerID=40&md5=d6941d06b9943678cf29c5286956d820","Face recognition, a kind of biometric identification, researched in several fields such as computer vision, image processing, and pattern recognition is a natural and direct biometric method. Face Recognition Technology has diverse potential over applications in the fields of information security, law enforcement and surveillance, smart cards, access control and more. Face recognition is one of the diverse techniques used for identifying an individual. Generally the image variations because of the change in face identity are less than the variations among the images of the same face under different illumination and viewing angle. Illumination and pose are the two major challenges, among the several factors that influence face recognition. After pose and illumination, the main factors that affect the face recognition performance are occlusion and expression. So in order to overcome these issues, we proposed an efficient face recognition system based on partial occlusion and expression. The similar blocks in the face image are identified and occlusion can be recovered using the block matching technique. This is combined with expression normalized by calculating the Empherical Mode Decomposition feature. Finally, the face can be recognized by using the PCA. From the implementation result, it is evident that our proposed method based on the PCA technique recognizes the face images effectively. © 2012 World Scientific Publishing Company.","block matching algorithm; expression; Face recognition; occlusion detection; principal component analysis (PCA)"
"Zhang M., Sun Z., Tan T.","Perturbation-enhanced feature correlation filter for robust iris recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866669357&doi=10.1049%2fiet-bmt.2012.0002&partnerID=40&md5=f87b5e1dcf7fcdf998012e7a15105107","Visual pattern of human iris provides rich texture information for personal identification. However, it is challenging to match intra-class iris images with large variations in applications. This study proposes a perturbation-enhanced feature correlation filter (PFCF) for robust iris matching. PFCF is developed based on quad-phase minimum average correlation energy filter, but it has two significant improvements. First, PFCF is performed on Gabor filtered iris images to encode both local and global features. On the one hand, Gabor images can enhance the local details of iris texture. On the other hand, correlation filters describe the regional appearance information and measure the global similarity between iris images efficiently. Secondly, artificially perturbed iris images are generated to model intra-class variations. Also, a set of additional correlation filters are developed accordingly as the gallery templates. The decision is determined by the fusion result of multiple correlation filters. Therefore PFCF not only takes the advantages of Gabor images and correlation filters but also enlarges the amount of enrolled templates for robust iris matching. Extensive experiments on three challenging iris image databases demonstrate that the proposed method outperforms the state-of-the-art methods according to its robustness against deformation, rotation, occlusion, blurring and illumination changes in iris images. © 2012 The Institution of Engineering and Technology.",
"Dibeklioglu H., Salah A.A., Gevers T.","A statistical method for 2-D facial landmarking","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856256887&doi=10.1109%2fTIP.2011.2163162&partnerID=40&md5=80c8a7a1b0fcaaf0653f716c5ba6e1c1","Many facial-analysis approaches rely on robust and accurate automatic facial landmarking to correctly function. In this paper, we describe a statistical method for automatic facial-landmark localization. Our landmarking relies on a parsimonious mixture model of Gabor wavelet features, computed in coarse-to-fine fashion and complemented with a shape prior. We assess the accuracy and the robustness of the proposed approach in extensive cross-database conditions conducted on four face data sets (Face Recognition Grand Challenge, Cohn-Kanade, Bosphorus, and BioID). Our method has 99.33% accuracy on the Bosphorus database and 97.62% accuracy on the BioID database on the average, which improves the state of the art. We show that the method is not significantly affected by low-resolution images, small rotations, facial expressions, and natural occlusions such as beard and mustache. We further test the goodness of the landmarks in a facial expression recognition application and report landmarking-induced improvement over baseline on two separate databases for video-based expression recognition (Cohn-Kanade and BU-4DFE). © 2011 IEEE.","Facial feature localization; facial landmarking; factor analysis; Gabor wavelet features; mixture models; shape prior; structural analysis"
"Yuan L., Mu Z.C.","Ear recognition based on local information fusion","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81155148573&doi=10.1016%2fj.patrec.2011.09.041&partnerID=40&md5=9a946c693613a76b18fe35f063365695","Ears have rich structural features that are almost invariant with increasing age and facial expression variations. Therefore ear recognition has become an effective and appealing approach to non-contact biometric recognition. This paper gives an up-to date review of research works on ear recognition. Current 2D ear recognition approaches achieve good performance in constrained environments. However the recognition performance degrades severely under pose, lighting and occlusion. This paper proposes a 2D ear recognition approach based on local information fusion to deal with ear recognition under partial occlusion. Firstly, the whole 2D image is separated to sub-windows. Then, Neighborhood Preserving Embedding is used for feature extraction on each sub-window, and we select the most discriminative sub-windows according to the recognition rate. Each sub-window corresponds to a sub-classifier. Thirdly, a sub-classifier fusion approach is used for recognition with partially occluded images. Experimental results on the USTB ear dataset and UND dataset have illustrated that using only few sub-windows we can represent the most meaningful region of the ear, and the multi-classifier model gets higher recognition rate than using the whole image for recognition. © 2011 Elsevier B.V. All rights reserved.","Ear recognition; Neighborhood preserving embedding; Partial occlusion; Sub-classifier fusion"
"Li B., Lian X.-C., Lu B.-L.","Gender classification by combining clothing, hair and facial component classifiers","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80555123017&doi=10.1016%2fj.neucom.2011.01.028&partnerID=40&md5=6b86021ab75fc1e10b7ee8c5355e5895","In this paper, we propose a novel gender classification framework, which utilizes not only facial features, but also external information, i.e. hair and clothing. Instead of using the whole face, we consider five facial components: forehead, eyes, nose, mouth and chin. We also design feature extraction methods for hair and clothing; these features have seldom been used in previous work because of their large variability. For each type of feature, we train a single support vector machine classifier with probabilistic output. The outputs of these classifiers are combined using various strategies, namely fuzzy integral, maximal, sum, voting, and product rule. The major contributions of this paper are (1) investigating the gender discriminative ability of clothing information; (2) using facial components instead of the whole face to obtain higher robustness for occlusions and noise; (3) exploiting hair and clothing information to facilitate gender classification. Experimental results show that our proposed framework improves classification accuracy, even when images contain occlusions, noise, and illumination changes. © 2011 Elsevier B.V.","Classifier combination; Clothing feature; Facial components; Gender classification; Hair feature; Local binary pattern; Support vector machine"
"Saha K., Debnath R., Bhowmik M.K., Bhattacharjee D., Nasipuri M.","North-East Indian face database: Its design and aspects","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907554226&doi=10.1049%2fcp.2012.2546&partnerID=40&md5=9488966efc013f40807c14ef02fd2568","The outer shell of human face may seem different in multiple occasions due to its flexibility and three dimensional formation. Researchers are developing robust algorithms efficient for automatic face detection, recognition and expression analysis, even in the presence of the difficulties caused by source of illumination, incidental angle of illumination, facial expression, head orientation, age, occlusion, facial surgery, facial hair, etc. But, to determine the efficiency of these algorithms, it requires to be tested using quality face images of benchmark databases. Here, we have studied some of the recent 2D face image databases with a comparative analysis between them. We have also described a visual face database being developed in the Biometrics Laboratory of Tripura University, India, containing the face images from the north-eastern states of India with variations in expression, illumination, pose etc.","2D face image database survey; Aging; Database creation; Detection; Expression; Face recognition; North-East Indian face database"
"Wagner A., Wright J., Ganesh A., Zhou Z., Mobahi H., Ma Y.","Toward a practical face recognition system: Robust alignment and illumination by sparse representation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84055212058&doi=10.1109%2fTPAMI.2011.112&partnerID=40&md5=16db44144741230d79d3f0a9c1cb858e","Many classic and contemporary face recognition algorithms work well on public data sets, but degrade sharply when they are used in a real recognition system. This is mostly due to the difficulty of simultaneously handling variations in illumination, image misalignment, and occlusion in the test image. We consider a scenario where the training images are well controlled and test images are only loosely controlled. We propose a conceptually simple face recognition system that achieves a high degree of robustness and stability to illumination variation, image misalignment, and partial occlusion. The system uses tools from sparse representation to align a test face image to a set of frontal training images. The region of attraction of our alignment algorithm is computed empirically for public face data sets such as Multi-PIE. We demonstrate how to capture a set of training images with enough illumination variation that they span test images taken under uncontrolled illumination. In order to evaluate how our algorithms work under practical testing conditions, we have implemented a complete face recognition system, including a projector-based training acquisition system. Our system can efficiently and effectively recognize faces under a variety of realistic conditions, using only frontal images under the proposed illuminations as training. © 2012 IEEE.","error correction; face alignment; Face recognition; illumination variation; occlusion and corruption; sparse representation; validation and outlier rejection"
"Min R., Dugelay J.-L.","Cap detection for moving people in entrance surveillance","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84455169148&doi=10.1145%2f2072298.2071987&partnerID=40&md5=118c2119231f493cdb612382113e4a74","While there has been an enormous amount of research on face recognition under pose/illumination changes and image degradations, problems caused by occlusions are mostly overlooked. Moreover, most of the existing approaches of face recognition under occlusion conditions focus on overcoming facial occlusion problems due to sunglasses and scarf. To the best of our knowledge, occlusion due to cap has never been studied in the literature, but the importance of this problem should be emphasized since it is known that bank robbers and football hooligans take advantage of it for hiding their faces. This paper presents a solution to this newly identified face occlusion problem - the time-variant occlusion due to cap in entrance surveillance, in the context of face biometrics in video surveillance. The proposed approach consists of two parts: detection and tracking of occluded faces in complex surveillance videos; detecting the presence of cap by exploiting temporal information. The detection and tracking part is based upon body silhouette and elliptical head tracker. The classification of cap/non-cap faces utilizes dynamic time warping (DTW) and agglomerative hierarchical clustering. The proposed algorithm is evaluated on several surveillance videos and yields good detection rates. Copyright 2011 ACM.","Entrance surveillance; Face recognition; Occlusion detection; Security management"
"Lakshmiprabha N.S., Bhattacharya J., Majumder S.","Face recognition using multimodal biometric features","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855928247&doi=10.1109%2fICIIP.2011.6108945&partnerID=40&md5=21cec9435b330d54562a64dd2fbcfa64","This paper presents a new multimodal biometric approach using face and periocular biometric. The available face recognition algorithm performance in presence of multiple variations such as illumination, pose, expression, occlusion and plastic surgery is not satisfactory. Also, periocular biometrics face problems in presence of spectacles, head angle, hair and expression. A method which can extract multiple feature information from a single source and can give a satisfactory performance even with less number of training images is desirable. Thus combining face and periocular data obtained from the same image may increase the performance of the recognition system. A detailed performance analysis of face recognition and periocular biometric using Gabor and LBP features is carried out. This is then compared with the proposed multimodal biometric feature extraction technique. The experimental results obtained using Muct and plastic surgery face database shows that the proposed multimodal biometric performs better than other face recognition and individual biometric methods. © 2011 IEEE.","Face recognition; Gabor wavelets; Local Binary Patterns; Multimodal biometric; Periocular recognition"
"Logesh S., Arun Bharathi S., Chandra Mouli P.V.S.S.R.","An efficient and robust face detection method using neuro-fuzzy approach","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855930697&doi=10.1109%2fICIIP.2011.6108976&partnerID=40&md5=49a05a6d6bc0dc717e23f6f16b90bbeb","Person identification plays a major role in any secured and safety system. Face is one of the major biometric explored by many researchers for human identification. The problem becomes more complex by means of any occlusion of objects, due to different illumination, expression and pose. We propose a novel pattern recognition approach for face detection in this paper. The approach presented is an amalgamation of artificial neural networks and fuzzy set theory. The proposed method runs in two phases and fuses the results for better performance and accuracy. The proposed method has been tested on BioID dataset and got 94% accuracy. © 2011 IEEE.","Face Detection; Fusion; Fuzzy Sets; Neural Networks"
"Tankasala S.P., Doynov P., Derakhshani R.R., Ross A., Crihalmeanu S.","Biometric recognition of conjunctival vasculature using GLCM features","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855961723&doi=10.1109%2fICIIP.2011.6108974&partnerID=40&md5=fc3047f7b9e6426d7a8198edded56b7a","Besides the iris, conjunctival vasculature may also be used for ocular biometric recognition. Conjunctival vessel patterns can be easily observed in the visible spectrum and can compensate for off-angle or otherwise occluded iridial texture. In this paper, classification of conjunctival vasculature using Gray Level Co-occurrence Matrix (GLCM) is studied. Statistical features of GLCM, i.e., contrast, correlation, energy and homogeneity, were used in conjunction with Fisher linear discriminant analysis and regularized neural network classifiers in order to recognize textures arising from conjunctival vessels. Match score level fusion of Fisher LDA and neural networks provided the best results, resulting in a test set equal error rate (EER) and area under receiver operating characteristics curve (ROC AUC) of 13.97% and 0.9333, respectively. These figures improved to 11.9% and 0.9504 after fusion of LDA and neural network match scores. © 2011 IEEE.","Biometrics; Classification; Conjunctival Vasculature; Gray Level Co-occurrence Matrix; Image Processing; Image Segmentation; Linear Discriminant Analysis; Neural Networks; Receiver Operating Characteristics"
"Fu B., Yang R.","Display control based on eye gaze estimation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855568032&doi=10.1109%2fCISP.2011.6099973&partnerID=40&md5=3223098f2aefd7ea962272f092ecd391","Detecting and tracking eye gaze is an active research area and significant progress has been made in this area in the past decades. However, challenge remains due to the differences between individual's eyes, variability in light condition, scale and occlusion. Works on eye location and eye movements have a large number of applications and is an important part of biometrics, human-computer interaction and face detection. Based on the current works and applications on eye gaze detection, the author notice, however, applying eye gaze information on human-computer interaction still lacks of enough work on it. This paper proposes a novel pipeline of employing eye gaze information for display control based on the video captured by integrated camera. The proposed pipeline shows that, despite the low quality of the video and light condition, eye gaze can still be estimated and display of the screen can be controlled accordingly. © 2011 IEEE.","display control; eye gaze; eye tracking"
"Zhang B.","Multiple features facial image retrieval by spectral regression and fuzzy aggregation approach","https://www.scopus.com/inward/record.uri?eid=2-s2.0-82555168369&doi=10.1108%2f17563781111186734&partnerID=40&md5=944a15f2323a5696bfaf17444de151fb","Purpose – Content-based image retrieval (CBIR) is an important research area for automatically retrieving images of user interest from a large database. Due to many potential applications, facial image retrieval has received much attention in recent years. Similar to face recognition, finding appropriate image representation is a vital step for a successful facial image retrieval system. Recently, many efficient image feature descriptors have been proposed and some of them have been applied to face recognition. It is valuable to have comparative studies of different feature descriptors in facial image retrieval. And more importantly, how to fuse multiple features is a significant task which can have a substantial impact on the overall performance of the CBIR system. The purpose of this paper is to propose an efficient face image retrieval strategy. Design/methodology/approach – In this paper, three different feature description methods have been investigated for facial image retrieval, including local binary pattern, curvelet transform and pyramid histogram of oriented gradient. The problem of large dimensionalities of the extracted features is addressed by employing a manifold learning method called spectral regression. A decision level fusion scheme fuzzy aggregation is applied by combining the distance metrics from the respective dimension reduced feature spaces. Findings – Empirical evaluations on several face databases illustrate that dimension reduced features are more efficient for facial retrieval and the fuzzy aggregation fusion scheme can offer much enhanced performance. A 98 per cent rank 1 retrieval accuracy was obtained for the AR faces and 91 per cent for the FERET faces, showing that the method is robust against different variations like pose and occlusion. Originality/value – The proposed method for facial image retrieval has a promising potential of designing a real-world system for many applications, particularly in forensics and biometrics. © 2011, Emerald Group Publishing Limited","Curvelet; Dimension reduction; Face image retrieval; Fuzzy aggregation; Image processing; Local binary pattern; Pyramid histogram of oriented gradient; Visual databases"
"Zhang Z., Wang C., Wang Y.","Video-based face recognition: State of the art","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81155148830&doi=10.1007%2f978-3-642-25449-9_1&partnerID=40&md5=aaf7a9f553f858f9891a81cf1746a69c","Face recognition in videos is a hot topic in computer vision and biometrics over many years. Compared to traditional face analysis, video based face recognition has advantages of more abundant information to improve accuracy and robustness, but also suffers from large scale variations, low quality of facial images, illumination changes, pose variations and occlusions. Related to applications, we divide the existing video based face recognition approaches into two categories: video-image based methods and video-video based methods, which are surveyed and analyzed in this paper. © 2011 Springer-Verlag.","Face recognition; survey; video"
"Liu N., Lai J., Zheng W.-S.","A sparse local feature descriptor for robust face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81155151825&doi=10.1007%2f978-3-642-25449-9_5&partnerID=40&md5=c0de24065d3294300c9e2f265cde1bab","A good face recognition algorithm should be robust against variations caused by occlusion, expression or aging changes etc. However, the performance of holistic feature based methods would drop dramatically as holistic features are easily distorted by those variations. SIFT, a classical sparse local feature descriptor, was proposed for object matching between different views and scales and has its potential advantages for face recognition. However, face recognition is different from the matching of general objects. This paper investigates the weakness of SIFT used for face recognition and proposes a novel method based on it. The contributions of our work are two-fold: first, we give a comprehensive analysis of SIFT and study its deficiencies when applied to face recognition. Second, based on the analysis of SIFT, a new sparse local feature descriptor, namely SLFD, Cis proposed. Experimental results on AR database validates our analysis of SIFT. Comparison experiments on both AR and FERET database show that SLFD outperforms the SIFT, LBP based methods and also some other existing face recognition algorithms in terms of recognition accuracy. © 2011 Springer-Verlag.","face recognition; local feature descriptor; SIFT"
"Hu X., Pauca V.P., Plemmons R.","Iterative directional ray-based iris segmentation for challenging periocular images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81155151849&doi=10.1007%2f978-3-642-25449-9_12&partnerID=40&md5=5103aad6d7167103fc43c57357e29d25","The face region immediately surrounding one, or both, eyes is called the periocular region. This paper presents an iris segmentation algorithm for challenging periocular images based on a novel iterative ray detection segmentation scheme. Our goal is to convey some of the difficulties in extracting the iris structure in images of the eye characterized by variations in illumination, eye-lid and eye-lash occlusion, de-focus blur, motion blur, and low resolution. Experiments on the Face and Ocular Challenge Series (FOCS) database from the U.S. National Institute of Standards and Technology (NIST) emphasize the pros and cons of the proposed segmentation algorithm. © 2011 Springer-Verlag.","Iris segmentation; periocular images; ray detection"
"Chiang C.-C., Chen Z.-W.","Recognizing partially-occluded faces by recovering normalized facial appearance","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054842491&partnerID=40&md5=f22c76942078f1dc005bf300ddb50188","This paper proposes a novel approach to recognize partially-occluded and -damaged face images. Two novel technical contributions of the proposed approach include an iterative face recovery method and a face recognition method called the recognition-by-input-approximation (RBIA) method. The iterative face recovery method can nicely recover the lost face textures of occluded or damaged areas, while well preserving the original input illumination on the recovered faces. With the RBIA method, our experiments on testing the public AR face database show that the achieved recognition rate in recognizing faces with occlusions from sunglasses, gauze masks and scarves, under different illumination conditions, is 92.5%. © 2011 ICIC INTERNATIONAL.","Biometrics; Face recognition; Face texture recovery; Facial appearance; Illumination adjustment; Partial occlusions; Principal component analysis"
"Eum S., Suhr J.K., Kim J.","Face recognizability evaluation for ATM applications with exceptional occlusion handling","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054889775&doi=10.1109%2fCVPRW.2011.5981883&partnerID=40&md5=075957bfe9fe3b20a2f150e961fd3693","Biometrics has been extensively utilized to lessen the ATM-related crimes. One of the most widely used methods is to capture the facial images of the users for follow-up criminal investigations. However, this method is vulnerable to attacks made by the criminals with heavy facial occlusions. To overcome this drawback, this paper proposes a novel method for face recognizability evaluation with exceptional occlusion handling (EOH). The proposed method conducts a recognizability evaluation based on local regions of the facial components. Subsequently, the resulting decisions are reaffirmed by the EOH exploiting the global aspect of the frequently occurring facial occlusions. The EOH can be divided into two separate approaches: 1) accepting the falsely rejected cases, 2) rejecting the falsely accepted cases. In this paper, two typical facial occlusions, eyeglasses and sunglasses, are chosen to prove the validity of the EOH. To evaluate the proposed method in the most realistic environment, an ATM database was constructed by using an off-the-shelf ATM while the users were asked to make withdrawals as they would in real situations. The proposed method was evaluated by the ATM database which includes 480 video sequences with 20 subjects. The results showed the feasibility of the face recognizability evaluation with the EOH in practical ATM environments. © 2011 IEEE.",
"Venkat I., Khader A.T., Subramanian K.G., De Wilde P.","Psychophysically ispired Bayesian occlusion model to recognize occluded faces","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052810367&doi=10.1007%2f978-3-642-23672-3_51&partnerID=40&md5=5215cbb41cd43c4e9d7a561092f73fad","Face recognition systems robust to major occlusions have wide applications ranging from consumer products with biometric features to surveillance and law enforcement applications. In unconstrained scenarios, faces are often subject to occlusions, apart from common variations such as pose, illumination, scale, orientation and so on. In this paper we propose a novel Bayesian oriented occlusion model inspired by psychophysical mechanisms to recognize faces prone to occlusions amidst other common variations. We have discovered and modeled similarity maps that exist in facial domains by means of Bayesian Networks. The proposed model is capable of efficiently learning and exploiting these maps from the facial domain. Hence it can tackle the occlusion uncertainty reasonably well. Improved recognition rates over state of the art techniques have been observed. © 2011 Springer-Verlag.","Bayesian Networks; Face Recognition; Occlusion Models; Parameter Estimation; Similarity Measures"
"Lihong Z., Ye W., Hongfeng T.","Face recognition based on independent component analysis","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052215330&doi=10.1109%2fCCDC.2011.5968217&partnerID=40&md5=331eafcca64cc6e706c170dad26effd9","Face recognition is a biometrics technology with high development potential, and research on face recognition technology is of great theoretical and practical value. Independent component analysis (ICA) is a method being developed in face recognition. In the method of ICA, not only statistical characteristics in second order or higher order are considered, but also basis vectors decomposed from face images obtained by ICA are more localized in distribution space than those by PCA. Localized characteristics are favorable for face recognition, because human faces are non-rigid bodies, and because localized characteristics are not easily influenced by face expression changes, location, position, or partial occlusion. In this paper, the methods of PCA and ICA are adopted and combined, and relatively high recognition rates (up to 99%) are obtained. © 2011 IEEE.","face recognition; Independent component analysis PCA"
"Passalis G., Perakis P., Theoharis T., Kakadiaris I.A.","Using facial symmetry to handle pose variations in real-world 3D face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052020983&doi=10.1109%2fTPAMI.2011.49&partnerID=40&md5=0b2e7383803fac748ace362403447abc","The uncontrolled conditions of real-world biometric applications pose a great challenge to any face recognition approach. The unconstrained acquisition of data from uncooperative subjects may result in facial scans with significant pose variations along the yaw axis. Such pose variations can cause extensive occlusions, resulting in missing data. In this paper, a novel 3D face recognition method is proposed that uses facial symmetry to handle pose variations. It employs an automatic landmark detector that estimates pose and detects occluded areas for each facial scan. Subsequently, an Annotated Face Model is registered and fitted to the scan. During fitting, facial symmetry is used to overcome the challenges of missing data. The result is a pose invariant geometry image. Unlike existing methods that require frontal scans, the proposed method performs comparisons among interpose scans using a wavelet-based biometric signature. It is suitable for real-world applications as it only requires half of the face to be visible to the sensor. The proposed method was evaluated using databases from the University of Notre Dame and the University of Houston that, to the best of our knowledge, include the most challenging pose variations publicly available. The average rank-one recognition rate of the proposed method in these databases was 83.7 percent. © 2011 IEEE.","Biometrics; face and gesture recognition; physically-based modeling."
"Bhowmik M.K., Bhattacharjee D., Kumar Basu D., Nasipuri M.","Polar fusion technique analysis for evaluating the performances of image fusion of thermal and visual images for human face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79961206701&doi=10.1109%2fCIBIM.2011.5949220&partnerID=40&md5=8159d1c3a22a5a3fcc90c9fde4093dd3","This paper presents a comparative study of two different methods, which are based on fusion and polar transformation of visual and thermal images. Here, investigation is done to handle the challenges of face recognition, which include pose variations, changes in facial expression, partial occlusions, variations in illumination, rotation through different angles, change in scale etc. To overcome these obstacles we have implemented and thoroughly examined two different fusion techniques through rigorous experimentation. In the first method log-polar transformation is applied to the fused images obtained after fusion of visual and thermal images whereas in second method fusion is applied on log-polar transformed individual visual and thermal images. After this step, which is thus obtained in one form or another, Principal Component Analysis (PCA) is applied to reduce dimension of the fused images. Log-polar transformed images are capable of handling complicacies introduced by scaling and rotation. The main objective of employing fusion is to produce a fused image that provides more detailed and reliable information, which is capable to overcome the drawbacks present in the individual visual and thermal face images. Finally, those reduced fused images are classified using a multilayer perceptron neural network. The database used for the experiments conducted here is Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database benchmark thermal and visual face images. The second method has shown better performance, which is 95.71% (maximum) and on an average 93.81% as correct recognition rate. © 2011 IEEE.","classes; face recognition; multilayer perceptron neural network; polar fusion; principal component analysis; thermal face images"
"Raposo R., Hoyle E., Peixinho A., Proença H.","UBEAR: A dataset of ear images captured on-the-move in uncontrolled conditions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79961174995&doi=10.1109%2fCIBIM.2011.5949208&partnerID=40&md5=e8ad5376185cdc996945cf5eeb517660","In order to broad the applicability of biometric systems, the data acquisition constraints required for reliable recognition are receiving increasing attention. For some of the traits (e.g., face and iris) significant research efforts were already made toward the development of systems able to operate in completely unconstrained conditions. For other traits (e.g., the ear) no similar efforts are known. The main purpose of this paper is to announce the availability of a new data set of ear images, which main distinguishing feature is that its images were acquired from on-the-move subjects, under varying lighting conditions and without demanding to subjects any particular care regarding ear occlusions and poses. The data set is freely available to the research community and should constitute a valuable tool in assessing the possibility of performing reliable ear biometric recognition in such d challenging conditions. © 2011 IEEE.",
"Deng Y., Dai Q., Zhang Z.","Graph laplace for occluded face completion and recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960520849&doi=10.1109%2fTIP.2011.2109729&partnerID=40&md5=b110fd9fa0288bd4a56780cac70b7c7d","This paper proposes a spectral-graph-based algorithm for face image repairing, which can improve the recognition performance on occluded faces. The face completion algorithm proposed in this paper includes three main procedures: 1) sparse representation for partially occluded face classification; 2) image-based data mining; and 3) graph Laplace (GL) for face image completion. The novel part of the proposed framework is GL, as named from graphical models and the Laplace equation, and can achieve a high-quality repairing of damaged or occluded faces. The relationship between the GL and the traditional Poisson equation is proven. We apply our face repairing algorithm to produce completed faces, and use face recognition to evaluate the performance of the algorithm. Experimental results verify the effectiveness of the GL method for occluded face completion. © 2011 IEEE.","Face recognition; graph Laplace (GL); occluded face completion"
"Badrinath G.S., Kachhi N.K., Gupta P.","Verification system robust to occlusion using low-order Zernike moments of palmprint sub-images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958085121&doi=10.1007%2fs11235-010-9318-y&partnerID=40&md5=f39fca65cd5f9bb363af2d4c01c2d60d","This paper proposes a palmprint based verification system which uses low-order Zernike moments of palmprint sub-images. Euclidean distance is used to match the Zernike moments of corresponding sub-images of query and enrolled palmprints. These matching scores of sub-images are fused using a weighted fusion strategy. The proposed system can also classify the sub-image of palmprint into non-occluded or occluded region and verify user with the help of non-occluded regions. So it is robust to occlusion. The palmprint is extracted from the acquired hand image using a low cost flat bed scanner. A palmprint extraction procedure which is robust to hand translation and rotation on the scanner has been proposed. The system is tested on IITK, PolyU and CASIA databases of size 549, 5239 and 7752 hand images respectively. It performs with accuracy of more than 98%, and FAR, FRR less than 2% for all the databases. © 2010 Springer Science+Business Media, LLC.","Biometrics; Occlusion; Palmprint; Rotation; Sub-image; Translation; Zernike moments"
"Doretto G., Sebastian T., Tu P., Rittscher J.","Appearance-based person reidentification in camera networks: Problem overview and current approaches","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955869423&doi=10.1007%2fs12652-010-0034-y&partnerID=40&md5=977abfd1e70735ec3a45d11121f46e91","Recent advances in visual tracking methods allow following a given object or individual in presence of significant clutter or partial occlusions in a single or a set of overlapping camera views. The question of when person detections in different views or at different time instants can be linked to the same individual is of fundamental importance to the video analysis in large-scale network of cameras. This is the person reidentification problem. The paper focuses on algorithms that use the overall appearance of an individual as opposed to passive biometrics such as face and gait. Methods that effectively address the challenges associated with changes in illumination, pose, and clothing appearance variation are discussed. More specifically, the development of a set of models that capture the overall appearance of an individual and can effectively be used for information retrieval are reviewed. Some of them provide a holistic description of a person, and some others require an intermediate step where specific body parts need to be identified. Some are designed to extract appearance features over time, and some others can operate reliably also on single images. The paper discusses algorithms for speeding up the computation of signatures. In particular it describes very fast procedures for computing co-occurrence matrices by leveraging a generalization of the integral representation of images. The algorithms are deployed and tested in a camera network comprising of three cameras with non-overlapping field of views, where a multi-camera multi-target tracker links the tracks in different cameras by reidentifying the same people appearing in different views. © 2011 Springer-Verlag.","Appearance matching; Co-occurrence; Integral image; Integral representation; Re-identification; Surveillance; Tracking"
"Fagertun J., Gomez D.D., Hansen M.F., Paulsen R.R.","Sparse similarity-based fisherfaces","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957448498&doi=10.1007%2f978-3-642-21227-7_7&partnerID=40&md5=ee1ac2f83518d846b202c8c690a3f207","In this work, the effect of introducing Sparse Principal Component Analysis within the Similarity-based Fisherfaces algorithm is examined. The technique aims at mimicking the human ability to discriminate faces by projecting the faces in a highly discriminative and easy interpretative way. Pixel intensities are used by Sparse Principal Component Analysis and Fisher Linear Discriminant Analysis to assign a one dimensional subspace projection to each person belonging to a reference data set. Experimental results performed in the AR dataset show that Similarity-based Fisherfaces in a sparse version can obtain the same recognition results as the technique in a dense version using only a fraction of the input data. Furthermore, the presented results suggest that using SPCA in the technique offers robustness to occlusions. © 2011 Springer-Verlag.","Biometrics; Face recognition; Fisher Linear Discriminant Analysis; Multi- Subspace Method; Sparse Principal Component Analysis"
"He R., Zheng W.-S., Hu B.-G.","Maximum correntropy criterion for robust face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959526388&doi=10.1109%2fTPAMI.2010.220&partnerID=40&md5=42208a9b25b641fbece585a4a585178b","In this paper, we present a sparse correntropy framework for computing robust sparse representations of face images for recognition. Compared with the state-of-the-art l1norm-based sparse representation classifier (SRC), which assumes that noise also has a sparse representation, our sparse algorithm is developed based on the maximum correntropy criterion, which is much more insensitive to outliers. In order to develop a more tractable and practical approach, we in particular impose nonnegativity constraint on the variables in the maximum correntropy criterion and develop a half-quadratic optimization technique to approximately maximize the objective function in an alternating way so that the complex optimization problem is reduced to learning a sparse representation through a weighted linear least squares problem with nonnegativity constraint at each iteration. Our extensive experiments demonstrate that the proposed method is more robust and efficient in dealing with the occlusion and corruption problems in face recognition as compared to the related state-of-the-art methods. In particular, it shows that the proposed method can improve both recognition accuracy and receiver operator characteristic (ROC) curves, while the computational cost is much lower than the SRC algorithms. © 2011 IEEE.","correntropy; face recognition; half-quadratic optimization; Information theoretical learning; linear least squares; M-estimator; occlusion and corruption; sparse representation"
"Battini Sonmez E., Sankur B., Albayrak S.","Face classification via sparse approximation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952942315&doi=10.1007%2f978-3-642-19530-3_16&partnerID=40&md5=3decf237b9d6f85fe125ab14d8a44f81","We address the problem of 2D face classification under adverse conditions. Faces are difficult to recognize since they are highly variable due to such factors as illumination, expression, pose, occlusion and resolution. We investigate the potential of a method where the face recognition problem is cast as a sparse approximation. The sparse approximation provides a significant amount of robustness beneficial in mitigating various adverse effects. The study is conducted experimentally using the Extended Yale Face B database and the results are compared against the Fisher classifier benchmark. © 2011 Springer-Verlag.","Face classification; Fisher classifier; sparse approximation"
"Park U., Jillela R.R., Ross A., Jain A.K.","Periocular biometrics in the visible spectrum","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951839283&doi=10.1109%2fTIFS.2010.2096810&partnerID=40&md5=5b8256a20e0374f4e2bd759ab99b9854","The term periocular refers to the facial region in the immediate vicinity of the eye. Acquisition of the periocular biometric is expected to require less subject cooperation while permitting a larger depth of field compared to traditional ocular biometric traits (viz., iris, retina, and sclera). In this work, we study the feasibility of using the periocular region as a biometric trait. Global and local information are extracted from the periocular region using texture and point operators resulting in a feature set for representing and matching this region. A number of aspects are studied in this work, including the 1) effectiveness of incorporating the eyebrows, 2) use of side information (left or right) in matching, 3) manual versus automatic segmentation schemes, 4) local versus global feature extraction schemes, 5) fusion of face and periocular biometrics, 6) use of the periocular biometric in partially occluded face images, 7) effect of disguising the eyebrows, 8) effect of pose variation and occlusion, 9) effect of masking the iris and eye region, and 10) effect of template aging on matching performance. Experimental results show a rank-one recognition accuracy of 87.32% using 1136 probe and 1136 gallery periocular images taken from 568 different subjects (2 images/subject) in the Face Recognition Grand Challenge (version 2.0) database with the fusion of three different matchers. © 2010 IEEE.","Biometrics; face; fusion; gradient orientation histogram; local binary patterns; periocular recognition; scale invariant feature transform"
"Shen L., Bai L., Ji Z.","FPCode: An efficient approach for multi-modal biometrics","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953656050&doi=10.1142%2fS0218001411008555&partnerID=40&md5=de2b431673c3fc1398a81e4bab119974","Although face recognition technology has progressed substantially, its performance is still not satisfactory due to the challenges of great variations in illumination, expression and occlusion. This paper aims to improve the accuracy of personal identification, when only few samples are registered as templates, by integrating multiple modal biometrics, i.e. face and palmprint. We developed in this paper a feature code, namely FPCode, to represent the features of both face and palmprint. Though feature code has been used for palmprint recognition in literature, it is first applied in this paper for face recognition and multi-modal biometrics. As the same feature is used, fusion is much easier. Experimental results show that both feature level and decision level fusion strategies achieve much better performance than single modal biometrics. The proposed approach uses fixed length 1/0 bits coding scheme that is very efficient in matching, and at the same time achieves higher accuracy than other fusion methods available in literature. © 2011 World Scientific Publishing Company.","Face recognition; feature fusion; fusion code; Gabor feature; palmprint recognition"
"Zhi R., Flierl M., Ruan Q., Kleijn W.B.","Graph-preserving sparse nonnegative matrix factorization with application to facial expression recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551687415&doi=10.1109%2fTSMCB.2010.2044788&partnerID=40&md5=5902a621aa7b0fbcc0286c0f8566301c","In this paper, a novel graph-preserving sparse nonnegative matrix factorization (GSNMF) algorithm is proposed for facial expression recognition. The GSNMF algorithm is derived from the original NMF algorithm by exploiting both sparse and graph-preserving properties. The latter may contain the class information of the samples. Therefore, GSNMF can be conducted as an unsupervised or a supervised dimension reduction method. A sparse representation of the facial images is obtained by minimizing the $l^{1}$-norm of the basis images. Furthermore, according to the graph embedding theory, the neighborhood of the samples is preserved by retaining the graph structure in the mapped space. The GSNMF decomposition transforms the high-dimensional facial expression images into a locality-preserving subspace with sparse representation. To guarantee convergence, we use the projected gradient method to calculate the nonnegative solution of GSNMF. Experiments are conducted on the JAFFE database and the CohnKanade database with unoccluded and partially occluded facial images. The results show that the GSNMF algorithm provides better facial representations and achieves higher recognition rates than nonnegative matrix factorization. Moreover, GSNMF is also more robust to partial occlusions than other tested methods. © 2010 IEEE.","Facial expression recognition; locality preservation; nonnegative matrix factorization (NMF); sparseness"
"Huang Y., Liu Q., Metaxas D.N.","A component-based framework for generalized face alignment","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551689917&doi=10.1109%2fTSMCB.2010.2052240&partnerID=40&md5=1b1c0af8e0f14eff4e5e21d8cd63b45e","This paper presents a component-based deformable model for generalized face alignment, in which a novel bistage statistical model is proposed to account for both local and global shape characteristics. Instead of using statistical analysis on the entire shape, we build separate Gaussian models for shape components to preserve more detailed local shape deformations. In each model of components, a Markov network is integrated to provide simple geometry constraints for our search strategy. In order to make a better description of the nonlinear interrelationships over shape components, the Gaussian process latent variable model is adopted to obtain enough control of shape variations. In addition, we adopt an illumination-robust feature to lead the local fitting of every shape point when light conditions change dramatically. To further boost the accuracy and efficiency of our component-based algorithm, an efficient subwindow search technique is adopted to detect components and to provide better initializations for shape components. Based on this approach, our system can generate accurate shape alignment results not only for images with exaggerated expressions and slight shading variation but also for images with occlusion and heavy shadows, which are rarely reported in previous work. © 2010 IEEE.","Bistage statistical model; component detection; face alignment; Gaussian process latent variable model (GPLVM); Markov network"
"Hollingsworth K., Bowyer K.W., Flynn P.J.","Useful features for human verification in near-infrared periocular images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80955159706&doi=10.1016%2fj.imavis.2011.09.002&partnerID=40&md5=1c2309d8c850f9b02c0904e807ee02f2","The periocular region is the part of the face immediately surrounding the eye, and researchers have recently begun to investigate how to use the periocular region for recognition. Understanding how humans recognize faces helped computer vision researchers develop algorithms for face recognition. Likewise, understanding how humans analyze periocular images could benefit researchers developing algorithms for periocular recognition. We conducted two experiments to determine how humans analyze periocular images. In these experiments, we presented pairs of images and asked volunteers to determine whether the two images showed eyes from the same subject or from different subjects. In the first experiment, subjects were paired randomly to create different-subject queries. Our volunteers correctly determined the relationship between the two images in 92% of the queries. In the second experiment, we considered multiple factors in forming different-subject pairs; queries were formed from pairs of subjects with the same gender and race, and with similar eye color, makeup, eyelash length, and eye occlusion. In addition, we limited the amount of time volunteers could view a query pair. On this harder experiment, the correct verification rate was 79%. We asked volunteers to describe what features in the images were helpful to them in making their decisions. In both experiments, eyelashes were reported to be the most helpful feature. © 2011 Elsevier B.V.","Near-infrared light; Ocular biometrics; Periocular recognition"
"Cadavid S., Mahoor M.H., Abdel-Mottaleb M.","Multimodal ear and face modeling and recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923623885&doi=10.1017%2fCBO9780511921056.003&partnerID=40&md5=87af0b956187d4b811f0ef682ce1dd32","Introduction Biometric systems deployed in current real-world applications are primarily unimodal – they depend on the evidence of a single biometric marker for personal identity authentication (e.g., ear or face). Unimodal biometrics are limited, because no single biometric is generally considered both sufficiently accurate and robust to hindrances caused by external factors (Ross and Jain 2004). Some of the problems that these systems regularly contend with are the following: (1) Noise in the acquired data due to alterations in the biometric marker (e.g., surgically modified ear) or improperly maintained sensors. (2) Intraclass variations that may occur when a user interacts with the sensor (e.g., varying head pose) or with physiological transformations that take place with aging. (3) Interclass similarities, arising when a biometric database comprises a large number of users, which results in an overlap in the feature space of multiple users, requires an increased complexity to discriminate between the users. (4) Nonuniversality – the biometric system may not be able to acquire meaningful biometric data from a subset of users. For instance, in face biometrics, a face image may be blurred because of abrupt head movement or partially occluded because of off-axis pose. (5) Certain biometric markers are susceptible to spoof attacks – situations in which a user successfully masquerades as another by falsifying their biometric data. © Cambridge University Press 2011.",
"Du M., Sankaranarayanan A.C., Chellappa R.","Face tracking and recognition in a camera network","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893951323&doi=10.1017%2fCBO9780511921056.012&partnerID=40&md5=e51c752fca38acc9f06fd66941cc252a","Introduction Multicamera networks are becoming increasingly common in surveillance applications given their ability to provide persistent sensing over a large area. Opportunistic sensing and nonintrusive acquisition of biometrics, which are useful in many applications, come into play. However, opportunistic sensing invariably comes with a price, namely, a wide range of potential nuisance factors that alter and degrade the biometric signatures of interest. Typical nuisance factors include pose, illumination, defocus blur, motion blur, occlusion, and weather effects. Having multiple views of a person is critical for mitigating some of these degradations. In particular, having multiple viewpoints helps build more robust signatures because the system has access to more information. For face recognition, having multiple views increases the chances of the person being in a favorable frontal pose. However, to use the multiview information reliably, we need to estimate the pose of the person's head. This could be done explicitly by computing the actual pose of the person to a reasonable approximation, or implicitly by using a view selection algorithm. Solving for the pose of a person's head presents a difficult problem, especially when images have poor resolution and the calibration of cameras (both external and internal) is not sufficiently precise to allow robust multiview fusion. This holds especially true in surveillance applications when the subjects under surveillance often appear in the far- field of the camera. © Cambridge University Press 2011.",
"Huang D., Zhang G., Ardabilian M., Wang Y., Chen L.","3D face recognition using distinctiveness enhanced facial representations and local feature hybrid matching","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650333784&doi=10.1109%2fBTAS.2010.5634497&partnerID=40&md5=04541082f1441d8ae7412611fafd6666","This paper presents a simple yet effective approach for 3D face recognition. A novel 3D facial surface representation, namely Multi-Scale Local Binary Pattern (MS-LBP) Depth Map, is proposed, which is used along with the Shape Index (SI) Map to increase the distinctiveness of smooth range faces. Scale Invariant Feature Transform (SIFT) is introduced to extract local features to enhance the robustness to pose variations. Moreover, a hybrid matching is designed for a further improved accuracy. The matching scheme combines local and holistic analysis. The former is achieved by comparing the SIFT-based features extracted from both 3D facial surface representations; while the latter performs a global constraint using facial component and configuration. Compared with the state-of-the-art, the proposed method does not require time-consuming accurate registration or any additional data in a bootstrap for training special thresholds. The rank-one recognition rate achieved on the complete FRGC v2.0 database is 96.1%. As a result of using local facial features, the approach proves to be competent for dealing with partially occluded face probes as highlighted by supplementary experiments using face masks. © 2010 IEEE.",
"Yang U., Kang M., Toh K.-A., Sohn K.","An illumination invariant skin-color model for face detection","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650386348&doi=10.1109%2fBTAS.2010.5634474&partnerID=40&md5=49a249b61e08e3c586a54394da345948","Face detection is an important step towards a fully automatic face recognition system. Among existing techniques in the literature, methods based on skin-color information have shown computational effectiveness as well as robustness in terms of rotation, scaling and partial occlusion. However, due to color variations resulted from illumination changes, many color-based techniques have yet to demonstrate a stable state of performance. In this paper, we present an illumination invariant color space model to address the color variation issue. The proposed method is evaluated both in terms of skin-color detection and face detection performances. Our empirical experiments evidenced both effectiveness and usefulness of the proposed method. © 2010 IEEE.",
"Merkow J., Jou B., Savvides M.","An exploration of gender identification using only the periocular region","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650388529&doi=10.1109%2fBTAS.2010.5634509&partnerID=40&md5=33272d820673b7c033a26c447295a836","The periocular region, the region of the face surrounding the eyes, has gained increasing attention in biometrics in recent years. This region of the face is of particular interest when trying to identify a person whose face is partially occluded.We propose the novel idea of applying the information obtained from the periocular region to identify the gender of a person, which is a type of soft biometric recognition. We gradually narrow the region of interest of the face to explore the feasibility of using smaller, eye-centered regions for building a robust gender classifier around the periocular region alone. Our experimental results show that at least an 85% classification rate is still obtainable using only the periocular region with a database of 936 low resolution images collected from the web. © 2010 IEEE.",
"Abaza A., Hebert C., Harrison M.A.F.","Fast learning ear detection for real-time surveillance","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650367846&doi=10.1109%2fBTAS.2010.5634486&partnerID=40&md5=02c1ad3d51c62f6a52514fc02c8ef3d9","Fully automated image segmentation is an essential step for designing automated identification systems. This paper investigates the problem of real-time image segmentation in the context of ear biometrics. The proposed approach is based on Haar features arranged in a cascaded Adaboost classifier. This method, widely known as Viola-Jones in the context of face detection, has a limitation of an extremely long training time, approximately a month. We efficiently implement a modified training / learning method, which significantly reduces training time. This approach is trained about 80 times faster than the original method, and achieves ∼ 95% accuracy based on four different test sets (> 2000 profile images for app. 450 persons). The developed ear detection system is very fast and can be used in a real-time surveillance scenario. Experimental results show that the proposed ear detection is robust in the presence of partial occlusion, noise and multiple ears with various resolutions. © 2010 IEEE.",
"Abaza A., Ross A.","Towards understanding the symmetry of human ears: A biometric perspective","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650340908&doi=10.1109%2fBTAS.2010.5634535&partnerID=40&md5=d8e7ea3b7125bb5afc3178d390578928","In this paper, an analysis of the symmetry of human ears is presented. Such an analysis is essential in order to understand the possibility of matching the left and right ears of an individual, or to reconstruct portions of the ear that may be occluded in a surveillance video. Ear symmetry is assessed geometrically using symmetry operators and Iannarelli's measurements, where the contribution of individual ear regions to the overall symmetry of the ear is studied. Next, to assess the ear symmetry (or asymmetry) from a biometric recognition system perspective, several experiments were conducted on the WVU Ear Database. Our experiments suggest the existence of some degree of symmetry in the human ears that can perhaps be systematically exploited in the design of commercial ear recognition systems. At the same time, the degree of asymmetry it offers may be used in designing effective fusion schemes that combine the face information with the two ears. © 2010 IEEE.",
"Gnanaprakasam C., Sumathi S., Malini R.R.H.","Average-half-face in 2D and 3D using wavelets for face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952683648&partnerID=40&md5=9f2b2a4a7b3414bd133d0c123cfd75f7","Face recognition is one of the most hot and challengeable technologies, which is based on biometrics, and also one of the most potential technologies. As the most natural and friendly identification method, automatic face recognition has become the important part of the next generation computing technology. 3D face recognition methods are able to overcome the problems resulting from illumination, expression or pose variations in 2D face recognition. Utilize the symmetry of the face for face recognition, select average half-face for research. The average-half-face is constructed from the full frontal face image in two steps: First the face image is centered and divided in half and two halves are averaged together. The consequence of this discovery may result in substantial savings in storage and computation time. We would like to apply the average-half-face to facial feature extraction methods using wavelets. Applying the average-half-face to additional algorithms and databases (2D&3D) and analyzing the effect of illumination, facial expressions, occlusions and other difficulties would be helpful in identifying the most useful applications of the method. A face recognition method that is able to recognize faces at various angles is proposed. This method uses only the three dimensional range images for matching. PCA is one of the most successful techniques that have been in image recognition and compression. The purpose of PCA is to reduce the large dimensionality of the data space to the smaller intrinsic dimensionality of feature space, which is needed to describe the data economically.","Average-half-face; Decomposition; Discrete wavelet transform; Face recognition; Principal component analysis"
"Alexiadis D., Syrris V., Papastergiou A., Hatzigaidas A., Mariuta L.","A new face database and evaluation of face recognition techniques","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958725398&partnerID=40&md5=137855226809ee7ff21ffa753821bf28","This paper introduces ELA5, a new image database that is suitable for experimentation within the face recognition domain. Its design attempts to cover a variety of scenarios encompassing pose and illumination variations, different facial expressions and occlusion. In addition, established computational techniques such as Principal Component Analysis (PCA) and Multilinear PCA, combined with Fisher/Linear Discriminant Analysis (LDA) are evaluated and comparative results display their strengths and weaknesses in settings that simulate real-world conditions.","Biometric identification; Face database; Face recognition; Image processing"
"Podilchuk C., Hulbert W., Flachsbart R., Barinov L.","Face recognition for uncontrolled environments","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551717934&doi=10.1117%2f12.851986&partnerID=40&md5=d9a656cbaba2c53d92d8c6400a714605","A new face recognition algorithm has been proposed which is robust to variations in pose, expression, illumination and occlusions such as sunglasses. The algorithm is motivated by the Edit Distance used to determine the similarity between strings of one dimensional data such as DNA and text. The key to this approach is how to extend the concept of an Edit Distance on one-dimensional data to two-dimensional image data. The algorithm is based on mapping one image into another and using the characteristics of the mapping to determine a two-dimensional Pictorial-Edit Distance or P-Edit Distance. We show how the properties of the mapping are similar to insertion, deletion and substitution errors defined in an Edit Distance. This algorithm is particularly well suited for face recognition in uncontrolled environments such as stand-off and other surveillance applications. We will describe an entire system designed for face recognition at a distance including face detection, pose estimation, multi-sample fusion of video frames and identification. Here we describe how the algorithm is used for face recognition at a distance, present some initial results and describe future research directions. © 2010 Copyright SPIE - The International Society for Optical Engineering.","biometrics; face recognition; stand-off; uncontrolled environment"
"Woodard D.L., Pundlik S., Miller P., Jillela R., Ross A.","On the fusion of periocular and iris biometrics in non-ideal imagery","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149490734&doi=10.1109%2fICPR.2010.58&partnerID=40&md5=4d46072c7c9a0a7c72c11c986fa2a89a","Human recognition based on the iris biometric is severely impacted when encountering non-ideal images of the eye characterized by occluded irises, motion and spatial blur, poor contrast, and illumination artifacts. This paper discusses the use of the periocular region surrounding the iris, along with the iris texture patterns, in order to improve the overall recognition performance in such images. Periocular texture is extracted from a small, fixed region of the skin surrounding the eye. Experiments on the images extracted from the Near Infra-Red (NIR) face videos of the Multi Biometric Grand Challenge (MBGC) dataset demonstrate that valuable information is contained in the periocular region and it can be fused with the iris texture to improve the overall identification accuracy in non-ideal situations. © 2010 IEEE.",
"Ramanathan V., Wechsler H.","Robust human authentication using appearance and holistic anthropometric features","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956394174&doi=10.1016%2fj.patrec.2010.07.011&partnerID=40&md5=7db47cca79fc6ff1e9701a92e4435111","We propose here decision-level fusion using neural networks and feature-level fusion using boosting for the purpose of robust human authentication vis - vis face occlusion and disguise. Holistic anthropometric and appearance-based features feed the data fusion stage. In addition to standard head and face geometric measurements, the proposed holistic anthropometric features include additional measurements below the face to describe the neck and shoulder and their contextual relations to head and face. The appearance-based features include standard PCA or Fisherfaces. Experimental data shows the feasibility and utility of the proposed hybrid (extended geometry + appearance) approach for robust human authentication vis - vis occluded and/or degraded face biometrics. The authentication results presented compare favorably against both appearance-based methods and hybrid methods with anthropometric features confined to face and head. The methods proposed can train on clean data and authenticate on corrupt data, or train on corrupt data and authenticate on clean data. © 2010 Elsevier B.V. All rights reserved.","Anthropometry; Biometrics; Face recognition; Feature selection; Occlusion and disguise; Soft biometrics"
"Gupta P., Kisku D.R., Sing J.K., Tistarelli M.","Maximized posteriori attributes selection from facial salient landmarks for face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957941175&doi=10.1007%2f978-3-642-13365-7_1&partnerID=40&md5=7464b25036b9e04616fd0833fee8ece5","This paper presents a robust and dynamic face recognition technique based on the extraction and matching of devised probabilistic graphs drawn on SIFT features related to independent face areas. The face matching strategy is based on matching individual salient facial graph characterized by SIFT features as connected to facial landmarks such as the eyes and the mouth. In order to reduce the face matching errors, the Dempster-Shafer decision theory is applied to fuse the individual matching scores obtained from each pair of salient facial features. The proposed algorithm is evaluated with the ORL and the IITK face databases. The experimental results demonstrate the effectiveness and potential of the proposed face recognition technique also in case of partially occluded faces. © 2010 Springer-Verlag Berlin Heidelberg.","Dempster-Shafer decision theory; Face biometrics; Graph matching; Intra-modal fusion; SIFT features"
"Storer M., Urschler M., Bischof H.","Occlusion detection for ICAO compliant facial photographs","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956536436&doi=10.1109%2fCVPRW.2010.5544616&partnerID=40&md5=bb1bc4d7b1c8a9ad4afe9a34947e20c1","Facial image analysis is an important computer vision topic as a first step for biometric applications like face recognition/verification. The ICAO specification defines criteria to assess suitability of facial images for later use in such tasks. This standard prohibits photographs showing occlusions, thus there is the need to detect occluded images automatically. In this work we present a novel algorithm for occlusion detection and evaluate its performance on several databases. First, we use the publicly available AR faces database which contains many occluded face image samples We show a straight-forward algorithm based on color space techniques which gives a very high performance on this database. We conclude that the AR faces database is too simple to evaluate occlusions and propose our own, more complex database, which includes, e.g., hands or arbitrary objects covering the face. Finally we extend our first algorithm by an Active Shape Model in combination with a CA reconstruction verification. We show how our novel occlusion detection algorithm outperforms the simple approach on our more complex database. © 2010 IEEE.",
"Moskovich B., Osadchy M.","Illumination invariant representation for privacy preserving face identification","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956533993&doi=10.1109%2fCVPRW.2010.5544620&partnerID=40&md5=ad1d6fa92ba49e9614b3581493f6a2b6","Most effective face recognition methods store biometric information in the clear. Doing so exposes those systems to the risk of identity theft and violation of privacy. This problem significantly narrows the practical use of face recognition technology. Recent methods for privacy preserving face recognition address face verification task. Most of them are unable to generalize to unseen conditions and require a large number of images of every user for training. We address the problem of face identification, which is more useful in security applications, and propose a binary, illumination invariant representation that can be easily integrated with various efficient cryptographic tools for protection. We propose several privacy preserving applications for our representation and test it on a number of benchmark databases to show its robustness to severe illumination changes, occlusions, and some other appearance variations. © 2010 IEEE.",
"De Marsico M., Nappi M., Daniel R.","HERO: Human Ear Recognition against Occlusions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956510667&doi=10.1109%2fCVPRW.2010.5544623&partnerID=40&md5=7d92d2cf32960c6ee6f3b58e3e5d0952","Iannarelli's studies demonstrated that ear shape represents a biometric identifier able to authenticate people in the same way as more established biometrics, like face or voice for instance. However, not many researches can be found in literature about ear recognition. In most cases existing algorithms are borrowed from other biometric contexts. An example is PCA (Principal Component Analysis). Eigen-ears only provide high recognition rate in closely controlled conditions, while performances decay even for small changes in environmental conditions. We propose a fractal based technique, namely HERO (Human Ear Recognition against Occlusions) to classify human ears. The feature extraction process has been made local, so that the system gets robust with respect to small changes in pose/illumination and partial occlusions. Experimental results confirm the superiority of this approach over several linear and non linear techniques. © 2010 IEEE.",
"Roy K., Bhattacharya P.","Iris recognition using genetic algorithms and asymmetrical SVMs","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956517763&partnerID=40&md5=4b63d2a2daf98c77156c1afd8aa65c35","With the increasing demand for enhanced security, iris biometrics-based personal identification has become an interesting research topic in the field of pattern recognition. While most state-of-the-art iris recognition algorithms are focused on preprocessing iris images, important new directions have been identified recently in iris biometrics research. These include optimal feature selection and iris pattern classification. In this paper, we propose an iris recognition scheme based on Genetic Algorithms (GAs) and asymmetrical Support Vector Machines (SVMs). Instead of using the whole iris region, we elicit the iris information between the collarette and the pupillary boundaries to suppress effects of eyelids and eyelashes occlusions, and pupil dilation, and to minimize the matching error. To select the optimal feature subset together with increasing the overall recognition accuracy, we apply GAs with a new fitness function. The traditional SVMs are modified into asymmetrical SVMs to handle: (1) highly unbalanced sample proportion between two classes, and 2) different types of misclassification error that lead to different misclassification losses. Furthermore, the parameters of SVMs are optimized in order to improve the generalization performance. The proposed technique is computationally effective, with recognition rates of 97.80% and 95.70% on the Iris Challenge Evaluation (ICE) and the West Virginia University (WVU) iris datasets, respectively.","Asymmetrical support vector machines; Biometrics; Collarette area localization; Genetic algorithms; Iris recognition"
"Park U., Jain A.K.","Face matching and retrieval using soft biometrics","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955684511&doi=10.1109%2fTIFS.2010.2049842&partnerID=40&md5=7730a655d5fbb1c34768d311f4466906","Soft biometric traits embedded in a face (e.g., gender and facial marks) are ancillary information and are not fully distinctive by themselves in face-recognition tasks. However, this information can be explicitly combined with face matching score to improve the overall face-recognition accuracy. Moreover, in certain application domains, e.g., visual surveillance, where a face image is occluded or is captured in off-frontal pose, soft biometric traits can provide even more valuable information for face matching or retrieval. Facial marks can also be useful to differentiate identical twins whose global facial appearances are very similar. The similarities found from soft biometrics can also be useful as a source of evidence in courts of law because they are more descriptive than the numerical matching scores generated by a traditional face matcher. We propose to utilize demographic information (e.g., gender and ethnicity) and facial marks (e.g., scars, moles, and freckles) for improving face image matching and retrieval performance. An automatic facial mark detection method has been developed that uses 1) the active appearance model for locating primary facial features (e.g., eyes, nose, and mouth), 2) the Laplacian-of-Gaussian blob detection, and 3) morphological operators. Experimental results based on the FERET database (426 images of 213 subjects) and two mugshot databases from the forensic domain (1225 images of 671 subjects and 10000 images of 10000 subjects, respectively) show that the use of soft biometric traits is able to improve the face-recognition performance of a state-of-the-art commercial matcher. © 2010 IEEE.","Demographic information; face marks; face recognition; face retrieval; soft biometrics"
"Naseem I., Togneri R., Bennamoun M.","Linear regression for face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149282850&doi=10.1109%2fTPAMI.2010.128&partnerID=40&md5=8960e44c9c442968843bee423d490dfe","In this paper, we present a novel approach of face identification by formulating the pattern recognition problem in terms of linear regression. Using a fundamental concept that patterns from a single-object class lie on a linear subspace, we develop a linear model representing a probe image as a linear combination of class-specific galleries. The inverse problem is solved using the least-squares method and the decision is ruled in favor of the class with the minimum reconstruction error. The proposed Linear Regression Classification (LRC) algorithm falls in the category of nearest subspace classification. The algorithm is extensively evaluated on several standard databases under a number of exemplary evaluation protocols reported in the face recognition literature. A comparative study with state-of-the-art algorithms clearly reflects the efficacy of the proposed approach. For the problem of contiguous occlusion, we propose a Modular LRC approach, introducing a novel Distance-based Evidence Fusion (DEF) algorithm. The proposed methodology achieves the best results ever reported for the challenging problem of scarf occlusion. © 2006 IEEE.","Face recognition; linear regression; nearest subspace classification"
"Štruc V., Pavešić N.","Face recognition from color images using sparse projection analysis","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955453908&doi=10.1007%2f978-3-642-13772-3_45&partnerID=40&md5=49ad09d8355bee8b774c502be30947c1","The paper presents a novel feature extraction technique for face recognition which uses sparse projection axes to compute a low- dimensional representation of face images. The proposed technique derives the sparse axes by first recasting the problem of face recognition as a regression problem and then solving the new (under-determined) regression problem by computing the solution with minimum L1 norm. The developed technique, named Sparse Projection Analysis (SPA), is applied to color as well as grey-scale images from the XM2VTS database and compared to popular subspace projection techniques (with sparse and dense projection axes) from the literature. The results of the experimental assessment show that the proposed technique ensures promising results on un-occluded as well occluded images from the XM2VTS database. © 2010 Springer-Verlag.","biometrics; face recognition; Image processing; regression problem; sparse projection axes"
"Tu C.-T., Lien J.-J.J.","Automatic location of facial feature points and synthesis of facial sketches using direct combined model","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954758938&doi=10.1109%2fTSMCB.2009.2035154&partnerID=40&md5=27dedb4a375d216d1e83d148c1522849","Automatically locating multiple feature points (i.e., the shape) in a facial image and then synthesizing the corresponding facial sketch are highly challenging since facial images typically exhibit a wide range of poses, expressions, and scales, and have differing degrees of illumination and/or occlusion. When the facial sketches are to be synthesized in the unique sketching style of a particular artist, the problem becomes even more complex. To resolve these problems, this paper develops an automatic facial sketch synthesis system based on a novel direct combined model (DCM) algorithm. The proposed system executes three cascaded procedures, namely, 1) synthesis of the facial shape from the input texture information (i.e., the facial image); 2) synthesis of the exaggerated facial shape from the synthesized facial shape; and 3) synthesis of a sketch from the original input image and the synthesized exaggerated shape. Previous proposals for reconstructing facial shapes and synthesizing the corresponding facial sketches are heavily reliant on the quality of the texture reconstruction results, which, in turn, are highly sensitive to occlusion and lighting effects in the input image. However, the DCM approach proposed in this paper accurately reconstructs the facial shape and then produces lifelike synthesized facial sketches without the need to recover occluded feature points or to restore the texture information lost as a result of unfavorable lighting conditions. Moreover, the DCM approach is capable of synthesizing facial sketches from input images with a wide variety of facial poses, gaze directions, and facial expressions even when such images are not included within the original training data set. © 2006 IEEE.","Active appearance models; eigenface; face sketch synthesis; image processing and computer vision; statistical image models"
"Gupta P., Kisku D.R., Sing J.K., Tistarelli M.","Maximized posteriori attributes selection from facial salient landmarks for face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954606726&doi=10.1007%2f978-3-642-13577-4_29&partnerID=40&md5=94bf11f00a23b9d0f368b081e36ab7f6","This paper presents a robust and dynamic face recognition technique based on the extraction and matching of devised probabilistic graphs drawn on SIFT features related to independent face areas. The face matching strategy is based on matching individual salient facial graph characterized by SIFT features as connected to facial landmarks such as the eyes and the mouth. In order to reduce the face matching errors, the Dempster-Shafer decision theory is applied to fuse the individual matching scores obtained from each pair of salient facial features. The proposed algorithm is evaluated with the ORL and the IITK face databases. The experimental results demonstrate the effectiveness and potential of the proposed face recognition technique also in case of partially occluded faces. © 2010 Springer-Verlag.","Dempster-Shafer decision theory; Face biometrics; Graph matching; Intra-modal fusion; SIFT features"
"Yan S., Wang H., Liu J., Tang X., Huang T.S.","Misalignment-robust face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949748877&doi=10.1109%2fTIP.2009.2038765&partnerID=40&md5=72894dc9b8234ad148598792dc275bd0","Subspace learning techniques for face recognition have been widely studied in the past three decades. In this paper, we study the problem of general subspace-based face recognition under the scenarios with spatial misalignments and/or image occlusions. For a given subspace derived from training data in a supervised, unsupervised, or semi-supervised manner, the embedding of a new datum and its underlying spatial misalignment parameters are simultaneously inferred by solving a constrained $\ell-{1}$ norm optimization problem, which minimizes the $\ell-{1}$ error between the misalignment-amended image and the image reconstructed from the given subspace along with its principal complementary subspace. A byproduct of this formulation is the capability to detect the underlying image occlusions. Extensive experiments on spatial misalignment estimation, image occlusion detection, and face recognition with spatial misalignments and/or image occlusions all validate the effectiveness of our proposed general formulation for misalignment-robust face recognition. © 2006 IEEE.","Face recognition; Spatial misalignments; Subspace learning"
"Guarneri I., Guarnera M., Messina G., Tomaselli V.","A signature analysis based method for elliptical shape","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77749336674&doi=10.1117%2f12.838803&partnerID=40&md5=c63bc633171ec546dc5423556d87d559","The high level context image analysis regards many fields as face recognition, smile detection, automatic red eye removal, iris recognition, fingerprint verification, etc. Techniques involved in these fields need to be supported by more powerful and accurate routines. The aim of the proposed algorithm is to detect elliptical shapes from digital input images. It can be successfully applied in topics as signal detection or red eye removal, where the elliptical shape degree assessment can improve performances. The method has been designed to handle low resolution and partial occlusions. The algorithm is based on the signature contour analysis and exploits some geometrical properties of elliptical points. The proposed method is structured in two parts: firstly, the best ellipse which approximates the object shape is estimated; then, through the analysis and the comparison between the reference ellipse signature and the object signature, the algorithm establishes if the object is elliptical or not. The first part is based on symmetrical properties of the points belonging to the ellipse, while the second part is based on the signature operator which is a functional representation of a contour. A set of real images has been tested and results point out the effectiveness of the algorithm in terms of accuracy and in terms of execution time. © 2009 Copyright SPIE - The International Society for Optical Engineering.","Elliptical; Shape detection; Signature"
"De Marsico M., Nappi M., Riccio D.","FARO: FAce recognition against occlusions and expression variations","https://www.scopus.com/inward/record.uri?eid=2-s2.0-72949119941&doi=10.1109%2fTSMCA.2009.2033031&partnerID=40&md5=99cfb3bf822a196002e3e4bdffb351ca","Face recognition is widely considered as one of the most promising biometric techniques, allowing high recognition rates without being too intrusive. Many approaches have been presented to solve this special pattern recognition problem, also addressing the challenging cases of face changes, mainly occurring in expression, illumination, or pose. On the other hand, less work can be found in literature that deals with partial occlusions (i.e., sunglasses and scarves). This paper presents FAce Recognition against Occlusions and Expression Variations (FARO) as a new method based on partitioned iterated function systems (PIFSs), which is quite robust with respect to expression changes and partial occlusions. In general, algorithms based on PIFSs compute a map of self-similarities inside the whole input image, searching for correspondences among small square regions. However, traditional algorithms of this kind suffer from local distortions such as occlusions. To overcome such limitation, information extracted by PIFS is made local by working independently on each face component (eyes, nose, and mouth). Distortions introduced by likely occlusions or expression changes are further reduced by means of an ad hoc distance measure. In order to experimentally confirm the robustness of the proposed method to both lighting and expression variations, as well as to occlusions, FARO has been tested using AR-Faces database, one of the main benchmarks for the scientific community in this context. A further validation of FARO performances is provided by the experimental results produced on Face Recognition Grand Challenge database. © 2009 IEEE.","Face recognition (FR); Fractals; Identification of persons"
"Hansen D.W., Ji Q.","In the Eye of the Beholder: A Survey of Models for Eyes and Gaze","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949331734&doi=10.1109%2fTPAMI.2009.30&partnerID=40&md5=19f5763a890a51fc4e87d640a724abd8","Despite active research and significant progress in the last 30 years, eye detection and tracking remains challenging due to the individuality of eyes, occlusion, variability in scale, location, and light conditions. Data on eye location and details of eye movements have numerous applications and are essential in face detection, biometric identification, and particular human-computer interaction tasks. This paper reviews current progress and state of the art in video-based eye detection and tracking in order to identify promising techniques as well as issues to be further addressed. We present a detailed review of recent eye models and techniques for eye detection and tracking. We also survey methods for gaze estimation and compare them based on their geometric properties and reported accuracies. This review shows that, despite their apparent simplicity, the development of a general eye detection technique involves addressing many challenges, requires further theoretical developments, and is consequently of interest to many other domains problems in computer vision and beyond. © 2010, The Institute of Electrical and Electronics Engineers, Inc.","Eye; eye detection; eye tracking; gaze estimation; gaze tracking; human-computer interaction; object detection and tracking; review paper"
"Ekenel H.K., Stiefelhagen R.","Face alignment by minimizing the closest classification distance","https://www.scopus.com/inward/record.uri?eid=2-s2.0-71749115423&doi=10.1109%2fBTAS.2009.5339076&partnerID=40&md5=fc925a03dac1c6585d3784f916fd5a2d","In this paper, we present a face registration approach, in which alignment is done by minimizing the closest distance at the classification step. This method eliminates the need of a feature localization step that exists in traditional face recognition systems and formulates alignment as an optimization process during classification. In other words, instead of performing a separate facial feature localization step and localizing facial features according to some type of feature matching score, in the proposed method, alignment is done by directly optimizing the classification score. Moreover, a feature detector can still be integrated to the system. In this case, the output of the feature detector is used as the initial point of the optimization process. Results of extensive experiments have shown that the proposed approach leads very high correct recognition rates, especially in the case of partial face occlusion, where it is not possible to precisely detect the facial feature locations. It has been also found that, in the case of using a facial feature detector, the approach can tolerate localization errors of up to 18% of the interocular distance. ©2009 IEEE.",
"Zeng Z., Fang T., Shah S., Kakadiaris I.A.","Local feature Hashing for face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-71749098191&doi=10.1109%2fBTAS.2009.5339013&partnerID=40&md5=2920d0978ed12ba806f69ad3b637de43","In this paper, we present Local Feature Hashing (LFH), a novel approach for face recognition. Focusing on the scalability of face recognition systems, we build our LFH algorithm on the p-stable distribution Locality-Sensitive Hashing (pLSH) scheme that projects a set of local features representing a query image to an ID histogram where the maximum bin is regarded as the recognized ID. Our extensive experiments on two publicly available databases demonstrate the advantages of our LFH method, including: i) significant computational improvement over naive search; ii) hashing in high-dimensional Euclidean space without embedding; and iii) robustness to pose, facial expression, illumination and partial occlusion. ©2009 IEEE.",
"Ananthashayana V.K., Jyothirmayi M., Pushpa M.K.","Real time face recognition using single face per person database","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864947610&partnerID=40&md5=976c22bb581228231c67a47a309260e6","Face recognition is important in today's emerging Biometrics and Video surveillance markets. This paper is addressing a practical real time face recognition system based on single person per database. We present a novel approach for face identification, by capturing the person who comes in the vicinity of the webcam view, with partial occlusion, pose variation and under different illumination constraints and detect the validity of the person. We use a neural network based Independent Component Analysis (ICA), the Infomax algorithm by Bell and Sejnowski and nearest neighbor classifier for recognition. The detection of the face is based on the skin model and face template. We find the system well suited for face recognition in a real time scenario like personal identification and monitoring employee entering the company with little modification to the existing system of swiping the identification cards. We compare the results with PCA and LDA based approaches for our system and find that ICA gives a better and reliable recognition.","Face detection; Face recognition; ICA; Real time; Single face database"
"Marcon M., Rurainsky J.","3D face reconstruction from a single camera using a multi mirror set-up","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955959630&doi=10.1049%2fic.2009.0236&partnerID=40&md5=77bfa68d0c825ba2fc22ff558bc29a1d","3D face models, thanks to the accuracy and effectiveness of recent devices and techniques for 3D object reconstruction, are extending and enforcing traditional 2D face recognition engines. Using 3D face models allows, in particular, improving recognition robustness with respect to, e.g. non-frontal or partially occluded acquisitions or variations in the lighting conditions. We further discuss some possible applicative scenarios in the conclusions. In this paper we will describe how a setup with a single hi-resolution camera together with one, two or more planar mirrors can be implemented to provide accurate 3D models of faces: in particular we will tackle the calibration phase of a multi-mirror environment showing advantages with respect to a multi cameras arrangement, we will also propose a possible reconstruction algorithm which uses a global energy-minimization approach to provide an accurate depth-map accounting for surface smoothness, non-convex regions and holes. Examples carried out with both synthetic and real data show that the proposed approach can fruitfully improve accuracy of 2D recognition engines.","3D face reconstruction; Biometrics; Multi camera systems; Multi mirrors set-up; Multi-camera calibration"
"Lin J., Li J.-P., Lin H., Ming J.","Robust person identification with face and iris by modified PUM method","https://www.scopus.com/inward/record.uri?eid=2-s2.0-76349111586&doi=10.1109%2fICACIA.2009.5361089&partnerID=40&md5=e6d4e9eb702813a4b054e266bd5d6aab","In previous works, we have applied the modified PUM method in face recognition and demonstrated the effectiveness of this method for deal with partial occlusion and distortion. Based on the similitude between the face features and iris features, this paper proposes a new method for person recognition by the combining of iris and face. This new method combines the iris and face features as a new feature for representing persons and then acts the modified PUM on the new features for recognition. Generally, the iris features, however, is more reliable than the face features. Hence the iris feature should be given a higher weight. For this, this paper further improves the method to form a better strategy for combining the face and iris on recognition. The new improved approach has been evaluated on combined-face and iris databases, using face testing images subjected to various types of partial distortion and occlusion. The new system has demonstrated improved performance over other systems. ©2009 IEEE.","Face recognition; Iris recognition; Person identification; PUM"
"Eskandari M., Toygar Ö.","Effect of eyelid and eyelash occlusions on iris images using subpattern-based approaches","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950504831&doi=10.1109%2fICSCCW.2009.5379468&partnerID=40&md5=e489f5ab16277c6acf5f7a5d6acedbb7","The effect of eyelid and eyelash occlusions on iris images is investigated in this study using subpattern-based approaches. Principal Component Analysis (PCA), subpattern-based PCA (spPCA) and modular PCA (mPCA) methods are used as feature extractors to recognize occluded iris images. In order to eliminate the effect of illumination changes, histogram equalization and mean-and-variance normalization techniques are used. Various experiments are carried out on UBIRIS, CASIA and MMU iris databases to demonstrate the effect of eyelid and eyelash occlusions on iris images. The results of the experiments are consistent with the results of other biometrics systems using PCA, spPCA and mPCA approaches. ©2009 IEEE.","Iris recognition; Occlusion; PCA; Subpattern-based approaches"
"Erbilek M., Toygar O.","Recognizing partially occluded irises using subpattern-based approaches","https://www.scopus.com/inward/record.uri?eid=2-s2.0-73949093579&doi=10.1109%2fISCIS.2009.5291890&partnerID=40&md5=7910955739bc1e69474e49f0385b875c","In this study, iris recognition in the presence of partial occlusions is investigated using holistic and subpattern-based approaches. Principal Component Analysis (PCA) and subspace Linear Discriminant Analysis (ssLDA) methods are used as feature extractors to recognize iris images. In order to eliminate the effect of illumination changes, histogram equalization and mean-and-variance normalization techniques are used. The recognition performance of the holistic approaches is compared with the performance of subpattern-based approaches spPCA, mPCA and subpattern-based ssLDA approaches in order to demonstrate the performance differences and similarities between these two types of approaches in the presence of partial occlusions. Various experiments are carried out on CASIA, UPOL and UBIRIS databases to demonstrate the effect of occlusions on iris recognition with holistic and subpattern-based approaches. © 2009 IEEE.","Iris recognition; PCA; Subpattern-based approaches; Subspace LDA"
"Micheloni C., Canazza S., Foresti G.L.","Audio-video biometric recognition for non-collaborative access granting","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350066798&doi=10.1016%2fj.jvlc.2009.01.008&partnerID=40&md5=9e7ef5f6b95c2df0d51fb8e7218015dc","In this paper, the problem of non-collaborative person identification for a secure access to facilities is addressed. The proposed solution adopts a face and a speaker recognition techniques. The integration of these two methods allows to improve the performance with respect to the two classifiers. In non-collaborative scenarios, the problem of face recognition first requires to detect the face pattern then to recognize it even when in non-frontal poses. In the current work, a histogram normalization, a boosting technique and a linear discrimination analysis have been exploited to solve typical problems like illumination variability, occlusions, pose variation, etc. In addition, a new temporal classification is proposed to improve the robustness of the frame-by-frame classification. This allows to project known classification techniques for still image recognition into a multi-frame context where the image capture allows dynamics in the environment. For the audio, a method for the automatic speaker identification in noisy environments is presented. In particular, we propose an optimization of a speech de-noising algorithm to optimize the performance of the extended Kalman filter (EKF). To provide a baseline system for the integration with our proposed speech de-noising algorithm, we use a conventional speaker recognition system, based on Gaussian mixture models and mel frequency cepstral coefficients (MFCCs) as features. To confirm the effectiveness of our methods, we performed video and speaker recognition tasks first separately then integrating the results. In particular, two different corpora have been used: (a) a public corpus (ELDSR for audio and FERRET for images) and (b) a dedicated audio/video corpus, in which the speakers read a list of sentences wearing a scarf or a full-face motorcycle helmet. Experimental results show that our methods are able to reduce significantly the classification error rate. © 2009 Elsevier Ltd. All rights reserved.","Audio de-noising; Face detection; Face recognition; Speaker recognition"
"Erbilek M., Toygar O.","Robustness of subpattern-based approaches to occlusions on iris images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864947422&partnerID=40&md5=2b761e9776dac3e4a82730d8f1d03677","The effect of occlusions on holistic and subpattern-based approaches for iris recognition is studied in this paper. The performance analysis of these methods is presented without applying the traditional iris detection methods. Original PCA and subspace LDA methods are used as feature extractors with the combination of the preprocessing techniques of histogram equalization and mean-and-variance normalization in order to nullify the effect of illumination changes which are known to significantly degrade recognition performance. The recognition performance of the holistic approaches is compared with the performance of subpattern-based PCA and subpattern-based subspace LDA approaches To be consistent with the research of others, our work has been tested on three iris databases namely CASIA, UPOL and UBIRIS. The experiments are performed on these three iris databases to demonstrate the recognition performances of the subpattern-based approaches and traditional PCA and subspace LDA approaches.","Iris recognition; PCA; Subpattern-based approaches; Subspace LDA"
"Ioan B., Ioan N.","Non-negative matrix factorization methods for face recognition under extreme lighting variations","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449499764&doi=10.1109%2fISSCS.2009.5206186&partnerID=40&md5=e9103c49387bf8fa7a292994624e72a8","Face recognition task is of primary interest in many computer vision applications, including access control for security systems, forensic or surveillance. Most commercial biometric systems based on face recognition are claimed to perform satisfactory when the enrollment and testing process takes place under controlled environmental conditions such as constant illumination, constant pose scale, non-occluded faces or frontal view. More or less deviation from those conditions might lead to poor recognition performances or even recognition system's failure when a test identity has to be recognized under new modified testing conditions. Three non-negative matrix factorization (NMF) methods, namely, the standard one, the local NMF (LNMF) and the discriminant NMF (DNMF) are employed in this paper where their robustness against extreme lighting variations are tested for the face recognition task. Principal Component Analysis (peA) method was also chosen as baseline. Experiments revealed that the best recognition performance is obtained with NMF, followed by DNMF and LNMF. ©2009 IEEE.",
"Du X., Liu C., Yu Y.","Analysis of detection and track on partially occluded face","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350550672&doi=10.1109%2fIFITA.2009.265&partnerID=40&md5=14ba965e641c686c62c9da51446b194c","As a new field of information technology,biometrics recognition consists of the recognition of face, iris,retina, pronunciation etc. In recent years, Static face detection algorithms concerning the categories of detection technology have been raised, but these algorithms put their focus on the detection of clear face. The research of detection on partially occluded face has not yet been conducted. Under this circumstance, the thesis gives a brand new static detection and dynamic track algorithm on partially occluded face. This new algorithm is that the static partial face is detected by the YCbCr, the dynamic image sequences use a logic ""and"" operation to track the partial face, and then the static partial face and dynamic face are fitted, if the fitting value is smaller than the pre-value, the static partial face is considered as a non-face; otherwise the partial is a face. By analyzing the 50 graphs including 160 faces (60 partial faces and 100 clear faces), it has been found that the detection accuracy of the partial faces is 62% and the clear faces detection accuracy is 98%. This new algorithm can provide important reference to partial face detection. the algorithm still needs to be verified and improved further. © 2009 IEEE.","Face detection; Knowledge model; Logic calculation; Skin color model; Static fill"
"Yi D., Liao S., Lei Z., Sang J., Li S.Z.","Partial face matching between near infrared and visual images in MBGC portal challenge","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70049108544&doi=10.1007%2f978-3-642-01793-3_75&partnerID=40&md5=499b2539e42b4d97425ac51c1d0b59eb","The latest multi-biometric grand challenge (MBGC 2008) sets up a new experiment in which near infrared (NIR) face videos containing partial faces are used as a probe set and the visual (VIS) images of full faces are used as the target set. This is challenging for two reasons: (1) it has to deal with partially occluded faces in the NIR videos, and (2) the matching is between heterogeneous NIR and VIS faces. Partial face matching is also a problem often confronted in many video based face biometric applications. In this paper, we propose a novel approach for solving this challenging problem. For partial face matching, we propose a local patch based method to deal with partial face data. For heterogeneous face matching, we propose the philosophy of enhancing common features in heterogeneous images while reducing differences. This is realized by using edge-enhancing filters, which at the same time is also beneficial for partial face matching. The approach requires neither learning procedures nor training data. Experiments are performed using the MBGC portal challenge data, comparing with several known state-of-the-arts methods. Extensive results show that the proposed approach, without knowing statistical characteristics of the subjects or data, outperforms the methods of contrast significantly, with ten-fold higher verification rates at FAR of 0.1%. © Springer-Verlag Berlin Heidelberg 2009.","Heterogeneous face biometrics; MBGC portal challenge; Multiple biometric grand challenge (MBGC); Near infrared (NIR); Video based face recognition"
"Ekenel H.K., Stiefelhagen R.","Why is facial occlusion a challenging problem?","https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949184955&doi=10.1007%2f978-3-642-01793-3_31&partnerID=40&md5=170f56965d2b842c6376366d3b08dcd5","This paper investigates the main reason for the obtained low performance when the face recognition algorithms are tested on partially occluded face images. It has been observed that in the case of upper face occlusion, missing discriminative information due to occlusion only accounts for a very small part of the performance drop. The main factor is found to be the registration errors due to erroneous facial feature localization. It has been shown that by solving the misalignment problem, very high correct recognition rates can be achieved with a generic local appearance-based face recognition algorithm. In the case of a lower face occlusion, only a slight decrease in the performance is observed, when a local appearance-based face representation approach is used. This indicates the importance of local processing when dealing with partial face occlusion. Moreover, improved alignment increases the correct recognition rate also in the experiments against the lower face occlusion, which shows that face registration plays a key role on face recognition performance. © Springer-Verlag Berlin Heidelberg 2009.",
"Su Y., Ai H., Lao S.","Multi-view face alignment using 3D shape model for view estimation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949155206&doi=10.1007%2f978-3-642-01793-3_19&partnerID=40&md5=82d790ae6f13329a0ebb44f9e24e33b7","For multi-view face alignment (MVFA), the non-linear variation of shape and texture, and the self-occlusion of facial feature points caused by view change are the two major difficulties. The state-of-the-art MVFA methods are essentially view-based approaches in which views are divided into several categories such as frontal, half profile, full profile etc. and each of them has its own model in MVFA. Therefore the view estimation problem becomes a critical step in MVFA. In this paper, a MVFA method using 3D face shape model for view estimation is presented in which the 3D shape model is used to estimate the pose of the face thereby selecting its model and indicating its self-occluded points. Experiments on different datasets are reported to show the improvement over previous works. © Springer-Verlag Berlin Heidelberg 2009.","3D face model; Active Shape Model; Face alignment"
"Schwartz W.R., Gopalan R., Chellappa R., Davis L.S.","Robust human detection under occlusion by integrating face and person detectors","https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949189276&doi=10.1007%2f978-3-642-01793-3_98&partnerID=40&md5=f1cf8b4208088b1657e2f6934a8f00cd","Human detection under occlusion is a challenging problem in computer vision. We address this problem through a framework which integrates face detection and person detection. We first investigate how the response of a face detector is correlated with the response of a person detector. From these observations, we formulate hypotheses that capture the intuitive feedback between the responses of face and person detectors and use it to verify if the individual detectors' outputs are true or false. We illustrate the performance of our integration framework on challenging images that have considerable amount of occlusion, and demonstrate its advantages over individual face and person detectors. © Springer-Verlag Berlin Heidelberg 2009.",
"Wang X., Tang X.","Face photo-sketch synthesis and recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349854895&doi=10.1109%2fTPAMI.2008.222&partnerID=40&md5=4f7753aa33f0987a7b44ae79bcfebe41","In this paper, we propose a novel face photo-sketch synthesis and recognition method using a multiscale Markov Random Fields (MRF) model. Our system has three components: 1) given a face photo, synthesizing a sketch drawing; 2) given a face sketch drawing, synthesizing a photo; and 3) searching for face photos in the database based on a query sketch drawn by an artist. It has useful applications for both digital entertainment and law enforcement. We assume that faces to be studied are in a frontal pose, with normal lighting and neutral expression, and have no occlusions. To synthesize sketch/photo images, the face region is divided into overlapping patches for learning. The size of the patches decides the scale of local face structures to be learned. From a training set which contains photo-sketch pairs, the joint photo-sketch model is learned at multiple scales using a multiscale MRF model. By transforming a face photo to a sketch (or transforming a sketch to a photo), the difference between photos and sketches is significantly reduced, thus allowing effective matching between the two in face sketch recognition. After the photo-sketch transformation, in principle, most of the proposed face photo recognition approaches can be applied to face sketch recognition in a straightforward way. Extensive experiments are conducted on a face sketch database including 606 faces, which can be downloaded from our Web site (http://mmlab.ie.cuhk.edu.hk/ facesketch.html). © 2009 IEEE.","Face recognition; Face sketch recognition; Face sketch synthesis; Multiscale Markov random field"
"Wang Y., Zhang L., Liu Z., Hua G., Wen Z., Zhang Z., Samaras D.","Face relighting from a single image under arbitrary unknown lighting conditions","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349860271&doi=10.1109%2fTPAMI.2008.244&partnerID=40&md5=94b0de9b4b20006a5af6bdb93bb37e11","In this paper, we present a new method to modify the appearance of a face image by manipulating the illumination condition, when the face geometry and albedo information is unknown. This problem is particularly difficult when there is only a single image of the subject available. Recent research demonstrates that the set of images of a convex Lambertian object obtained under a wide variety of lighting conditions can be approximated accurately by a low-dimensional linear subspace using a spherical harmonic representation. Moreover, morphable models are statistical ensembles of facial properties such as shape and texture. In this paper, we integrate spherical harmonics into the morphable model framework by proposing a 3D spherical harmonic basis morphable model (SHBMM). The proposed method can represent a face under arbitrary unknown lighting and pose simply by three low-dimensional vectors, i.e., shape parameters, spherical harmonic basis parameters, and illumination coefficients, which are called the SHBMM parameters. However, when the image was taken under an extreme lighting condition, the approximation error can be large, thus making it difficult to recover albedo information. In order to address this problem, we propose a subregion-based framework that uses a Markov random field to model the statistical distribution and spatial coherence of face texture, which makes our approach not only robust to extreme lighting conditions, but also insensitive to partial occlusions. The performance of our framework is demonstrated through various experimental results, including the improved rates for face recognition under extreme lighting conditions. © 2009 IEEE.","3D spherical harmonic basis morphable model; Face synthesis and recognition; Markov random field; Vision for graphics"
"Grassi M., Faundez-Zanuy M., Piazza F.","Face localization in 2D frontal face images using luminosity profiles analysis","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650491399&doi=10.1007%2f978-3-642-00525-1_34&partnerID=40&md5=6bda0e1d4df73179cc2222a7b718d57f","Face detection from a single image represents a challenging task because of variability in scale, location, orientation and pose. Facial expression, occlusion, and lighting conditions also change the overall appearance of faces. In this work we propose a fast face localization method in 2D frontal face images, through eyes detection, based on the analysis of the horizontal and vertical profiles of image's average luminosity and the definition of rules describing the relations between these profiles and the positions of characteristic face elements. Experimental results over the AR face database show high rates of successful detection together with reduced computational times that make this method particularly suitable for real time applications. © Springer-Verlag Berlin Heidelberg 2009.","Biometrics; Face detection; Face recognition; Image segmentation"
"Wechsler H.","Linguistics and face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349268147&doi=10.1016%2fj.jvlc.2009.01.001&partnerID=40&md5=b0c8816243d8554d01d0acee3ee1166d","We describe in this paper a novel biometric methodology for face recognition suitable to address pose, illumination, and expression (PIE) image variability, temporal change, flexible matching, and last but not least occlusion and disguise that are usually referred to as denial and deception. The adverse conditions listed above affect the scope and performance of biometric analysis vis-à-vis both training and testing. The conceptual framework proposed here draws support from discriminative methods using likelihood ratios. At the conceptual level it links forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory. As many of the concerns listed usually affect only parts of the face, a non-parametric recognition-by-part approach is advanced here for the purpose of reliable face recognition. Recognition-by-parts facilitates authentication because it does not seek for explicit invariance. Instead, it handles variability using component-based configurations that are flexible enough to compensate among others for limited pose changes, if any, and limited occlusion and disguise. The recognition-by-parts approach proposed here supports incremental and progressive processing. It is similar in nature to modern linguistics and practical intelligence with the emphasis on semantics and pragmatics. Layered categorization starts with face detection using implicit rather than explicit segmentation. It proceeds with face authentication that involves feature selection of local patch instances including dimensionality reduction, exemplar-based clustering of patches into parts, and data fusion for matching using boosting driven by parts that play the role of weak learners. The implementation, driven by transduction, employs proximity and typicality (ranking) realized using strangeness and random deficiency p-values, respectively. The feasibility and reliability of the proposed architecture has been validated using FERET and FRGC data. The paper concludes with suggestions for augmenting and enhancing the scope and utility of the recognition-by-parts architecture. © 2009 Elsevier Ltd. All rights reserved.","Authentication; Biometrics; Boosting; Clustering; Cross-validation; Data fusion; Face recognition; Feature selection; FERET; Forensics; FRGC; ICA; k Nearest neighbor; Likelihood ratio; Linguistics; Margin; MDL; Multimodal integration; Neyman-Pearson; Occlusion; p-Values; Parsing; Random deficiency; Ranking; Recognition; Recognition-by-parts; Segmentation; SIFT; Strangeness; Surveillance; Transduction; Typicality"
"Wright J., Yang A.Y., Ganesh A., Sastry S.S., Ma Y.","Robust face recognition via sparse representation","https://www.scopus.com/inward/record.uri?eid=2-s2.0-61549128441&doi=10.1109%2fTPAMI.2008.79&partnerID=40&md5=39f75e5abd4191b495e297186fb1a04d","We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well as occlusion and disguise. We cast the recognition problem as one of classifying among multiple linear regression models and argue that new theory from sparse signal representation offers the key to addressing this problem. Based on a sparse representation computed by C1 -minimization, we propose a general classification algorithm for (image-based) object recognition. This new framework provides new insights into two crucial issues in face recognition: feature extraction and robustness to occlusion. For feature extraction, we show that if sparsity in the recognition problem is properly harnessed, the choice of features is no longer critical. What is critical, however, is whether the number of features is sufficiently large and whether the sparse representation is correctly computed. Unconventional features such as downsampled images and random projections perform just as well as conventional features such as eigenfaces and Laplacianfaces, as long as the dimension of the feature space surpasses certain threshold, predicted by the theory of sparse representation. This framework can handle errors due to occlusion and corruption uniformly by exploiting the fact that these errors are often sparse with respect to the standard (pixel) basis. The theory of sparse representation helps predict how much occlusion the recognition algorithm can handle and how to choose the training images to maximize robustness to occlusion. We conduct extensive experiments on publicly available databases to verify the efficacy of the proposed algorithm and corroborate the above claims. © 2009 IEEE.","ℓ1-minimization; Compressed sensing; Face recognition; Feature extraction; Occlusion and corruption; Sparse representation; Validation and outlier rejection"
"Zhang D., You X., Wang P., Yanushkevich S.N., Tang Y.Y.","Facial biometrics using nontensor product wavelet and 2d discriminant techniques","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650694969&doi=10.1142%2fS0218001409007260&partnerID=40&md5=f51c287267f1cd2d1b19d7dc168bc6c5","A new facial biometric scheme is proposed in this paper. Three steps are included. First, a new nontensor product bivariate wavelet is utilized to get different facial frequency components. Then a modified 2D linear discriminant technique (M2DLD) is applied on these frequency components to enhance the discrimination of the facial features. Finally, support vector machine (SVM) is adopted for classification. Compared with the traditional tensor product wavelet, the new nontensor product wavelet can detect more singular facial features in the high-frequency components. Earlier studies show that the high-frequency components are sensitive to facial expression variations and minor occlusions, while the low-frequency component is sensitive to illumination changes. Therefore, there are two advantages of using the new nontensor product wavelet compared with the traditional tensor product one. First, the low-frequency component is more robust to the expression variations and minor occlusions, which indicates that it is more efficient in facial feature representation. Second, the corresponding high-frequency components are more robust to the illumination changes, subsequently it is more powerful for classification as well. The application of the M2DLD on these wavelet frequency components enhances the discrimination of the facial features while reducing the feature vectors dimension a lot. The experimental results on the AR database and the PIE database verified the efficiency of the proposed method. © 2009 World Scientific Publishing Company.","Face recognition; Nontensor product wavelet; Two-dimensional component analysis"
"Li F., Wechsler H.","Face authentication using recognition-by-parts, boosting and transduction","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349172877&doi=10.1142%2fS0218001409007193&partnerID=40&md5=2bc7d8b2c37455bfb9d9751b74f1939c","The paper describes an integrated recognition-by-parts architecture for reliable and robust face recognition. Reliability and robustness are characteristic of the ability to deploy full-fledged and operational biometric engines, and handling adverse image conditions that include among others uncooperative subjects, occlusion, and temporal variability, respectively. The architecture proposed is model-free and non-parametric. The conceptual framework draws support from discriminative methods using likelihood ratios. At the conceptual level it links forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory (SLT). Layered categorization starts with face detection using implicit rather than explicit segmentation. It proceeds with face authentication that involves feature selection of local patch instances including dimensionality reduction, exemplar-based clustering of patches into parts, and data fusion for matching using boosting driven by parts that play the role of weak-learners. Face authentication shares the same implementation with face detection. The implementation, driven by transduction, employs proximity and typicality (ranking) realized using strangeness and p-values, respectively. The feasibility and reliability of the proposed architecture are illustrated using FRGC data. The paper concludes with suggestions for augmenting and enhancing the scope and utility of the proposed architecture. © 2009 World Scientific Publishing Company.","Authentication; Biometrics; Boosting; Clustering; Cross-validation; Data fusion; Dimensionality reduction; Face recognition; Feature selection; Forensics; K-nearest neighbor; Likelihood ratio; Margin; NeymanPearson; Occlusion; Open set recognition; P-values; Ranking"
"Watabe D., Sai H., Ueda T., Sakai K., Nakamura O.","ICA, LDA, and Gabor jets for robust ear recognition, and jet space similarity for ear detection","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054011260&doi=10.1080%2f1931308X.2009.10644168&partnerID=40&md5=88f16c7490c0e942d7c9be76aecc3976","Fully automatic and robust ear recognition systems that use only 2D grayscale still images are presented. To exploit robustness against pose variation, changes in lighting, and hair occlusions, we thoroughly examined the techniques: linear discriminant analysis (LDA), independent component analysis (ICA), and Gabor jets. We obtained a 93.3% rank-one recognition rate on a dataset of 121 subjects in 4 image sets taken on various days from the public face database XM2VTS, where 47.0% of the images show hair occlusion, pose variation, and jagged images. To fully automate the recognition algorithm, we developed an ear detection algorithm that uses Gabor jets subjected to training using principal components analysis. A 1.0% equal error rate was obtained in experiments on the XM2VTS database. Our experiments provide evidence that ear biometrics has the potential for use in real-world applications for identifying individuals by their ears. © 2009, Taylor & Francis Group, LLC.","Ear biometrics; EICA; Eigen jet; Gabor jet; ICA; LDA"
"Savran A., Alyüz N., Dibeklioǧlu H., Çeliktutan O., Gökberk B., Sankur B., Akarun L.","Bosphorus database for 3D face analysis","https://www.scopus.com/inward/record.uri?eid=2-s2.0-59149105946&doi=10.1007%2f978-3-540-89991-4_6&partnerID=40&md5=83b7bbad9fb84b7d8e059c0c7a4b5fec","A new 3D face database that includes a rich set of expressions, systematic variation of poses and different types of occlusions is presented in this paper. This database is unique from three aspects: i) the facial expressions are composed of judiciously selected subset of Action Units as well as the six basic emotions, and many actors/actresses are incorporated to obtain more realistic expression data; ii) a rich set of head pose variations are available; and iii) different types of face occlusions are included. Hence, this new database can be a very valuable resource for development and evaluation of algorithms on face recognition under adverse conditions and facial expression analysis as well as for facial expression synthesis. © 2008 Springer Berlin Heidelberg.",
"Zhang G., Wang Y.","Combining cascade PCA and face shape models for robust registration","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959357292&doi=10.1117%2f12.777365&partnerID=40&md5=ec2e9ad4c9df6d073c7725ef69ca2451","3D facial feature point localization is very important to registration. This paper proposes a localization method that is capable of locating 3D facial feature points rapidly while achieving high localization and registration accuracy. There are two contributions of this paper. The first is the introduction of the Cascade PCA which allows the non-occluded and symmetric face models to be normalized quickly while spending more computation on occluded face models. The second is the three face shape models which are used to verify the normalization results produced by Cascade PCA, and localize dozens of feature points at the same time. Experimental results prove the efficiency and accuracy of our method both in localization and registration.","Cascade PCA; Face shape models; Registration"
"Buciu I.","Overview of face recognition techniques","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956274069&partnerID=40&md5=9a21c8da1af201fe77c82d79df9ac5f4","Humans are able to rapidly and accurately recognize familiar faces and identities under widely varying and difficult viewing conditions, such as illuminations changing, occlusion, scaling or rotation. Motivated by its importance in human-to-human communication and leading to various applications, from biometrics to human - computer interaction, the face recognition task is a major issue in the Computer Vision field and more. This paper presents a brief survey on state-of-the art methods used to cope with this challenging task.","Applications; Face recognition techniques; Open problems; Technologies"
"Sundaraj K.","Real-time face detection using dynamic background subtraction","https://www.scopus.com/inward/record.uri?eid=2-s2.0-59549102867&partnerID=40&md5=e11c039ab930cd024e8897d453364436","Face biometrics is an automated method of recognizing a person's face based on a physiological or behavioral characteristic. Face recognition works by first obtaining an image of a person. This process is usually known as face detection. In this paper, we describe an approach for face detection that is able to locate a human face embedded in an outdoor or indoor background. Segmentation of novel or dynamic objects in a scene, often referred to as background subtraction or foreground segmentation, is a critical early step in most computer vision applications in domains such as surveillance and human-computer interaction. All previous implementations aim to handle properly one or more problematic phenomena, such as global illumination changes, shadows, highlights, foreground-background similarity, occlusion and background clutter. Satisfactory results have been obtained but very often at the expense of real-time performance. We propose a method for modeling the background that uses per-pixel time-adaptive Gaussian mixtures in the combined input space of pixel color and pixel neighborhood. We add a safety net to this approach by splitting the luminance and chromaticity components in the background and use their density functions to detect shadows and highlights. Several criteria are then combined to discriminate foreground and background pixels. Our experiments show that the proposed method possesses robustness to problematic phenomena such as global illumination changes, shadows and highlights, without sacrificing real-time performance, making it well-suited for a live video event like face biometric that requires face detection and recognition.","Background subtraction; Face detection"
"Sundaraj K.","Real-time background subtraction using adaptive thresholding and dynamic updating for biometric face detection","https://www.scopus.com/inward/record.uri?eid=2-s2.0-59249105257&partnerID=40&md5=8dfaa4a52b17306daf85675594a5e780","Face biometrics is an automated method of recognizing a person's face based on a physiological or behavioral characteristic. Face recognition works by first obtaining an image of a person. This process is usually known as face detection. In this paper, we describe an approach for face detection that is able to locate a human face embedded in an outdoor or indoor background. Segmentation of novel or dynamic objects in a scene, often referred to as background subtraction or foreground segmentation, is a critical early step in most computer vision applications in domains such as surveillance and human-computer interaction. All previous implementations aim to handle properly one or more problematic phenomena, such as global illumination changes, shadows, highlights, foreground-background similarity, occlusion and background clutter. Satisfactory results have been obtained but very often at the expense of real-time performance. We propose a method for modeling the background that uses per-pixel time-adaptive Gaussian mixtures in the combined input space of pixel color and pixel neighborhood. We add a safety net to this approach by splitting the luminance and chromaticity components in the background and use their density functions to detect shadows and highlights. Several criteria are then combined to discriminate foreground and background pixels. Our experiments show that the proposed method possesses robustness to problematic phenomena such as global illumination changes, shadows and highlights, without sacrificing real-time performance, making it well-suited for a live video event like face biometric that requires face detection and recognition.","Background modeling; Biometric identification; Face detection"
"Li F., Wechsler H., Tistarelli M.","Robust fusion using boosting and transduction for component-based face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-64549146171&doi=10.1109%2fICARCV.2008.4795558&partnerID=40&md5=f99a6ba2ef5c9405d6e3be11a86cd623","Face recognition performance depends upon the input variability as encountered during biometric data capture including occlusion and disguise. The challenge met in this paper is to expand the scope and utility of biometrics by discarding unwarranted assumptions regarding the completeness and quality of the data captured. Towards that end we propose a model-free and non-parametric component-based face recognition strategy with robust decisions for data fusion that are driven by transduction and boosting. The conceptual framework draws support throughout from discriminative methods using likelihood ratios. It links at the conceptual level forensics and biometrics, while at the implementation level it links the Bayesian framework and statistical learning theory (SLT). Feature selection of local patch instances and their corresponding high-order combinations, exemplar-based clustering (of patches) as components including the sharing (of exemplars) among components, and finally decision-making regarding authentication using boosting driven by components that play the role of weak-learners, are implemented in a similar fashion using transduction driven by a strangeness measure akin to typicality. The feasibility, reliability, and utility of the proposed open set face recognition architecture vis-a-vis adverse image capture conditions are illustrated using FRGC data. The potential for future developments concludes the paper. © 2008 IEEE.","Biometrics; Boosting; Component-based recognition; Data fusion; Disguise; Face recognition; Forensics; K-nearest neighbor; Likelihood ratio; Margin; Neyman-Pearson; Occlusion; Open set recognition; Strangeness; Surveillance; Transduction; Typicality"
"Islam S.M.S., Bennamoun M., Davies R.","Fast and fully automatic ear detection using cascaded adaboost","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50849124178&doi=10.1109%2fWACV.2008.4544023&partnerID=40&md5=e2fff381f990295409da519b071682fb","Ear detection from a profile face image is an important step in many applications including biometric recognition. But accurate and rapid detection of the ear for real-time applications is a challenging task, particularly in the presence of occlusions. In this work, a cascaded AdaBoost based ear detection approach is proposed. In an experiment with a test set of 203 profile face images, all the ears were accurately detected by the proposed detector with a very low (5 × 10-6) false positive rate. It is also very fast and relatively robust to the presence of occlusions and degradation of the ear images (e.g. motion blur). The detection process is fully automatic and does not require any manual intervention.",
"Lai H., Ramanathan V., Wechsler H.","Reliable face recognition using adaptive and robust correlation filters","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50249171815&doi=10.1016%2fj.cviu.2008.01.003&partnerID=40&md5=5d8426ed6245c900d68f43fa8615a7c1","This paper expands on the scope of correlation filters to show their usefulness for reliable face recognition. Towards that end we propose adaptive and robust correlation filters (ARCF) and describe their usefulness for reliable face authentication using recognition-by-parts strategies. ARCF provide information that involves both appearance and location. The cluster and strength of the ARCF correlation peaks indicate the confidence of the face authentication made, if any. The development of ARCF, motivated by MACE filters and adaptive beam-forming from radar/sonar, is driven by Tikhonov regularization. The adaptive aspect of ARCF comes from their derivation using both training and test data, similar to transduction, while the robust aspect benefits from the correlation peak optimization to decrease their sensitivity to noise and distortions. The comparative advantages of ARCF are motivated, explained, and illustrated vis-á-vis competing correlation filters. Experimental evidence shows the feasibility and reliability of ARCF vis-á-vis occlusion, disguise, and illumination, expression, and temporal variability. The generalization ability of ARCF is further illustrated when decision-making thresholds learned a priori from one data base, e.g., FERET, carry over to face images from another data base, e.g., AR. © 2008 Elsevier Inc. All rights reserved.","Adaptation; Appearance; AR; Beam-forming; Biometrics; Configural/configuration; Correlation filters; Disguise; Face recognition; Facial features; Feed-forward; FERET; Holistic; Location; Matching; Occlusion; Recognition-by-parts; Reliability; Robustness; Tikhonov regularization; Transduction"
"Belcher C., Du Y.","A selective feature information approach for Iris image-quality measure","https://www.scopus.com/inward/record.uri?eid=2-s2.0-49549092227&doi=10.1109%2fTIFS.2008.924606&partnerID=40&md5=8b9214950162527900d4031b64574fa7","Poor quality images can significantly affect the accuracy of iris-recognition systems because they do not have enough feature information. However, existing quality measures have focused on parameters or factors other than feature information. The quality of feature available for measure is a combination of the distinctiveness of the iris region and the amount of iris region available. Some irises may only have a small area of changing patterns. Due to this, the proposed approach automatically selects the portions of the iris with the most distinguishable changing patterns to measure the feature information. The combination of occlusion and dilation determines the amount of iris region available and is considered in the proposed quality measure. The quality score is the fused result of the feature information score, the occlusion score, and the dilation score. The relationship between the quality score and recognition accuracy is evaluated using 2-D Gabor and 1-D Log-Gabor wavelet approaches and validated using a diverse data set. In addition, the proposed method is compared with the convolution matrix, spectrum energy, and Mexican hat wavelet methods. These three methods represent a variety of approaches for iris-quality measure. The experimental results show that the proposed quality score is highly correlated with the recognition accuracy and is capable of predicting the recognition results. © 2008 IEEE.","Biometrics; Feature information; Iris recognition; Iris-quality measure"
"Barzegar N., Moin M.S.","A new approach for iris localization in iris recognition systems","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50049096941&doi=10.1109%2fAICCSA.2008.4493581&partnerID=40&md5=af128fada433564c63ff6c7014ef6164","This paper presents a new approach for iris localization which consists of one of the most important steps in an iris recognition system. We have solved some of the most important drawbacks of the current methods using a pointwise level set algorithm, which detects the precise location of the iris by a stepwise deformation of an initial contour. Due to the special properties of our approach, there is no constraint about angles of head tilt. Furthermore, this algorithm is robust in noisy situations and can find irises which are partly occluded by eyelid and eyelashes. This is done by using a topology preserving technique in only one step to find both inner and outer boundaries. Another advantage of our method is its ability to find iris in images which include other parts of face. This pointwise level set approach makes it possible to perform the operations of the iris localization and mapping of iris coordinates to a polar dimension simultaneously, an approach which decreases the processing time of the system considerably. The experimental results show that the proposed method outperforms the current methods both in terms of accuracy and response time. ©2008 IEEE.","Biometrie systems; Iris localization; Iris recognition; Level set approach"
"Belcher C., Du Y.","Information distance based contrast invariant iris quality measure","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44949165634&doi=10.1117%2f12.778111&partnerID=40&md5=ab4b2e7dbb5479c8d92f27ff8dc366d4","Poor quality can affect iris recognition accuracy. Feature information is an objective measure to evaluate the iris image quality. By combining Feature Information Measure (FIM), an occlusion measure and a dilation measure, a quality score is obtained that is well correlated with recognition accuracy. FIM is calculated as the distance between the distribution of iris features and a uniform distribution. Images of low contrast can appear to lack information from manual inspection, but actually perform well in iris recognition due to the presence of feature information. However, the FIM score for a low contrast image could be low. To adjust this affect, this paper developed an information based contrast invariant iris quality measure. For exhaustive comparison, CASIA 1.0, CASIA 2.0, ICE and WVU databases is used. In addition, the proposed method is compared to the convolution matrix, spectrum energy and Mexican hat wavelet approaches which represent a variety of approaches to iris quality measure. The experimental results show that the proposed quality measure is capable of predicting matching performance.","Biometrics; Feature information; Iris quality measure; Iris recognition"
"Sheeba Rani J., Devaraj D., Sukanesh R.","Robust face recognition using wavelet transform and autoassociative neural network","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953162530&doi=10.1504%2fIJBM.2008.020146&partnerID=40&md5=32be8aa4a104f1a4f5dfa55359f6fc13","In this paper, an efficient face recognition system using wavelet transform (WT) and modular autoassociative neural network (AANN) is proposed. WT, which has superior feature representation capability in multiresolution space and also less sensitive to noise and variation to lighting condition, is used to extract the features. The AANN which perform identity mapping of input space is used to capture the distribution of the low resolution face data obtained from WT. To avoid over fitting, over training and small-sample effect problem, we construct separate AANN for each person. To evaluate the proposed scheme, experiments have been conducted using ORL database and Yale A database for three cases namely normal images, noisy images and occluded images. In all the three cases, the modular AANN scheme produces better recognition rate compared to PCA, LDA and kernel associative memory (KAM). In particular, the proposed method outperforms the other methods in the case of occluded images. © 2008 Inderscience Enterprises Ltd.","AANN; autoassociative neural network; biometrics; face recognition; Haar wavelet; wavelet transform"
"Heo J., Savvides M.","Face pose correction with eyeglasses and occlusions removal","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50249182986&doi=10.1109%2fBCC.2007.4430551&partnerID=40&md5=6171ad680cb76cc71b6abec3f9552d44","This paper presents how to remove unwanted occlusions such as eyeglasses in face images. By choosing training images carefully, we can derive a set of basis vectors that can eliminate this impediment for processing face images. In order to handle different poses, we apply Multi-View Active Appearance Models (MVAAMs) for fitting and then convert non-frontal images into frontal neutral faces. A set of these frontal-neutral faces is chosen for the basis and used for reconstructing other face images with occlusions. In addition, we are able to correct missing features while converting into frontal faces. The corrected faces are used for inputting to a frontal based face recognition system which can handle non-frontal faces efficiently. ©2007 IEEE.",
"Li F., Wechsler H.","Robust part-based face recognition using boosting and transduction","https://www.scopus.com/inward/record.uri?eid=2-s2.0-48649088385&doi=10.1109%2fBTAS.2007.4401923&partnerID=40&md5=5425f6da846cd846f41d71b2b3aa0f23","The challenge for biometrics is to withstand image variability and defend against impostors seeking to breach security. The impostors attempt to hide and/or alter the information needed for their identification. While faces can be partially occluded and/or disguised some of their parts remain unchanged and can still be properly detected and authenticated. Towards that end this paper advocates robust part-based face recognition using boosting and transduction. The face representation used spans a multi-resolution (golden ratio) grid that captures partial information at different scales in order to accommodate different surveillance scenarios including human identification from distance. The face components are defined across the eyes, nose, mouth, eye and nose, nose and mouth, and the like, and encode both facial parts and their second order relationships. The parts, clusters of local patches described using similar SIFT features, are modeled using an exemplar based representation. The model free and non-parametric weak learners found by transduction, which correspond to parts and their relationships, compete to build up a strong boosting classifier. The feasibility of the novel approach, using FRGC (UND) database, shows robustness to uncontrolled lighting condition, different facial expressions, and occlusion. ©2007 IEEE.",
"Elbakary M.I., Alam M.S., Asian M.S.","Face recognition algorithm in hyperspectral imagery by employing the K-means method and the mahalanobis distance","https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149121357&doi=10.1117%2f12.737191&partnerID=40&md5=742424bebeb05373d7fdfc010d248da4","Recently, spectral information is introduced into face recognition applications to improve the detection performance for different conditions. Besides the changes in scale, orientation, and rotation of facial images, expression, occlusion and lighting conditions change the overall appearance of faces and recognition results. To eliminate these difficulties, we introduced a new face recognition technique by using the spectral signature of facial tissues. Unlike alternate algorithms, the proposed algorithm classifies the hyperspectral imagery corresponding to each face into clusters to automatically recognize the desired face and to eliminate the user intervention in the data set. The K-means clustering algorithm is employed to accomplish the clustering and then Mahalanobis distance is computed between the clusters to identify the closest cluster in the data with respect to the reference cluster. By identifying a cluster in the data, the face that contains that cluster is identified by the proposed algorithm. Test results using real life hyperspectral imagery shows the effectiveness of the proposed algorithm.","Biometric recognition; Face recognition; Hyperspectral data; K-means algorithm; Mahalanobis distance"
"Lai H., Li F., Wechsler H.","Robust face recognition strategies using feed-forward architectures and parts","https://www.scopus.com/inward/record.uri?eid=2-s2.0-38149090985&partnerID=40&md5=1884ce822ef1355bc69b85d0992df060","This paper describes new feed-forward architectural and configural/holistic strategies for robust face recognition. This includes adaptive and robust correlation filters that lock on both appearance and location, and recognition-by-parts using boosting over strangeness driven weak learners. The utility of the proposed architectural strategies, shown with respect to different databases, includes occlusion, disguise, and temporal changes. The results obtained confirm and complement key findings on the ways people recognize each other, among them that the facial features are processed holistically and that the eyebrows are among the most important features for recognition. © Springer-Verlag Berlin Heidelberg 2007.","Adaptive and robust correlation filters (ARCF); Biometrics; Boosting; Configurai; Disguise; Face recognition; Feed-forward; Holistic; Occlusion; Recognition-by-parts; Strangeness; Transduction; Weak learners"
"Tong Y., Liao W., Ji Q.","Facial action unit recognition by exploiting their dynamic and semantic relationships","https://www.scopus.com/inward/record.uri?eid=2-s2.0-36048938814&doi=10.1109%2fTPAMI.2007.1094&partnerID=40&md5=078b66bd05bf360f484e75eb294070ea","A system that could automatically analyze the facial actions in real time has applications in a wide range of different fields. However, developing such a system is always challenging due to the richness, ambiguity, and the dynamic nature of facial actions. Although a number of research groups attempt to recognize facial action units (AUs) by either improving facial feature extraction techniques, or the AU classification techniques, these methods often recognize AUs or certain AU combinations individually and statically, ignoring the semantic relationships among AUs and the dynamics of AUs. Hence, these approaches cannot always recognize AUs reliably, robustly, and consistently.In this paper, we propose a novel approach that systematically accounts for the relationships among AUs and their temporal evolutions for AU recognition. Specifically, we use a dynamic Bayesian network (DBN) to model the relationships among different AUs. The DBN provides a coherent and unified hierarchical probabilistic framework to represent probabilistic relationships among various AUs and to account for the temporal changes in facial action development. Within our system, robust computer vision techniques are used to obtain AU measurements. And such AU measurements are then applied as evidence to the DBN for inferring various AUs. The experiments show that the integration of AU relationships and AU dynamics with AU measurements yields significant improvement of AU recognition, especially for spontaneous facial expressions and under more realistic environment including illumination variation, face pose variation, and occlusion. © 2007 IEEE.","Bayesian networks; Facial Action Coding System; Facial action unit recognition; Facial expression analysis"
"Carrasco M., Pizarro L., Mery D.","Bimodal biometrie person identification system under perturbations","https://www.scopus.com/inward/record.uri?eid=2-s2.0-38149138700&partnerID=40&md5=3a924b85e122bf1f84f6b5f09725f407","Multibiometric person identification systems play a crucial role in environments where security must be ensured. However, building such systems must jointly encompass a good compromise between computational costs and overall performance. These systems must also be robust against inherent or potential noise on the data-acquisition machinery. In this respect, we proposed a bimodal identification system that combines two inexpensive and widely accepted biometric traits, namely face and voice information. We use a probabilistic fusion scheme at the matching score level, which linearly weights the classification probabilities of each person-class from both face and voice classifiers. The system is tested under two scenarios: a database composed of perturbation-free faces and voices (ideal case), and a database perturbed with variable Gaussian noise, salt-and-pepper noise and occlusions. Moreover, we develop a simple rule to automatically determine the weight parameter between the classifiers via the empirical evidence obtained from the learning stage and the noise level. The fused recognition systems exceeds in all cases the performance of the face and voice classifiers alone. © Springer-Verlag Berlin Heidelberg 2007.","Biometrics; Face; Gaussian noise; Identificacion; Multimodal; Occlusions; Probabilistic fusion; Salt-and-pepper noise; Voice"
"Serrano A., Conde C., De Diego I.M., Cabello E., Bai L., Shen L.","Parallel gabor PCA with fusion of SVM scores for face verification","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650236880&partnerID=40&md5=e78c6cedcbb71a19fa0dc5161405d7a7","Here we present a novel fusion technique for support vector machine (SVM) scores, obtained after a dimension reduction with a principal component analysis algorithm (PCA) for Gabor features applied to face verification. A total of 40 wavelets (5 frequencies, 8 orientations) have been convolved with public domain FRAV2D face database (109 subjects), with 4 frontal images with neutral expression per person for the SVM training and 4 different kinds of tests, each with 4 images per person, considering frontal views with neutral expression, gestures, occlusions and changes of illumination. Each set of wavelet-convolved images is considered in parallel or independently for the PCA and the SVM classification. A final fusion is performed taking into account all the SVM scores for the 40 wavelets. The proposed algorithm improves the Equal Error Rate for the occlusion experiment compared to a Downsampled Gabor PCA method and obtains similar EERs in the other experiments with fewer coefficients after the PCA dimension reduction stage.","Biometrics; Data fusion; Face database; Face verification; Gabor wavelet; Principal component analysis; Support vector machine"
"Wechsler H.","Robust recognition-by-parts using transduction and boosting with applications to biometrics","https://www.scopus.com/inward/record.uri?eid=2-s2.0-48049085221&doi=10.1109%2fIWSSIP.2007.4381084&partnerID=40&md5=31e06f3047d1f852a28beab286354a55","The ability to recognize objects, in general, and living creatures, in particular, in photographs or video clips, is a critical enabling technology for a wide range of applications including health care, human-computer intelligent interaction, search engines for image retrieval and data mining, industrial and personal robotics, surveillance and security, and transportation. Despite almost 50 years of research, however, today's object recognition systems are still largely unable to handle the extraordinary wide range of appearances assumed by common objects [including human faces] in typical images. Some of the challenges for modern pattern recognition that have to be addressed in order to advance and make practical both detection and categorization include open set recognition, occlusion and masking, change detection and time-varying imagery, lack of enough data for training, and proper performance evaluation and error analysis. Open set recognition operates under the assumption that not all the test (unknown) probes have mates in the gallery (training set), occlusion and masking hide and disguise parts of the input, image contents vary across both the spatial and temporal dimensions, the amount of data available for learning and adaptation is limited, and errors are not uniformly distributed across patterns. The recognition-by-parts approach proposed here to address the challenges listed above is driven by transduction and boosting. Transduction employs local estimation and inference to find a compatible labeling of joined training and test data. Active learning further promotes the recognition process by making incremental choices about what is best to learn and when in order to accumulate the evidence needed to disambiguate among alternative interpretations. The interplay between labeled (""training"") and unlabeled (""test"") data points mediates between semi-supervised learning and transduction. The additional information coming from the unlabeled data points includes constraints and hints about the meaningful relations and regularities affecting their very discrimination. Boosting combines in an iterative fashion part-based, model-free, and non-parametric simple weak classifiers, whose contents and relative ranking are driven by their ""strangeness"" characteristics. The scope of the proposed approach covers also stream-based data points and includes change detection. The benefits of the proposed discriminative recognition-by-parts approach include a priori setting of rejection thresholds, no need for image segmentation, robustness to occlusion, clutter, and disguise. Examples drawn from biometrics illustrate the proposed approach and show its feasibility and utility.",
"Zhang B., Ko H., Gao Y.","Learning kernel subspace classifier","https://www.scopus.com/inward/record.uri?eid=2-s2.0-37849022817&partnerID=40&md5=559ced13d5793c0e2c746c1948bc3a9b","Subspace classifiers are well-known in pattern recognition, which represent pattern classes by linear subspaces spanned by the class specific basis vectors through simple mathematical operations like SVD. Recently, kernel based subspace methods have been proposed to extend the functionalities by directly applying the Kernel Principal Component Analysis (KPCA). The projection variance in kernel space as applied in these earlier proposed kernel subspace methods, however, is not a trustworthy criteria for class discrimination and they simply fail in many recognition problems as we encountered in biometrics research. We address this issue by proposing a learning kernel subspace classifier which attempts to reconstruct data in input space through the kernel subspace projection. While the pre-image methods aiming at finding an approximate pre-image for each input by minimization of the reconstruction error in kernel space, we emphasize the problem of how to estimate a kernel subspace as a model for a specific class. Using the occluded face recognition as examples, our experimental results demonstrated the efficiency of the proposed method. © Springer-Verlag Berlin Heidelberg 2007.",
"Zhu X., Liao S., Lei Z., Liu R., Li S.Z.","Feature correlation filter for face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-37849027612&partnerID=40&md5=f7516a8c41dfe92980da84f2cbbcbcd9","The correlation filters for pattern recognition, have been extensively studied in the areas of automatic target recognition(ATR) and biometrics. Whereas the conventional correlation filters perform directly on image pixels, in this paper, we propose a novel method, called ""feature correlation filter (FCF)"", by extending the concept of correlation filter to feature spaces. The FCF preserves the benefits of conventional correlation filters, i.e., shift-invariant, occlusion-insensitive, and closed-form solution, and also inherits virtues of the feature representations. Moreover, since the size of feature is often much smaller than the size of image, the FCF method can significantly reduce the storage requirement in recognition system. The comparative results on CMU-PIE and the FRGC2.0 database show that the proposed FCFs can achieve noteworthy performance improvement compared with their conventional counterpart. © Springer-Verlag Berlin Heidelberg 2007.","Correlation filters; Face recognition; Feature correlation filters; MACE"
"Abate A.F., Nappi M., Riccio D., Tortora G.","RBS: A robust bimodal system for face recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548647721&doi=10.1142%2fS0218194007003379&partnerID=40&md5=727a5a2d93b3af01341444975fc3a0f3","During the last few years, many algorithms have been proposed in particular for face recognition using classical 2-D images. However, it is necessary to deal with occlusions when the subject is wearing sunglasses, scarves and such. In the same way, ear recognition is arising as a new promising biometric for people recognition, even if the related literature appears to be somewhat underdeveloped. In this paper, several hybrid face/ear recognition systems are investigated. The system is based on IFS (Iterated Function Systems) theory that are applied on both face and ear- resulting in a bimodal architecture. One advantage is that the information used for the indexing and recognition task of face/ear can be made local, and this makes the method more robust to possible occlusions. The distribution of similarities in the input images is exploited as a signature for the identity of the subject. The amount of information provided by each component of the face and the ear- image has been assessed, first independently and then jointly. At last, results underline that the system significantly outperforms the existing approaches in the state of the art. © World Scientific Publishing Company.","Biometrics; Fractals; Multimodal"
"Wang S., Wang Y., Jin M., Gu X.D., Samaras D.","Conformal geometry and its applications on 3D shape matching, recognition, and stitching","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249680361&doi=10.1109%2fTPAMI.2007.1050&partnerID=40&md5=56fa0a16be49b82793a8cb3f27c6a6a8","Three-dimensional shape matching is a fundamental issue in computer vision with many applications such as shape registration, 3D object recognition, and classification. However, shape matching with noise, occlusion, and clutter is a challenging problem. In this paper, we analyze a family of quasi-conformal maps including harmonic maps, conformal maps, and least-squares conformal maps with regards to 3D shape matching. As a result, we propose a novel and computationally efficient shape matching framework by using least-squares conformal maps. According to conformal geometry theory, each 3D surface with disk topology can be mapped to a 2D domain through a global optimization and the resulting map is a diffeomorphism, i.e., one-to-one and onto. This allows us to simplify the 3D shape-matching problem to a 2D image-matching problem, by comparing the resulting 2D parametric maps, which are stable, insensitive to resolution changes and robust to occlusion, and noise. Therefore, highly accurate and efficient 3D shape matching algorithms can be achieved by using the above three parametric maps. Finally, the robustness of least-squares conformal maps is evaluated and analyzed comprehensively in 3D shape matching with occlusion, noise, and resolution variation. In order to further demonstrate the performance of our proposed method, we also conduct a series of experiments on two computer vision applications, i.e., 3D face recognition and 3D nonrigid surface alignment and stitching. © 2007 IEEE.","3D face recognition; Conformal geometry; Shape matching; Shape representations"
"Malassiotis S., Strintzis M.G.","Snapshots: A novel local surface descriptor and matching algorithm for robust 3D surface alignment","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249735996&doi=10.1109%2fTPAMI.2007.1060&partnerID=40&md5=ba0e3c9d43d2350f3a2f430c9f58a69b","In this paper, a novel local surface descriptor is proposed and applied to the problem of aligning partial views of a 3D object. The descriptor is based on taking ""snapshots"" of the surface over each point using a virtual camera oriented perpendicularly to the surface. This representation has the advantage of imposing minimal loss of information be robust to self-occlusions and also be very efficient to compute. Then, we describe an efficient search technique to deal with the rotation ambiguity of our representation and experimentally demonstrate the benefits of our approaches which are pronounced especially when we align views with small overlap. © 2007 IEEE.","Object recognition; Partially overlapping surfaces; Surface matching"
"Bakhtari A., Benhabib B.","An active vision system for multitarget surveillance in dynamic environments","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847619797&doi=10.1109%2fTSMCB.2006.883423&partnerID=40&md5=0ec75865a0e076bdb77aa551627eb932","This paper presents a novel agent-based method for the dynamic coordinated selection and positioning of active-vision cameras for the simultaneous surveillance of multiple objects-of-interest as they travel through a cluttered environment with a-priori unknown trajectories. The proposed system dynamically adjusts not only the orientation but also the position of the cameras in order to maximize the system's performance by avoiding occlusions and acquiring images with preferred viewing angles. Sensor selection and positioning are accomplished through an agent-based approach. The proposed sensing-system reconfiguration strategy has been verified via simulations and implemented on an experimental prototype setup for automated facial recognition. Both simulations and experimental analyses have shown that the use of dynamic sensors along with an effective online dispatching strategy may tangibly improve the surveillance performance of a sensing system. © 2007 IEEE.","Active vision; Dispatching; Facial recognition; Sensor fusion; Surveillance"
"Anjum M.A., Javed M.Y.","Multiresolution and varying expressions analysis of face images for recognition","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33947187311&partnerID=40&md5=a89cc170e3b433438dfef2fe4099001a","This study demonstrates a lower dimension multiresolution and facial expression analysis of facial images using wavelet transform and image decimation algorithm. It minimizes heavy computational load, reduce noise, produce a representation in low frequency domain and hence make the facial images less sensitive to facial expressions and small occlusions. An improved recognition rate is achieved through effective image pre processing and novel feature extraction technique. Within class varying facial expressions effects have been minimized by using image decimation. Novel feature extraction methodology has been used to extract the most suitable feature vectors required for recognition. Experiments on ORL, YALE, FERET and EME color datasets have been performed with success rate up to 99.25%. Model has been also tested on CMU AMP face expression and dataset to evaluate the ability of wavelets and decimation algorithm for varying expression compensation. Hundred percent recognition rate on this dataset is achieved. © 2007 Asian Network for Scientific Information.","Biometrics; Facial expressions face recognition; Image decimation; Image processing; Morphological operations; Wavelets"
"Arandjelović O., Hammoud R., Cipolla R.","Multi-sensory face biometric fusion (for personal identification)","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845524031&doi=10.1109%2fCVPRW.2006.136&partnerID=40&md5=0b96f5120e02c63951cd0c62115029ba","The objective of this work is to recognize faces using sets of images in visual and thermal spectra. This is challenging because the former is greatly affected by illumination changes, while the latter frequently contains occlusions due to eye-wear and is inherently less discriminative. Our method is based on a fusion of the two modalities. Specifically: we examine (i) the effects of preprocessing of data in each domain, (ii) the fusion of holistic and local facial appearance, and (iii) propose an algorithm for combining the similarity scores in visual and thermal spectra in the presence of prescription glasses and significant pose variations, using a small number of training images (5-7). Our system achieved a high correct identification rate of 97% on a freely available test set of 29 individuals and extreme illumination changes. © 2006 IEEE.",
"Zhang B., Cerone P., Gao Y.","Robust face recognition by hierarchical kernel associative memory models based on spatial domain Gabor transforms","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650365447&partnerID=40&md5=c68b490240cb8e077faf3e593eecdd16","Face recognition can be studied as an associative memory (AM) problem and kernel-based AM models have been proven efficient. In this paper, a hierarchical Kernel Associative Memory (KAM) face recognition scheme with a multiscale Gabor transform, is proposed. The pyramidal multiscale Gabor decomposition proposed by Nestares, Navarro, Portilla and Tabernero not only provides a very efficient implementation of the Gabor transform in the spatial domain, but also permits a fast reconstruction of images. In our method, face images of each person are first decomposed into their multiscale representations by a quasicomplete Gabor transform, which are then modelled by Kernel Associative Memories. In the recognition stage, a query face image is also represented by a Gabor multiresolution pyramid and the reconstructions from different KAM models corresponding to even Gabor channels are then simply summed to give the recall. The recognition scheme was thoroughly tested using several benchmarking face datasets, including the AR faces, UMIST faces, JAFFE faces and Yale A faces, which include different kind of face variations from occlusions, pose, expression and illumination. The experiment results show that the proposed method demonstrated strong robustness in recognizing faces under different conditions, particularly under occlusions, pose alterations and expression changes. © 2006 ACADEMY PUBLISHER.","Associative memory; Biometrics; Face recognition; Gabor wavelet transform; Kernel methods"
"Lee S.-W., Park J., Lee S.-W.","Face reconstruction with low resolution facial images by feature vector projection in kernel space","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34147155754&doi=10.1109%2fICPR.2006.533&partnerID=40&md5=05bbe14f193593c0e5f5f5e0e9fdfc2d","In spite of increasing interest in person identification based on biometrics, face recognition technology has not been applied into real world. It is caused by appearance changes such as illumination, noise, degradation, and occlusion. Among these problems, we focus on the low resolution problem and propose a new face recognition method of extending the SVDD(support vector data description). In the proposed method, we first solve the SVDD problem for the data belonging to the given prototype facial images, and model the data region for the normal faces as the ball resulting from the SVDD problem. Next, for each input facial image in low resolution, we project its feature vector onto the decision boundary of the SVDD ball so that it can be tailored enough to belong to the normal region. Finally, we synthesize facial images which are obtained from the preimage of the projection, and then perform the face recognition. The applicability of the proposed method is illustrated via some experiments using general recognition algorithm. © 2006 IEEE.",
"Anjum M.A., Javed M.Y.","Face images dimension reduction using wavelets and decimation algorithm","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864961833&partnerID=40&md5=6b1096d7b97226976e55c6cf565c902a","This paper demonstrates a novel lower dimension multi resolution analysis technique to represent facial images using wavelet transform and decimation, which alleviate heavy computational load, reduce noise, produce a representation in low frequency domain and hence make the facial images less sensitive to facial expressions and small occlusions. All coefficients of wavelet transform do not have information needed for face classification. This work also selects the most appropriate wavelet coefficients required for recognition. In preprocessing phase to reduce computational load, Automatic Cropping Algorithm (ACA) is applied for scale normalization which removes unnecessary details except face from image and at the same time facial tilt has been addressed through reverse rotation process. Image decimation is carried out to compute the recognition results at different image resolutions and to compensate varying facial expression. The experiments have been performed on ORL and FERET datasets with different resolutions; success rate up to 99% on ORL dataset is achieved.","Biometrics; Face recognition; Image decimation and wavelets; Image processing"
"Beverina F., Palmas G., Anisetti M., Bellandi V.","Tracking based face identification: A way to manage occlusions, and illumination, posture and expression changes","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248161968&doi=10.1049%2fcp%3a20060638&partnerID=40&md5=86ce5907d44c91cc14b4251c349d21f2","This paper presents a method for face identification using an eigenfaces approach. Our technique is suitable for use within ambient security environments and is robust across variations in pose, expression and illuminations conditions. To account for these variations, we use a face template matching algorithm based on a 3D head model. Thanks to our tracking-based approach our algorithm is able to extract simultaneously all parameters related to the face expression and to the 3D posture. With these estimates, we are able to reconstruct a frontal, neutral and normalized image on which an eigenface classification for identification is performed.","Biometric data analysis; Expression; Face classification; Occlusion; Posture"
"Mitra S.","Towards statistically rigorous biometric authentication using facial images","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889987680&doi=10.1007%2f0-387-35209-0_5&partnerID=40&md5=bbae7f255e0cc6d4cab1db4135a3ed46","In the modern electronic information age, there is an ever-growing need to authenticate and identify individuals for ensuring the security of a system. Traditional methods of authentication and identification make use of identification (ID) cards or personal identification numbers (PINs), but such identifiers can be lost, stolen, or forgotten. In addition, these methods fail to differentiate between an authorized person and an impostor who fraudulently acquires knowledge or ""token"" of the authorized person. Security breaches have led to losses amounting to millions of dollars in agencies like banks and telecommunication systems that depend on token-based security systems. In traditional statistical literature, the term biometrics or biometry refers to the field of statistical methods applicable to data analysis problems in the biological sciences, such as agricultural field experiments to compare the yields of different varieties of a crop, or human clinical trials to measure the effectiveness of competing therapies. Recently the term biometrics has also been used to denote the unique biological traits (physical or behavioral of individuals that can be used for identification), and biometric authentication is the newly emerging technology devoted to verification of a person's identity based on his/her biometrics. The purpose of biometric authentication is to provide answers to questions like the following: • Is this person authorized to enter a facility? • Is this individual entitled to access privileged information? • Is the given service being administered only to enrolled users? These questions are vital for ensuring security of many business and governmental organizations. Since it relies on ""something you are"" rather than ""something you know or possess,"" a biometric in principle cannot be stolen, forgotten, or duplicated and is less prone to fraud than PINs and ID cards. For all these reasons, the field of biometrics has been growing exponentially in recent years (especially after the attacks of September 11, 2001), and the rapidly 48 Sinjini Mitra evolving technology is being widely used in forensics for criminal identification in law enforcement and immigration, in experimental form in restricting access to automated teller machines (ATMs) and computer networks, as well as in various forms of e-commerce and electronic banking. Moreover, the recent practice of recording biometric information (photo and fingerprint) of foreign passengers at all U.S. airports and also the proposed inclusion of digitized photos in passports show the growing importance of biometrics in U.S. homeland security. Typically used biometrics include face images, fingerprints, iris measurements, palm prints, hand geometry, hand veins (physical traits), and voiceprint, gait, and gesture (behavioral traits). Generally, biometric systems are composed of two parts: (1) the enrollment and (2) the identification part. The former involves the registration of a user's characteristic, which is subsequently to be used as a criterion for classification purposes. This procedure involves sample capturing with the help of digital cameras or similar devices, feature extraction for developing a sample template, and storing the template with the relevant database. The second part provides the user interface to have the end user's characteristic captured, compared to the existing templates, and verified whether he or she is authentic or an impostor. Face recognition is probably the most popular biometric-based method because of its potential to be both accurate as well as nonintrusive and userfriendly. It analyzes facial characteristics to verify whether the image belongs to a particular person. Faces are rich in information about individual identity, mood and mental state, and position relationships between face parts, such as eyes, nose, mouth, and chin, as well as their shapes and sizes, are widely used as discriminative features for identification. Much research has been done on face recognition in the past decades in the field of computer science, and yet face authentication still poses many challenges. Several images of a single person may be dramatically different because of changes in viewpoint, color, and illumination, or simply because the person's face looks different from day to day due to appearance-related changes like makeup, facial hair, glasses, etc. Several authentication methods based on face images have been developed for recognition and classification purposes. In face authentication, as in most image processing problems, it is necessary to extract relevant discriminative features that distinguish individuals. But one hardly knows in advance which possible features will be discriminative. For this reason, most of the face authentication systems today use some kind of efficient automatic feature extraction technique. Jonsson et al. [JKL99] used support vector machines (SVM) to extract relevant discriminatory information from the training data and build an efficient face authentication system, and Li et al. [LKM99] used linear discriminant analysis (LDA) for efficient face recognition and verification. Liu et al. [LCV02] applied principal components analysis (PCA) for modeling variations arising in face images from expression changes and registration errors by using the motion field between images in a video clip. Havran et al. [HHC02] performed face authentication based on independent component Biometric Authentication Using Facial Images 49 analysis (ICA), and Palanivel et al. [PVY03] proposed a method for videobased, real-time face authentication using neural networks. A recently developed face authentication system is the minimum average correlation energy (MACE) filter [VSV02, SVK02]. The MACE filter was originally proposed by Mahalanobis et al. [MVC87] as an effective automatic target recognition tool, and Vijaya Kumar et al. [VSV02] first used it to authenticate a facial expression database, obtaining impressive results. Savvides and Vijaya Kumar [SV03] showed that the filter-based methods produce more accurate authentication results than traditional methods based on LDA and PCA, especially in the presence of distortions such as illumination changes and partial occlusions. The present chapter reports some initial work on establishing a firmer statistical foundation for face authentication systems and in verifying the accuracy of proposed methods in engineering and computer science, which are mostly empirical in nature. Given the sensitive nature of their applications today, it is imperative to have rigorous authentication systems where inaccurate results may have a drastic impact. The layout of the chapter is as follows. Section 2 describes some basic statistical tools that can be employed for evaluation of authentication techniques and Sect. 3 provides brief descriptions of the databases used for our study. Section 4 introduces the MACE filter authentication system along with its statistical aspects, and Sect. 5 discusses statistical model-based systems and the associated challenges and comparison with the MACE system. © 2006 Springer Science+Business Media, LLC.",
"Das A., Ghosh P.","Audio-visual biometric recognition by Vector Quantization","https://www.scopus.com/inward/record.uri?eid=2-s2.0-48749116740&doi=10.1109%2fSLT.2006.326843&partnerID=40&md5=6b40a3ad7a20b58803500807ad53e5f9","We present a Vector Quantization based bimodal (speech and face) biometric recognition method which delivers high performance amidst noise, illumination variations and occlusions (disguised mode) while requiring very little training data, memory storage and complexity of operation. A Transform VQ method delivers good face-recognition performance and a Text Dependent VQ method provides good recognition performance using speech. Simple fusion of two leads to a wider separation between the user-clusters in the combined feature space, leading to high performance. ©2006 IEEE.",
"Kadyrov A., Petrou M.","Affine parameter estimation from the trace transform","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750132711&doi=10.1109%2fTPAMI.2006.198&partnerID=40&md5=2ca4c9fad7b493456b09ece04aec1b70","In this paper, we assume that we are given the images of two segmented objects, one of which may be an affinely distorted version of the other, and wish to recover the values of the parameters of the affine transformation between the two images. The images may also differ by the overall level of illumination. The multiplicative constant of such difference may also be recovered. We present a generic theoretical framework to solve this problem. In terms of this framework, other proposed methods may be interpreted. We show how, in this framework, one can recover the affine parameters in a way that is robust to various effects, such as occlusion and illumination variation. The proposed method is generic enough to be applicable also to matching two images that do not depict the same scene or object. © 2006 IEEE.","Affine transform; Image registration; Object matching; Parameter estimation; Trace transform"
"Mian A., Bennamoun M., Owens R.","Face recognition using 2D and 3D multimodal local features","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845424523&partnerID=40&md5=3d3dfbf37642a9939fc0c5317142628d","Machine recognition of faces is very challenging because it is an interclass recognition problem and the variation in faces is very low compared to other biometrics. Global features have been extensively used for face recognition however they are sensitive to variations caused by expressions, illumination, pose, occlusions and makeup. We present a novel 3D local feature for automatic face recognition which is robust to these variations. The 3D features are extracted by uniformly sampling local regions of the face in locally defined coordinate bases which makes them invariant to pose. The high descriptiveness of this feature makes it ideal for the challenging task of interclass recognition. In the 2D domain, we use the SIFT descriptor and fuse the results with the 3D approach at the score level. Experiments were performed using the FRGC v2.0 data and the achieved verification rates at 0.001 FAR were 98.5% and 86.0% for faces with neutral and non-neutral expressions respectively. © Springer-Verlag Berlin Heidelberg 2006.",
"Abate A.F., Nappi M., Riccio D., De Marsico M.","Component based face recognition against occlusions: Gabor wavelets vs. GFD","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923855489&partnerID=40&md5=f77a48a31fdeebfcf68ac83b6470babe","The need to assure the safety of places, people and information is particularly compelling nowadays. A reliable and widely accepted solution is the use of biometric systems and of face recognition in particular, thanks to its high degree of acceptance and ease of use. Most techniques presented in literature work on the whole face and often omit to consider the occlusion problem. This work proposes two classifiers, suitably adjusted to be Component Based and robust to occlusions. The experiments that we carried out show how these approaches perform well even in presence of partial occlusions. © 2006 by Knowledge Systems Institute Graduate School. All rights reserved.",
